{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT DETAILS\n",
    "- this project is built on top of langchain and llama-cpp leveraging mainly mistral's GGUF models and can be extensible to support other models\n",
    "- the decision to utilize running .GGUF models on top of llama-cpp is purely due to a resource constraint on my host machine and this decision could be factored in similarly if you were to work on resource constraint devices.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-REQUISITES:\n",
    "\n",
    "### Data Files:\n",
    "- data.csv: containing transaction data\n",
    "- client.csv: trivial table containingclient id and client name columns\n",
    "- assumes a .gguf model is downloaded, for reference, the model that this repository uses extensively: \n",
    "  - https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF\n",
    "  - https://huggingface.co/TheBloke/CodeLlama-34B-Instruct-GGUF\n",
    "  - specifically: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/blob/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf\n",
    "  - `curl -L -o models/mistral-7b-instruct-v0.1.Q4_K_M.gguf https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/blob/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf` to download using curl command on Linux\n",
    "\n",
    "\n",
    "### Environment\n",
    "- you must have a virtual environment package manager like conda, poetry, etc. installed and setup properly\n",
    "- have a conda environment or equivalent created e.g. `conda create -n venv python=3.11.5\n",
    "- [OPTIONAL | RECOMMENDED] development on my end is done on WSL-Linux environment on Ubuntu22.04 distro and is recommended to follow as well.\n",
    "- assumes a database `data.db` already loaded from a given `data.csv` file\n",
    "  - there is legacy code that could be referred from `archive/backup.py` to achieve this\n",
    "- have the minimum RAM required to run the .gguf model (5~6 GB RAM)\n",
    "  - due to hardware constraint the `.gguf` model is used for mistral-7b which suffers quality loss in exchange for less hardware resource usage\n",
    "  - you can opt to extend the code to load full models from hugging face / ollama if you do not face such hardware constraints\n",
    "- the python version used is `3.11.5`\n",
    "- [OPTIONAL] have a .env file in the same directory as`main.py`, example:\n",
    "    ```\n",
    "    MODEL_NAME=xxx\n",
    "    HF_AUTH_TOKEN=xxx\n",
    "    OPENAI_TOKEN=xxx\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS / SET-UPs\n",
    "\n",
    "setup is done for logger and database dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n",
      "Requirement already satisfied: langchain==0.3.15 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.3.15)\n",
      "Requirement already satisfied: transformers==4.48.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.48.1)\n",
      "Requirement already satisfied: torch==2.5.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.5.1)\n",
      "Requirement already satisfied: langchain-community==0.3.15 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.3.15)\n",
      "Requirement already satisfied: langchain-experimental==0.3.4 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.3.4)\n",
      "Requirement already satisfied: pandas==2.2.3 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: langchain-huggingface==0.1.2 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: pydantic==2.10.5 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.10.5)\n",
      "Requirement already satisfied: accelerate==1.3.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: llama-cpp-python==0.3.6 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.27.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (0.3.31)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain==0.3.15->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: filelock in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from transformers==4.48.1->-r requirements.txt (line 2)) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from transformers==4.48.1->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from transformers==4.48.1->-r requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from transformers==4.48.1->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from transformers==4.48.1->-r requirements.txt (line 2)) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from transformers==4.48.1->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain-community==0.3.15->-r requirements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain-community==0.3.15->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain-community==0.3.15->-r requirements.txt (line 4)) (2.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pandas==2.2.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pandas==2.2.3->-r requirements.txt (line 6)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pandas==2.2.3->-r requirements.txt (line 6)) (2025.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain-huggingface==0.1.2->-r requirements.txt (line 7)) (3.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pydantic==2.10.5->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pydantic==2.10.5->-r requirements.txt (line 8)) (2.27.2)\n",
      "Requirement already satisfied: psutil in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from accelerate==1.3.0->-r requirements.txt (line 9)) (6.1.1)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from llama-cpp-python==0.3.6->-r requirements.txt (line 10)) (5.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.15->-r requirements.txt (line 1)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.15->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.15->-r requirements.txt (line 1)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.15->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.15->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.15->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.15->-r requirements.txt (line 1)) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.15->-r requirements.txt (line 4)) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.15->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from jinja2->torch==2.5.1->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain==0.3.15->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.15->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.15->-r requirements.txt (line 1)) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.15->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.15->-r requirements.txt (line 1)) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.15->-r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.15->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.15->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.15->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.15->-r requirements.txt (line 1)) (2024.12.14)\n",
      "Requirement already satisfied: scikit-learn in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2->-r requirements.txt (line 7)) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2->-r requirements.txt (line 7)) (1.15.1)\n",
      "Requirement already satisfied: Pillow in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2->-r requirements.txt (line 7)) (11.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.15->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.15->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.15->-r requirements.txt (line 1)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.15->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain==0.3.15->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.15->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2->-r requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/bot/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.15->-r requirements.txt (line 1)) (1.3.1)\n",
      "Package                   Version\n",
      "------------------------- --------------\n",
      "accelerate                1.3.0\n",
      "aiohappyeyeballs          2.4.4\n",
      "aiohttp                   3.11.11\n",
      "aiosignal                 1.3.2\n",
      "annotated-types           0.7.0\n",
      "anyio                     4.8.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.3.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.2.0\n",
      "certifi                   2024.12.14\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.1\n",
      "comm                      0.2.2\n",
      "dataclasses-json          0.6.7\n",
      "debugpy                   1.8.12\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "diskcache                 5.6.3\n",
      "entrypoints               0.4\n",
      "executing                 2.2.0\n",
      "fastjsonschema            2.21.1\n",
      "filelock                  3.17.0\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.5.0\n",
      "fsspec                    2024.12.0\n",
      "greenlet                  3.1.1\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.28.1\n",
      "httpx-sse                 0.4.0\n",
      "huggingface-hub           0.27.1\n",
      "idna                      3.10\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.31.0\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.5\n",
      "joblib                    1.4.2\n",
      "json5                     0.10.0\n",
      "jsonpatch                 1.33\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter_client            7.4.9\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.11.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.4\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "langchain                 0.3.15\n",
      "langchain-community       0.3.15\n",
      "langchain-core            0.3.31\n",
      "langchain-experimental    0.3.4\n",
      "langchain-huggingface     0.1.2\n",
      "langchain-text-splitters  0.3.5\n",
      "langsmith                 0.3.1\n",
      "llama_cpp_python          0.3.6\n",
      "MarkupSafe                3.0.2\n",
      "marshmallow               3.25.1\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.1.0\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.1.0\n",
      "mypy-extensions           1.0.0\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.5\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "notebook                  7.3.2\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.26.4\n",
      "nvidia-cublas-cu12        12.4.5.8\n",
      "nvidia-cuda-cupti-cu12    12.4.127\n",
      "nvidia-cuda-nvrtc-cu12    12.4.127\n",
      "nvidia-cuda-runtime-cu12  12.4.127\n",
      "nvidia-cudnn-cu12         9.1.0.70\n",
      "nvidia-cufft-cu12         11.2.1.3\n",
      "nvidia-curand-cu12        10.3.5.147\n",
      "nvidia-cusolver-cu12      11.6.1.9\n",
      "nvidia-cusparse-cu12      12.3.1.170\n",
      "nvidia-nccl-cu12          2.21.5\n",
      "nvidia-nvjitlink-cu12     12.4.127\n",
      "nvidia-nvtx-cu12          12.4.127\n",
      "orjson                    3.10.15\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pillow                    11.1.0\n",
      "pip                       24.3.1\n",
      "platformdirs              4.3.6\n",
      "prometheus_client         0.21.1\n",
      "prompt_toolkit            3.0.50\n",
      "propcache                 0.2.1\n",
      "psutil                    6.1.1\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pycparser                 2.22\n",
      "pydantic                  2.10.5\n",
      "pydantic_core             2.27.2\n",
      "pydantic-settings         2.7.1\n",
      "Pygments                  2.19.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-dotenv             1.0.1\n",
      "python-json-logger        3.2.1\n",
      "pytz                      2024.2\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     24.0.1\n",
      "referencing               0.36.1\n",
      "regex                     2024.11.6\n",
      "requests                  2.32.3\n",
      "requests-toolbelt         1.0.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.22.3\n",
      "safetensors               0.5.2\n",
      "scikit-learn              1.6.1\n",
      "scipy                     1.15.1\n",
      "Send2Trash                1.8.3\n",
      "sentence-transformers     3.3.1\n",
      "setuptools                75.8.0\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "SQLAlchemy                2.0.37\n",
      "stack-data                0.6.3\n",
      "sympy                     1.13.1\n",
      "tenacity                  9.0.0\n",
      "terminado                 0.18.1\n",
      "threadpoolctl             3.5.0\n",
      "tinycss2                  1.4.0\n",
      "tokenizers                0.21.0\n",
      "torch                     2.5.1\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "transformers              4.48.1\n",
      "triton                    3.1.0\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.12.2\n",
      "typing-inspect            0.9.0\n",
      "tzdata                    2025.1\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.45.1\n",
      "yarl                      1.18.3\n",
      "zstandard                 0.23.0\n"
     ]
    }
   ],
   "source": [
    "! conda activate myprojects # or replace with your desired environemnt name\n",
    "! pip install -r requirements.txt\n",
    "! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the models, example:\n",
    "# more info here:\n",
    "# https://huggingface.co/bartowski/Mistral-7B-Instruct-v0.3-GGUF\n",
    "# https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF\n",
    "\n",
    "# NOTE: comment this out if downloaded! no download checks in place yet!\n",
    "# !huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF mistral-7b-instruct-v0.2.Q4_K_M.gguf --local-dir . --local-dir ./models\n",
    "# !huggingface-cli download bartowski/Mistral-7B-Instruct-v0.3-GGUF --include \"Mistral-7B-Instruct-v0.3-Q4_K_M.gguf\" --local-dir ./models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_MODEL_PATH: ./models/mistral-7B-Instruct-v0.3-Q6_K.gguf\n",
      "DATABASE_PATH: data.db\n",
      "DATABASE_URL: sqlite:///data.db\n",
      "TRANSACTION_CSV: data.csv\n",
      "CLIENT_INFO_CSV: clients.csv\n",
      "DEFAULT_CHAT_OUTPUT_FILEPATH: chat_report.txt\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "from typing import Any, List, Optional, Tuple, Type, Union\n",
    "from llama_cpp import Llama\n",
    "\n",
    "from langchain_experimental.sql import SQLDatabaseChain, SQLDatabaseSequentialChain\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.schema.cache import BaseCache\n",
    "from langchain.callbacks.base import Callbacks\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import BasePromptTemplate, PromptTemplate\n",
    "from pydantic import Field\n",
    "\n",
    "from classes import GracefulSQLDatabaseChain\n",
    "from mydatabase import initialize_database\n",
    "from utils import BenchmarkReport, truncate_conversation_history\n",
    "from my_logger import setup_logger\n",
    "from myprompts import ALL_PROMPT_STRINGS, DEFAULT_SQLITE_PROMPT_TEMPLATE, prompt_template_generator, _sqlite_prompt1, _sqlite_prompt2, _sqlite_prompt3\n",
    "import myprompts\n",
    "from configs import DATABASE_PATH, DATABASE_URL, DEFAULT_CHAT_OUTPUT_FILEPATH, DEFAULT_MODEL_PATH\n",
    "\n",
    "\n",
    "# Load the model\n",
    "from main import load_local_model, DEFAULT_CONTEXT_WINDOW_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing database 'data.db' has been deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 14:43:05,035 - global - INFO - Loaded data from data.csv into 'transactions' table.\n",
      "2025-01-25 14:43:05,042 - global - INFO - Loaded data from clients.csv into 'clients' table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from data.csv has been successfully loaded into 'transactions' table.\n",
      "Data from clients.csv has been successfully loaded into 'clients' table.\n"
     ]
    }
   ],
   "source": [
    "from main import test_database_context\n",
    "\n",
    "\n",
    "logger = setup_logger(\"jupyter_notebook\", \"jupyter.log\", level=logging.INFO)\n",
    "\n",
    "if os.path.exists(DATABASE_PATH):\n",
    "    os.remove(DATABASE_PATH)\n",
    "    print(f\"Existing database '{DATABASE_PATH}' has been deleted.\")\n",
    "# Reinitialize the database\n",
    "initialize_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step: Build > Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import CustomLlamaLLM\n",
    "from main import load_database_connection\n",
    "from main import create_sql_llm_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model from local storage and wrap it with subclass of langchain's `LLM` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 29 key-value pairs and 291 tensors from ./models/mistral-7B-Instruct-v0.3-Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Mistral-7B-Instruct-v0.3\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 32768\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32768]   = [\"<unk>\", \"<s>\", \"</s>\", \"[INST]\", \"[...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32768]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32768]   = [2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  25:                      quantize.imatrix.file str              = /models/Mistral-7B-Instruct-v0.3-GGUF...\n",
      "llama_model_loader: - kv  26:                   quantize.imatrix.dataset str              = /training_data/calibration_data.txt\n",
      "llama_model_loader: - kv  27:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  28:              quantize.imatrix.chunks_count i32              = 228\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: control token:    468 '[control_466]' is not marked as EOG\n",
      "llm_load_vocab: control token:    464 '[control_462]' is not marked as EOG\n",
      "llm_load_vocab: control token:    727 '[control_725]' is not marked as EOG\n",
      "llm_load_vocab: control token:    343 '[control_341]' is not marked as EOG\n",
      "llm_load_vocab: control token:    603 '[control_601]' is not marked as EOG\n",
      "llm_load_vocab: control token:    332 '[control_330]' is not marked as EOG\n",
      "llm_load_vocab: control token:     34 '[control_32]' is not marked as EOG\n",
      "llm_load_vocab: control token:    412 '[control_410]' is not marked as EOG\n",
      "llm_load_vocab: control token:    675 '[control_673]' is not marked as EOG\n",
      "llm_load_vocab: control token:    177 '[control_175]' is not marked as EOG\n",
      "llm_load_vocab: control token:    434 '[control_432]' is not marked as EOG\n",
      "llm_load_vocab: control token:    166 '[control_164]' is not marked as EOG\n",
      "llm_load_vocab: control token:    199 '[control_197]' is not marked as EOG\n",
      "llm_load_vocab: control token:    252 '[control_250]' is not marked as EOG\n",
      "llm_load_vocab: control token:    742 '[control_740]' is not marked as EOG\n",
      "llm_load_vocab: control token:    611 '[control_609]' is not marked as EOG\n",
      "llm_load_vocab: control token:    573 '[control_571]' is not marked as EOG\n",
      "llm_load_vocab: control token:    455 '[control_453]' is not marked as EOG\n",
      "llm_load_vocab: control token:    701 '[control_699]' is not marked as EOG\n",
      "llm_load_vocab: control token:    583 '[control_581]' is not marked as EOG\n",
      "llm_load_vocab: control token:    433 '[control_431]' is not marked as EOG\n",
      "llm_load_vocab: control token:    301 '[control_299]' is not marked as EOG\n",
      "llm_load_vocab: control token:    617 '[control_615]' is not marked as EOG\n",
      "llm_load_vocab: control token:    536 '[control_534]' is not marked as EOG\n",
      "llm_load_vocab: control token:    285 '[control_283]' is not marked as EOG\n",
      "llm_load_vocab: control token:    376 '[control_374]' is not marked as EOG\n",
      "llm_load_vocab: control token:     79 '[control_77]' is not marked as EOG\n",
      "llm_load_vocab: control token:    671 '[control_669]' is not marked as EOG\n",
      "llm_load_vocab: control token:    391 '[control_389]' is not marked as EOG\n",
      "llm_load_vocab: control token:    174 '[control_172]' is not marked as EOG\n",
      "llm_load_vocab: control token:    708 '[control_706]' is not marked as EOG\n",
      "llm_load_vocab: control token:    729 '[control_727]' is not marked as EOG\n",
      "llm_load_vocab: control token:    311 '[control_309]' is not marked as EOG\n",
      "llm_load_vocab: control token:    384 '[control_382]' is not marked as EOG\n",
      "llm_load_vocab: control token:    766 '[control_764]' is not marked as EOG\n",
      "llm_load_vocab: control token:     94 '[control_92]' is not marked as EOG\n",
      "llm_load_vocab: control token:    304 '[control_302]' is not marked as EOG\n",
      "llm_load_vocab: control token:    197 '[control_195]' is not marked as EOG\n",
      "llm_load_vocab: control token:     17 '[control_15]' is not marked as EOG\n",
      "llm_load_vocab: control token:    604 '[control_602]' is not marked as EOG\n",
      "llm_load_vocab: control token:    576 '[control_574]' is not marked as EOG\n",
      "llm_load_vocab: control token:    359 '[control_357]' is not marked as EOG\n",
      "llm_load_vocab: control token:    302 '[control_300]' is not marked as EOG\n",
      "llm_load_vocab: control token:    453 '[control_451]' is not marked as EOG\n",
      "llm_load_vocab: control token:    374 '[control_372]' is not marked as EOG\n",
      "llm_load_vocab: control token:    207 '[control_205]' is not marked as EOG\n",
      "llm_load_vocab: control token:    739 '[control_737]' is not marked as EOG\n",
      "llm_load_vocab: control token:    689 '[control_687]' is not marked as EOG\n",
      "llm_load_vocab: control token:    335 '[control_333]' is not marked as EOG\n",
      "llm_load_vocab: control token:    485 '[control_483]' is not marked as EOG\n",
      "llm_load_vocab: control token:    283 '[control_281]' is not marked as EOG\n",
      "llm_load_vocab: control token:    249 '[control_247]' is not marked as EOG\n",
      "llm_load_vocab: control token:    752 '[control_750]' is not marked as EOG\n",
      "llm_load_vocab: control token:    330 '[control_328]' is not marked as EOG\n",
      "llm_load_vocab: control token:    635 '[control_633]' is not marked as EOG\n",
      "llm_load_vocab: control token:    161 '[control_159]' is not marked as EOG\n",
      "llm_load_vocab: control token:    731 '[control_729]' is not marked as EOG\n",
      "llm_load_vocab: control token:    631 '[control_629]' is not marked as EOG\n",
      "llm_load_vocab: control token:    323 '[control_321]' is not marked as EOG\n",
      "llm_load_vocab: control token:     48 '[control_46]' is not marked as EOG\n",
      "llm_load_vocab: control token:    544 '[control_542]' is not marked as EOG\n",
      "llm_load_vocab: control token:    687 '[control_685]' is not marked as EOG\n",
      "llm_load_vocab: control token:    463 '[control_461]' is not marked as EOG\n",
      "llm_load_vocab: control token:     47 '[control_45]' is not marked as EOG\n",
      "llm_load_vocab: control token:     86 '[control_84]' is not marked as EOG\n",
      "llm_load_vocab: control token:    331 '[control_329]' is not marked as EOG\n",
      "llm_load_vocab: control token:     13 '[control_11]' is not marked as EOG\n",
      "llm_load_vocab: control token:    760 '[control_758]' is not marked as EOG\n",
      "llm_load_vocab: control token:    612 '[control_610]' is not marked as EOG\n",
      "llm_load_vocab: control token:    473 '[control_471]' is not marked as EOG\n",
      "llm_load_vocab: control token:    601 '[control_599]' is not marked as EOG\n",
      "llm_load_vocab: control token:    146 '[control_144]' is not marked as EOG\n",
      "llm_load_vocab: control token:    734 '[control_732]' is not marked as EOG\n",
      "llm_load_vocab: control token:    141 '[control_139]' is not marked as EOG\n",
      "llm_load_vocab: control token:    138 '[control_136]' is not marked as EOG\n",
      "llm_load_vocab: control token:     61 '[control_59]' is not marked as EOG\n",
      "llm_load_vocab: control token:     46 '[control_44]' is not marked as EOG\n",
      "llm_load_vocab: control token:    173 '[control_171]' is not marked as EOG\n",
      "llm_load_vocab: control token:    367 '[control_365]' is not marked as EOG\n",
      "llm_load_vocab: control token:    417 '[control_415]' is not marked as EOG\n",
      "llm_load_vocab: control token:    740 '[control_738]' is not marked as EOG\n",
      "llm_load_vocab: control token:    216 '[control_214]' is not marked as EOG\n",
      "llm_load_vocab: control token:    498 '[control_496]' is not marked as EOG\n",
      "llm_load_vocab: control token:    512 '[control_510]' is not marked as EOG\n",
      "llm_load_vocab: control token:    122 '[control_120]' is not marked as EOG\n",
      "llm_load_vocab: control token:    246 '[control_244]' is not marked as EOG\n",
      "llm_load_vocab: control token:    745 '[control_743]' is not marked as EOG\n",
      "llm_load_vocab: control token:    451 '[control_449]' is not marked as EOG\n",
      "llm_load_vocab: control token:    280 '[control_278]' is not marked as EOG\n",
      "llm_load_vocab: control token:    654 '[control_652]' is not marked as EOG\n",
      "llm_load_vocab: control token:    679 '[control_677]' is not marked as EOG\n",
      "llm_load_vocab: control token:     77 '[control_75]' is not marked as EOG\n",
      "llm_load_vocab: control token:    638 '[control_636]' is not marked as EOG\n",
      "llm_load_vocab: control token:    472 '[control_470]' is not marked as EOG\n",
      "llm_load_vocab: control token:     59 '[control_57]' is not marked as EOG\n",
      "llm_load_vocab: control token:    145 '[control_143]' is not marked as EOG\n",
      "llm_load_vocab: control token:    318 '[control_316]' is not marked as EOG\n",
      "llm_load_vocab: control token:    640 '[control_638]' is not marked as EOG\n",
      "llm_load_vocab: control token:    690 '[control_688]' is not marked as EOG\n",
      "llm_load_vocab: control token:    256 '[control_254]' is not marked as EOG\n",
      "llm_load_vocab: control token:    476 '[control_474]' is not marked as EOG\n",
      "llm_load_vocab: control token:     21 '[control_19]' is not marked as EOG\n",
      "llm_load_vocab: control token:    288 '[control_286]' is not marked as EOG\n",
      "llm_load_vocab: control token:    255 '[control_253]' is not marked as EOG\n",
      "llm_load_vocab: control token:    113 '[control_111]' is not marked as EOG\n",
      "llm_load_vocab: control token:    190 '[control_188]' is not marked as EOG\n",
      "llm_load_vocab: control token:    108 '[control_106]' is not marked as EOG\n",
      "llm_load_vocab: control token:    211 '[control_209]' is not marked as EOG\n",
      "llm_load_vocab: control token:    551 '[control_549]' is not marked as EOG\n",
      "llm_load_vocab: control token:     14 '[control_12]' is not marked as EOG\n",
      "llm_load_vocab: control token:    737 '[control_735]' is not marked as EOG\n",
      "llm_load_vocab: control token:    555 '[control_553]' is not marked as EOG\n",
      "llm_load_vocab: control token:    227 '[control_225]' is not marked as EOG\n",
      "llm_load_vocab: control token:    210 '[control_208]' is not marked as EOG\n",
      "llm_load_vocab: control token:    230 '[control_228]' is not marked as EOG\n",
      "llm_load_vocab: control token:      7 '[/AVAILABLE_TOOLS]' is not marked as EOG\n",
      "llm_load_vocab: control token:     55 '[control_53]' is not marked as EOG\n",
      "llm_load_vocab: control token:    525 '[control_523]' is not marked as EOG\n",
      "llm_load_vocab: control token:    533 '[control_531]' is not marked as EOG\n",
      "llm_load_vocab: control token:    195 '[control_193]' is not marked as EOG\n",
      "llm_load_vocab: control token:    584 '[control_582]' is not marked as EOG\n",
      "llm_load_vocab: control token:    203 '[control_201]' is not marked as EOG\n",
      "llm_load_vocab: control token:    322 '[control_320]' is not marked as EOG\n",
      "llm_load_vocab: control token:    757 '[control_755]' is not marked as EOG\n",
      "llm_load_vocab: control token:    642 '[control_640]' is not marked as EOG\n",
      "llm_load_vocab: control token:    168 '[control_166]' is not marked as EOG\n",
      "llm_load_vocab: control token:    389 '[control_387]' is not marked as EOG\n",
      "llm_load_vocab: control token:    368 '[control_366]' is not marked as EOG\n",
      "llm_load_vocab: control token:    767 '[control_765]' is not marked as EOG\n",
      "llm_load_vocab: control token:    222 '[control_220]' is not marked as EOG\n",
      "llm_load_vocab: control token:    420 '[control_418]' is not marked as EOG\n",
      "llm_load_vocab: control token:    530 '[control_528]' is not marked as EOG\n",
      "llm_load_vocab: control token:    535 '[control_533]' is not marked as EOG\n",
      "llm_load_vocab: control token:    765 '[control_763]' is not marked as EOG\n",
      "llm_load_vocab: control token:    661 '[control_659]' is not marked as EOG\n",
      "llm_load_vocab: control token:     88 '[control_86]' is not marked as EOG\n",
      "llm_load_vocab: control token:    581 '[control_579]' is not marked as EOG\n",
      "llm_load_vocab: control token:    327 '[control_325]' is not marked as EOG\n",
      "llm_load_vocab: control token:    201 '[control_199]' is not marked as EOG\n",
      "llm_load_vocab: control token:    115 '[control_113]' is not marked as EOG\n",
      "llm_load_vocab: control token:    709 '[control_707]' is not marked as EOG\n",
      "llm_load_vocab: control token:    291 '[control_289]' is not marked as EOG\n",
      "llm_load_vocab: control token:    265 '[control_263]' is not marked as EOG\n",
      "llm_load_vocab: control token:    148 '[control_146]' is not marked as EOG\n",
      "llm_load_vocab: control token:    185 '[control_183]' is not marked as EOG\n",
      "llm_load_vocab: control token:    574 '[control_572]' is not marked as EOG\n",
      "llm_load_vocab: control token:    360 '[control_358]' is not marked as EOG\n",
      "llm_load_vocab: control token:    127 '[control_125]' is not marked as EOG\n",
      "llm_load_vocab: control token:    325 '[control_323]' is not marked as EOG\n",
      "llm_load_vocab: control token:    183 '[control_181]' is not marked as EOG\n",
      "llm_load_vocab: control token:    116 '[control_114]' is not marked as EOG\n",
      "llm_load_vocab: control token:    540 '[control_538]' is not marked as EOG\n",
      "llm_load_vocab: control token:    293 '[control_291]' is not marked as EOG\n",
      "llm_load_vocab: control token:    559 '[control_557]' is not marked as EOG\n",
      "llm_load_vocab: control token:    527 '[control_525]' is not marked as EOG\n",
      "llm_load_vocab: control token:    156 '[control_154]' is not marked as EOG\n",
      "llm_load_vocab: control token:    338 '[control_336]' is not marked as EOG\n",
      "llm_load_vocab: control token:    519 '[control_517]' is not marked as EOG\n",
      "llm_load_vocab: control token:    516 '[control_514]' is not marked as EOG\n",
      "llm_load_vocab: control token:     10 '[control_8]' is not marked as EOG\n",
      "llm_load_vocab: control token:      8 '[TOOL_RESULTS]' is not marked as EOG\n",
      "llm_load_vocab: control token:    505 '[control_503]' is not marked as EOG\n",
      "llm_load_vocab: control token:    503 '[control_501]' is not marked as EOG\n",
      "llm_load_vocab: control token:    500 '[control_498]' is not marked as EOG\n",
      "llm_load_vocab: control token:    496 '[control_494]' is not marked as EOG\n",
      "llm_load_vocab: control token:    492 '[control_490]' is not marked as EOG\n",
      "llm_load_vocab: control token:    489 '[control_487]' is not marked as EOG\n",
      "llm_load_vocab: control token:    538 '[control_536]' is not marked as EOG\n",
      "llm_load_vocab: control token:    596 '[control_594]' is not marked as EOG\n",
      "llm_load_vocab: control token:    481 '[control_479]' is not marked as EOG\n",
      "llm_load_vocab: control token:    475 '[control_473]' is not marked as EOG\n",
      "llm_load_vocab: control token:    336 '[control_334]' is not marked as EOG\n",
      "llm_load_vocab: control token:    670 '[control_668]' is not marked as EOG\n",
      "llm_load_vocab: control token:     50 '[control_48]' is not marked as EOG\n",
      "llm_load_vocab: control token:    456 '[control_454]' is not marked as EOG\n",
      "llm_load_vocab: control token:    105 '[control_103]' is not marked as EOG\n",
      "llm_load_vocab: control token:    421 '[control_419]' is not marked as EOG\n",
      "llm_load_vocab: control token:    430 '[control_428]' is not marked as EOG\n",
      "llm_load_vocab: control token:    429 '[control_427]' is not marked as EOG\n",
      "llm_load_vocab: control token:    575 '[control_573]' is not marked as EOG\n",
      "llm_load_vocab: control token:    425 '[control_423]' is not marked as EOG\n",
      "llm_load_vocab: control token:    424 '[control_422]' is not marked as EOG\n",
      "llm_load_vocab: control token:    680 '[control_678]' is not marked as EOG\n",
      "llm_load_vocab: control token:     57 '[control_55]' is not marked as EOG\n",
      "llm_load_vocab: control token:    356 '[control_354]' is not marked as EOG\n",
      "llm_load_vocab: control token:    458 '[control_456]' is not marked as EOG\n",
      "llm_load_vocab: control token:    313 '[control_311]' is not marked as EOG\n",
      "llm_load_vocab: control token:    418 '[control_416]' is not marked as EOG\n",
      "llm_load_vocab: control token:     70 '[control_68]' is not marked as EOG\n",
      "llm_load_vocab: control token:    759 '[control_757]' is not marked as EOG\n",
      "llm_load_vocab: control token:    416 '[control_414]' is not marked as EOG\n",
      "llm_load_vocab: control token:    238 '[control_236]' is not marked as EOG\n",
      "llm_load_vocab: control token:    568 '[control_566]' is not marked as EOG\n",
      "llm_load_vocab: control token:    409 '[control_407]' is not marked as EOG\n",
      "llm_load_vocab: control token:    550 '[control_548]' is not marked as EOG\n",
      "llm_load_vocab: control token:    571 '[control_569]' is not marked as EOG\n",
      "llm_load_vocab: control token:    618 '[control_616]' is not marked as EOG\n",
      "llm_load_vocab: control token:    623 '[control_621]' is not marked as EOG\n",
      "llm_load_vocab: control token:    247 '[control_245]' is not marked as EOG\n",
      "llm_load_vocab: control token:    400 '[control_398]' is not marked as EOG\n",
      "llm_load_vocab: control token:    396 '[control_394]' is not marked as EOG\n",
      "llm_load_vocab: control token:    392 '[control_390]' is not marked as EOG\n",
      "llm_load_vocab: control token:    552 '[control_550]' is not marked as EOG\n",
      "llm_load_vocab: control token:    651 '[control_649]' is not marked as EOG\n",
      "llm_load_vocab: control token:    390 '[control_388]' is not marked as EOG\n",
      "llm_load_vocab: control token:    186 '[control_184]' is not marked as EOG\n",
      "llm_load_vocab: control token:    565 '[control_563]' is not marked as EOG\n",
      "llm_load_vocab: control token:     92 '[control_90]' is not marked as EOG\n",
      "llm_load_vocab: control token:    508 '[control_506]' is not marked as EOG\n",
      "llm_load_vocab: control token:    373 '[control_371]' is not marked as EOG\n",
      "llm_load_vocab: control token:    299 '[control_297]' is not marked as EOG\n",
      "llm_load_vocab: control token:    562 '[control_560]' is not marked as EOG\n",
      "llm_load_vocab: control token:    537 '[control_535]' is not marked as EOG\n",
      "llm_load_vocab: control token:    372 '[control_370]' is not marked as EOG\n",
      "llm_load_vocab: control token:    366 '[control_364]' is not marked as EOG\n",
      "llm_load_vocab: control token:    196 '[control_194]' is not marked as EOG\n",
      "llm_load_vocab: control token:    478 '[control_476]' is not marked as EOG\n",
      "llm_load_vocab: control token:    621 '[control_619]' is not marked as EOG\n",
      "llm_load_vocab: control token:     53 '[control_51]' is not marked as EOG\n",
      "llm_load_vocab: control token:     40 '[control_38]' is not marked as EOG\n",
      "llm_load_vocab: control token:    347 '[control_345]' is not marked as EOG\n",
      "llm_load_vocab: control token:    345 '[control_343]' is not marked as EOG\n",
      "llm_load_vocab: control token:    339 '[control_337]' is not marked as EOG\n",
      "llm_load_vocab: control token:    234 '[control_232]' is not marked as EOG\n",
      "llm_load_vocab: control token:    770 '[control_768]' is not marked as EOG\n",
      "llm_load_vocab: control token:    444 '[control_442]' is not marked as EOG\n",
      "llm_load_vocab: control token:    317 '[control_315]' is not marked as EOG\n",
      "llm_load_vocab: control token:    693 '[control_691]' is not marked as EOG\n",
      "llm_load_vocab: control token:    321 '[control_319]' is not marked as EOG\n",
      "llm_load_vocab: control token:    320 '[control_318]' is not marked as EOG\n",
      "llm_load_vocab: control token:    179 '[control_177]' is not marked as EOG\n",
      "llm_load_vocab: control token:    214 '[control_212]' is not marked as EOG\n",
      "llm_load_vocab: control token:    666 '[control_664]' is not marked as EOG\n",
      "llm_load_vocab: control token:    712 '[control_710]' is not marked as EOG\n",
      "llm_load_vocab: control token:    303 '[control_301]' is not marked as EOG\n",
      "llm_load_vocab: control token:    440 '[control_438]' is not marked as EOG\n",
      "llm_load_vocab: control token:    314 '[control_312]' is not marked as EOG\n",
      "llm_load_vocab: control token:    397 '[control_395]' is not marked as EOG\n",
      "llm_load_vocab: control token:    312 '[control_310]' is not marked as EOG\n",
      "llm_load_vocab: control token:    129 '[control_127]' is not marked as EOG\n",
      "llm_load_vocab: control token:    545 '[control_543]' is not marked as EOG\n",
      "llm_load_vocab: control token:     58 '[control_56]' is not marked as EOG\n",
      "llm_load_vocab: control token:    509 '[control_507]' is not marked as EOG\n",
      "llm_load_vocab: control token:    541 '[control_539]' is not marked as EOG\n",
      "llm_load_vocab: control token:    443 '[control_441]' is not marked as EOG\n",
      "llm_load_vocab: control token:     45 '[control_43]' is not marked as EOG\n",
      "llm_load_vocab: control token:    469 '[control_467]' is not marked as EOG\n",
      "llm_load_vocab: control token:    532 '[control_530]' is not marked as EOG\n",
      "llm_load_vocab: control token:     64 '[control_62]' is not marked as EOG\n",
      "llm_load_vocab: control token:    365 '[control_363]' is not marked as EOG\n",
      "llm_load_vocab: control token:    563 '[control_561]' is not marked as EOG\n",
      "llm_load_vocab: control token:    346 '[control_344]' is not marked as EOG\n",
      "llm_load_vocab: control token:    282 '[control_280]' is not marked as EOG\n",
      "llm_load_vocab: control token:    450 '[control_448]' is not marked as EOG\n",
      "llm_load_vocab: control token:    526 '[control_524]' is not marked as EOG\n",
      "llm_load_vocab: control token:    672 '[control_670]' is not marked as EOG\n",
      "llm_load_vocab: control token:    232 '[control_230]' is not marked as EOG\n",
      "llm_load_vocab: control token:    273 '[control_271]' is not marked as EOG\n",
      "llm_load_vocab: control token:    272 '[control_270]' is not marked as EOG\n",
      "llm_load_vocab: control token:    636 '[control_634]' is not marked as EOG\n",
      "llm_load_vocab: control token:    260 '[control_258]' is not marked as EOG\n",
      "llm_load_vocab: control token:    518 '[control_516]' is not marked as EOG\n",
      "llm_load_vocab: control token:    353 '[control_351]' is not marked as EOG\n",
      "llm_load_vocab: control token:    257 '[control_255]' is not marked as EOG\n",
      "llm_load_vocab: control token:    126 '[control_124]' is not marked as EOG\n",
      "llm_load_vocab: control token:    124 '[control_122]' is not marked as EOG\n",
      "llm_load_vocab: control token:    751 '[control_749]' is not marked as EOG\n",
      "llm_load_vocab: control token:    383 '[control_381]' is not marked as EOG\n",
      "llm_load_vocab: control token:    175 '[control_173]' is not marked as EOG\n",
      "llm_load_vocab: control token:     75 '[control_73]' is not marked as EOG\n",
      "llm_load_vocab: control token:     72 '[control_70]' is not marked as EOG\n",
      "llm_load_vocab: control token:    614 '[control_612]' is not marked as EOG\n",
      "llm_load_vocab: control token:    167 '[control_165]' is not marked as EOG\n",
      "llm_load_vocab: control token:    465 '[control_463]' is not marked as EOG\n",
      "llm_load_vocab: control token:    341 '[control_339]' is not marked as EOG\n",
      "llm_load_vocab: control token:    703 '[control_701]' is not marked as EOG\n",
      "llm_load_vocab: control token:    501 '[control_499]' is not marked as EOG\n",
      "llm_load_vocab: control token:     90 '[control_88]' is not marked as EOG\n",
      "llm_load_vocab: control token:     89 '[control_87]' is not marked as EOG\n",
      "llm_load_vocab: control token:    593 '[control_591]' is not marked as EOG\n",
      "llm_load_vocab: control token:    107 '[control_105]' is not marked as EOG\n",
      "llm_load_vocab: control token:    241 '[control_239]' is not marked as EOG\n",
      "llm_load_vocab: control token:    713 '[control_711]' is not marked as EOG\n",
      "llm_load_vocab: control token:    212 '[control_210]' is not marked as EOG\n",
      "llm_load_vocab: control token:     80 '[control_78]' is not marked as EOG\n",
      "llm_load_vocab: control token:    707 '[control_705]' is not marked as EOG\n",
      "llm_load_vocab: control token:    371 '[control_369]' is not marked as EOG\n",
      "llm_load_vocab: control token:    628 '[control_626]' is not marked as EOG\n",
      "llm_load_vocab: control token:     15 '[control_13]' is not marked as EOG\n",
      "llm_load_vocab: control token:    354 '[control_352]' is not marked as EOG\n",
      "llm_load_vocab: control token:     25 '[control_23]' is not marked as EOG\n",
      "llm_load_vocab: control token:    261 '[control_259]' is not marked as EOG\n",
      "llm_load_vocab: control token:    435 '[control_433]' is not marked as EOG\n",
      "llm_load_vocab: control token:    307 '[control_305]' is not marked as EOG\n",
      "llm_load_vocab: control token:    305 '[control_303]' is not marked as EOG\n",
      "llm_load_vocab: control token:    656 '[control_654]' is not marked as EOG\n",
      "llm_load_vocab: control token:    702 '[control_700]' is not marked as EOG\n",
      "llm_load_vocab: control token:    428 '[control_426]' is not marked as EOG\n",
      "llm_load_vocab: control token:    499 '[control_497]' is not marked as EOG\n",
      "llm_load_vocab: control token:    154 '[control_152]' is not marked as EOG\n",
      "llm_load_vocab: control token:    308 '[control_306]' is not marked as EOG\n",
      "llm_load_vocab: control token:    286 '[control_284]' is not marked as EOG\n",
      "llm_load_vocab: control token:    634 '[control_632]' is not marked as EOG\n",
      "llm_load_vocab: control token:     51 '[control_49]' is not marked as EOG\n",
      "llm_load_vocab: control token:    599 '[control_597]' is not marked as EOG\n",
      "llm_load_vocab: control token:    606 '[control_604]' is not marked as EOG\n",
      "llm_load_vocab: control token:     30 '[control_28]' is not marked as EOG\n",
      "llm_load_vocab: control token:    250 '[control_248]' is not marked as EOG\n",
      "llm_load_vocab: control token:    714 '[control_712]' is not marked as EOG\n",
      "llm_load_vocab: control token:    270 '[control_268]' is not marked as EOG\n",
      "llm_load_vocab: control token:     83 '[control_81]' is not marked as EOG\n",
      "llm_load_vocab: control token:    730 '[control_728]' is not marked as EOG\n",
      "llm_load_vocab: control token:    743 '[control_741]' is not marked as EOG\n",
      "llm_load_vocab: control token:    484 '[control_482]' is not marked as EOG\n",
      "llm_load_vocab: control token:    758 '[control_756]' is not marked as EOG\n",
      "llm_load_vocab: control token:    271 '[control_269]' is not marked as EOG\n",
      "llm_load_vocab: control token:    279 '[control_277]' is not marked as EOG\n",
      "llm_load_vocab: control token:     73 '[control_71]' is not marked as EOG\n",
      "llm_load_vocab: control token:    363 '[control_361]' is not marked as EOG\n",
      "llm_load_vocab: control token:     60 '[control_58]' is not marked as EOG\n",
      "llm_load_vocab: control token:    405 '[control_403]' is not marked as EOG\n",
      "llm_load_vocab: control token:    220 '[control_218]' is not marked as EOG\n",
      "llm_load_vocab: control token:    436 '[control_434]' is not marked as EOG\n",
      "llm_load_vocab: control token:     27 '[control_25]' is not marked as EOG\n",
      "llm_load_vocab: control token:    652 '[control_650]' is not marked as EOG\n",
      "llm_load_vocab: control token:    646 '[control_644]' is not marked as EOG\n",
      "llm_load_vocab: control token:    395 '[control_393]' is not marked as EOG\n",
      "llm_load_vocab: control token:    549 '[control_547]' is not marked as EOG\n",
      "llm_load_vocab: control token:     12 '[control_10]' is not marked as EOG\n",
      "llm_load_vocab: control token:    229 '[control_227]' is not marked as EOG\n",
      "llm_load_vocab: control token:    162 '[control_160]' is not marked as EOG\n",
      "llm_load_vocab: control token:    497 '[control_495]' is not marked as EOG\n",
      "llm_load_vocab: control token:     31 '[control_29]' is not marked as EOG\n",
      "llm_load_vocab: control token:     98 '[control_96]' is not marked as EOG\n",
      "llm_load_vocab: control token:    686 '[control_684]' is not marked as EOG\n",
      "llm_load_vocab: control token:      3 '[INST]' is not marked as EOG\n",
      "llm_load_vocab: control token:    155 '[control_153]' is not marked as EOG\n",
      "llm_load_vocab: control token:    470 '[control_468]' is not marked as EOG\n",
      "llm_load_vocab: control token:     69 '[control_67]' is not marked as EOG\n",
      "llm_load_vocab: control token:     93 '[control_91]' is not marked as EOG\n",
      "llm_load_vocab: control token:     71 '[control_69]' is not marked as EOG\n",
      "llm_load_vocab: control token:     11 '[control_9]' is not marked as EOG\n",
      "llm_load_vocab: control token:     43 '[control_41]' is not marked as EOG\n",
      "llm_load_vocab: control token:     22 '[control_20]' is not marked as EOG\n",
      "llm_load_vocab: control token:     35 '[control_33]' is not marked as EOG\n",
      "llm_load_vocab: control token:    706 '[control_704]' is not marked as EOG\n",
      "llm_load_vocab: control token:    511 '[control_509]' is not marked as EOG\n",
      "llm_load_vocab: control token:    491 '[control_489]' is not marked as EOG\n",
      "llm_load_vocab: control token:    324 '[control_322]' is not marked as EOG\n",
      "llm_load_vocab: control token:    655 '[control_653]' is not marked as EOG\n",
      "llm_load_vocab: control token:    117 '[control_115]' is not marked as EOG\n",
      "llm_load_vocab: control token:    665 '[control_663]' is not marked as EOG\n",
      "llm_load_vocab: control token:      9 '[/TOOL_RESULTS]' is not marked as EOG\n",
      "llm_load_vocab: control token:     29 '[control_27]' is not marked as EOG\n",
      "llm_load_vocab: control token:     44 '[control_42]' is not marked as EOG\n",
      "llm_load_vocab: control token:    310 '[control_308]' is not marked as EOG\n",
      "llm_load_vocab: control token:    157 '[control_155]' is not marked as EOG\n",
      "llm_load_vocab: control token:    515 '[control_513]' is not marked as EOG\n",
      "llm_load_vocab: control token:    388 '[control_386]' is not marked as EOG\n",
      "llm_load_vocab: control token:    438 '[control_436]' is not marked as EOG\n",
      "llm_load_vocab: control token:    486 '[control_484]' is not marked as EOG\n",
      "llm_load_vocab: control token:    139 '[control_137]' is not marked as EOG\n",
      "llm_load_vocab: control token:    543 '[control_541]' is not marked as EOG\n",
      "llm_load_vocab: control token:    622 '[control_620]' is not marked as EOG\n",
      "llm_load_vocab: control token:    598 '[control_596]' is not marked as EOG\n",
      "llm_load_vocab: control token:     16 '[control_14]' is not marked as EOG\n",
      "llm_load_vocab: control token:     39 '[control_37]' is not marked as EOG\n",
      "llm_load_vocab: control token:    102 '[control_100]' is not marked as EOG\n",
      "llm_load_vocab: control token:    673 '[control_671]' is not marked as EOG\n",
      "llm_load_vocab: control token:    287 '[control_285]' is not marked as EOG\n",
      "llm_load_vocab: control token:    244 '[control_242]' is not marked as EOG\n",
      "llm_load_vocab: control token:    446 '[control_444]' is not marked as EOG\n",
      "llm_load_vocab: control token:    483 '[control_481]' is not marked as EOG\n",
      "llm_load_vocab: control token:    467 '[control_465]' is not marked as EOG\n",
      "llm_load_vocab: control token:    264 '[control_262]' is not marked as EOG\n",
      "llm_load_vocab: control token:    176 '[control_174]' is not marked as EOG\n",
      "llm_load_vocab: control token:    625 '[control_623]' is not marked as EOG\n",
      "llm_load_vocab: control token:    160 '[control_158]' is not marked as EOG\n",
      "llm_load_vocab: control token:     20 '[control_18]' is not marked as EOG\n",
      "llm_load_vocab: control token:    641 '[control_639]' is not marked as EOG\n",
      "llm_load_vocab: control token:     99 '[control_97]' is not marked as EOG\n",
      "llm_load_vocab: control token:     54 '[control_52]' is not marked as EOG\n",
      "llm_load_vocab: control token:     37 '[control_35]' is not marked as EOG\n",
      "llm_load_vocab: control token:    401 '[control_399]' is not marked as EOG\n",
      "llm_load_vocab: control token:    130 '[control_128]' is not marked as EOG\n",
      "llm_load_vocab: control token:    218 '[control_216]' is not marked as EOG\n",
      "llm_load_vocab: control token:    243 '[control_241]' is not marked as EOG\n",
      "llm_load_vocab: control token:    753 '[control_751]' is not marked as EOG\n",
      "llm_load_vocab: control token:     74 '[control_72]' is not marked as EOG\n",
      "llm_load_vocab: control token:    171 '[control_169]' is not marked as EOG\n",
      "llm_load_vocab: control token:    151 '[control_149]' is not marked as EOG\n",
      "llm_load_vocab: control token:    364 '[control_362]' is not marked as EOG\n",
      "llm_load_vocab: control token:    495 '[control_493]' is not marked as EOG\n",
      "llm_load_vocab: control token:    119 '[control_117]' is not marked as EOG\n",
      "llm_load_vocab: control token:    217 '[control_215]' is not marked as EOG\n",
      "llm_load_vocab: control token:     84 '[control_82]' is not marked as EOG\n",
      "llm_load_vocab: control token:      5 '[TOOL_CALLS]' is not marked as EOG\n",
      "llm_load_vocab: control token:    531 '[control_529]' is not marked as EOG\n",
      "llm_load_vocab: control token:     33 '[control_31]' is not marked as EOG\n",
      "llm_load_vocab: control token:     82 '[control_80]' is not marked as EOG\n",
      "llm_load_vocab: control token:    100 '[control_98]' is not marked as EOG\n",
      "llm_load_vocab: control token:    125 '[control_123]' is not marked as EOG\n",
      "llm_load_vocab: control token:    520 '[control_518]' is not marked as EOG\n",
      "llm_load_vocab: control token:    144 '[control_142]' is not marked as EOG\n",
      "llm_load_vocab: control token:    152 '[control_150]' is not marked as EOG\n",
      "llm_load_vocab: control token:    592 '[control_590]' is not marked as EOG\n",
      "llm_load_vocab: control token:    461 '[control_459]' is not marked as EOG\n",
      "llm_load_vocab: control token:    624 '[control_622]' is not marked as EOG\n",
      "llm_load_vocab: control token:     65 '[control_63]' is not marked as EOG\n",
      "llm_load_vocab: control token:    172 '[control_170]' is not marked as EOG\n",
      "llm_load_vocab: control token:    178 '[control_176]' is not marked as EOG\n",
      "llm_load_vocab: control token:    258 '[control_256]' is not marked as EOG\n",
      "llm_load_vocab: control token:    524 '[control_522]' is not marked as EOG\n",
      "llm_load_vocab: control token:    657 '[control_655]' is not marked as EOG\n",
      "llm_load_vocab: control token:    184 '[control_182]' is not marked as EOG\n",
      "llm_load_vocab: control token:    441 '[control_439]' is not marked as EOG\n",
      "llm_load_vocab: control token:    315 '[control_313]' is not marked as EOG\n",
      "llm_load_vocab: control token:    662 '[control_660]' is not marked as EOG\n",
      "llm_load_vocab: control token:      6 '[AVAILABLE_TOOLS]' is not marked as EOG\n",
      "llm_load_vocab: control token:    517 '[control_515]' is not marked as EOG\n",
      "llm_load_vocab: control token:    194 '[control_192]' is not marked as EOG\n",
      "llm_load_vocab: control token:    447 '[control_445]' is not marked as EOG\n",
      "llm_load_vocab: control token:     52 '[control_50]' is not marked as EOG\n",
      "llm_load_vocab: control token:    718 '[control_716]' is not marked as EOG\n",
      "llm_load_vocab: control token:    692 '[control_690]' is not marked as EOG\n",
      "llm_load_vocab: control token:    290 '[control_288]' is not marked as EOG\n",
      "llm_load_vocab: control token:    763 '[control_761]' is not marked as EOG\n",
      "llm_load_vocab: control token:    362 '[control_360]' is not marked as EOG\n",
      "llm_load_vocab: control token:    200 '[control_198]' is not marked as EOG\n",
      "llm_load_vocab: control token:    204 '[control_202]' is not marked as EOG\n",
      "llm_load_vocab: control token:    722 '[control_720]' is not marked as EOG\n",
      "llm_load_vocab: control token:    351 '[control_349]' is not marked as EOG\n",
      "llm_load_vocab: control token:    349 '[control_347]' is not marked as EOG\n",
      "llm_load_vocab: control token:     38 '[control_36]' is not marked as EOG\n",
      "llm_load_vocab: control token:    134 '[control_132]' is not marked as EOG\n",
      "llm_load_vocab: control token:     67 '[control_65]' is not marked as EOG\n",
      "llm_load_vocab: control token:    239 '[control_237]' is not marked as EOG\n",
      "llm_load_vocab: control token:    570 '[control_568]' is not marked as EOG\n",
      "llm_load_vocab: control token:    253 '[control_251]' is not marked as EOG\n",
      "llm_load_vocab: control token:    221 '[control_219]' is not marked as EOG\n",
      "llm_load_vocab: control token:    664 '[control_662]' is not marked as EOG\n",
      "llm_load_vocab: control token:    225 '[control_223]' is not marked as EOG\n",
      "llm_load_vocab: control token:    226 '[control_224]' is not marked as EOG\n",
      "llm_load_vocab: control token:    553 '[control_551]' is not marked as EOG\n",
      "llm_load_vocab: control token:    242 '[control_240]' is not marked as EOG\n",
      "llm_load_vocab: control token:    633 '[control_631]' is not marked as EOG\n",
      "llm_load_vocab: control token:    580 '[control_578]' is not marked as EOG\n",
      "llm_load_vocab: control token:    245 '[control_243]' is not marked as EOG\n",
      "llm_load_vocab: control token:    620 '[control_618]' is not marked as EOG\n",
      "llm_load_vocab: control token:    191 '[control_189]' is not marked as EOG\n",
      "llm_load_vocab: control token:     87 '[control_85]' is not marked as EOG\n",
      "llm_load_vocab: control token:    189 '[control_187]' is not marked as EOG\n",
      "llm_load_vocab: control token:    542 '[control_540]' is not marked as EOG\n",
      "llm_load_vocab: control token:    548 '[control_546]' is not marked as EOG\n",
      "llm_load_vocab: control token:    558 '[control_556]' is not marked as EOG\n",
      "llm_load_vocab: control token:    560 '[control_558]' is not marked as EOG\n",
      "llm_load_vocab: control token:    564 '[control_562]' is not marked as EOG\n",
      "llm_load_vocab: control token:    410 '[control_408]' is not marked as EOG\n",
      "llm_load_vocab: control token:    566 '[control_564]' is not marked as EOG\n",
      "llm_load_vocab: control token:    649 '[control_647]' is not marked as EOG\n",
      "llm_load_vocab: control token:    414 '[control_412]' is not marked as EOG\n",
      "llm_load_vocab: control token:    567 '[control_565]' is not marked as EOG\n",
      "llm_load_vocab: control token:    569 '[control_567]' is not marked as EOG\n",
      "llm_load_vocab: control token:    761 '[control_759]' is not marked as EOG\n",
      "llm_load_vocab: control token:    408 '[control_406]' is not marked as EOG\n",
      "llm_load_vocab: control token:    579 '[control_577]' is not marked as EOG\n",
      "llm_load_vocab: control token:    147 '[control_145]' is not marked as EOG\n",
      "llm_load_vocab: control token:    236 '[control_234]' is not marked as EOG\n",
      "llm_load_vocab: control token:    588 '[control_586]' is not marked as EOG\n",
      "llm_load_vocab: control token:    292 '[control_290]' is not marked as EOG\n",
      "llm_load_vocab: control token:    591 '[control_589]' is not marked as EOG\n",
      "llm_load_vocab: control token:    645 '[control_643]' is not marked as EOG\n",
      "llm_load_vocab: control token:    140 '[control_138]' is not marked as EOG\n",
      "llm_load_vocab: control token:    422 '[control_420]' is not marked as EOG\n",
      "llm_load_vocab: control token:    595 '[control_593]' is not marked as EOG\n",
      "llm_load_vocab: control token:    597 '[control_595]' is not marked as EOG\n",
      "llm_load_vocab: control token:    754 '[control_752]' is not marked as EOG\n",
      "llm_load_vocab: control token:    159 '[control_157]' is not marked as EOG\n",
      "llm_load_vocab: control token:    344 '[control_342]' is not marked as EOG\n",
      "llm_load_vocab: control token:    393 '[control_391]' is not marked as EOG\n",
      "llm_load_vocab: control token:    691 '[control_689]' is not marked as EOG\n",
      "llm_load_vocab: control token:    608 '[control_606]' is not marked as EOG\n",
      "llm_load_vocab: control token:    663 '[control_661]' is not marked as EOG\n",
      "llm_load_vocab: control token:    613 '[control_611]' is not marked as EOG\n",
      "llm_load_vocab: control token:    340 '[control_338]' is not marked as EOG\n",
      "llm_load_vocab: control token:    616 '[control_614]' is not marked as EOG\n",
      "llm_load_vocab: control token:    719 '[control_717]' is not marked as EOG\n",
      "llm_load_vocab: control token:    521 '[control_519]' is not marked as EOG\n",
      "llm_load_vocab: control token:    619 '[control_617]' is not marked as EOG\n",
      "llm_load_vocab: control token:    523 '[control_521]' is not marked as EOG\n",
      "llm_load_vocab: control token:    626 '[control_624]' is not marked as EOG\n",
      "llm_load_vocab: control token:    695 '[control_693]' is not marked as EOG\n",
      "llm_load_vocab: control token:    637 '[control_635]' is not marked as EOG\n",
      "llm_load_vocab: control token:    235 '[control_233]' is not marked as EOG\n",
      "llm_load_vocab: control token:    659 '[control_657]' is not marked as EOG\n",
      "llm_load_vocab: control token:    268 '[control_266]' is not marked as EOG\n",
      "llm_load_vocab: control token:    406 '[control_404]' is not marked as EOG\n",
      "llm_load_vocab: control token:    735 '[control_733]' is not marked as EOG\n",
      "llm_load_vocab: control token:    398 '[control_396]' is not marked as EOG\n",
      "llm_load_vocab: control token:    674 '[control_672]' is not marked as EOG\n",
      "llm_load_vocab: control token:    684 '[control_682]' is not marked as EOG\n",
      "llm_load_vocab: control token:    462 '[control_460]' is not marked as EOG\n",
      "llm_load_vocab: control token:    382 '[control_380]' is not marked as EOG\n",
      "llm_load_vocab: control token:    697 '[control_695]' is not marked as EOG\n",
      "llm_load_vocab: control token:    698 '[control_696]' is not marked as EOG\n",
      "llm_load_vocab: control token:    699 '[control_697]' is not marked as EOG\n",
      "llm_load_vocab: control token:    688 '[control_686]' is not marked as EOG\n",
      "llm_load_vocab: control token:    704 '[control_702]' is not marked as EOG\n",
      "llm_load_vocab: control token:    705 '[control_703]' is not marked as EOG\n",
      "llm_load_vocab: control token:    205 '[control_203]' is not marked as EOG\n",
      "llm_load_vocab: control token:    726 '[control_724]' is not marked as EOG\n",
      "llm_load_vocab: control token:    180 '[control_178]' is not marked as EOG\n",
      "llm_load_vocab: control token:    716 '[control_714]' is not marked as EOG\n",
      "llm_load_vocab: control token:    590 '[control_588]' is not marked as EOG\n",
      "llm_load_vocab: control token:    454 '[control_452]' is not marked as EOG\n",
      "llm_load_vocab: control token:    728 '[control_726]' is not marked as EOG\n",
      "llm_load_vocab: control token:    738 '[control_736]' is not marked as EOG\n",
      "llm_load_vocab: control token:    744 '[control_742]' is not marked as EOG\n",
      "llm_load_vocab: control token:    403 '[control_401]' is not marked as EOG\n",
      "llm_load_vocab: control token:    764 '[control_762]' is not marked as EOG\n",
      "llm_load_vocab: control token:    676 '[control_674]' is not marked as EOG\n",
      "llm_load_vocab: control token:    756 '[control_754]' is not marked as EOG\n",
      "llm_load_vocab: control token:    380 '[control_378]' is not marked as EOG\n",
      "llm_load_vocab: control token:    319 '[control_317]' is not marked as EOG\n",
      "llm_load_vocab: control token:    600 '[control_598]' is not marked as EOG\n",
      "llm_load_vocab: control token:    297 '[control_295]' is not marked as EOG\n",
      "llm_load_vocab: control token:    259 '[control_257]' is not marked as EOG\n",
      "llm_load_vocab: control token:    639 '[control_637]' is not marked as EOG\n",
      "llm_load_vocab: control token:    529 '[control_527]' is not marked as EOG\n",
      "llm_load_vocab: control token:    101 '[control_99]' is not marked as EOG\n",
      "llm_load_vocab: control token:    522 '[control_520]' is not marked as EOG\n",
      "llm_load_vocab: control token:    723 '[control_721]' is not marked as EOG\n",
      "llm_load_vocab: control token:    254 '[control_252]' is not marked as EOG\n",
      "llm_load_vocab: control token:    513 '[control_511]' is not marked as EOG\n",
      "llm_load_vocab: control token:    667 '[control_665]' is not marked as EOG\n",
      "llm_load_vocab: control token:    267 '[control_265]' is not marked as EOG\n",
      "llm_load_vocab: control token:    732 '[control_730]' is not marked as EOG\n",
      "llm_load_vocab: control token:     24 '[control_22]' is not marked as EOG\n",
      "llm_load_vocab: control token:    650 '[control_648]' is not marked as EOG\n",
      "llm_load_vocab: control token:    528 '[control_526]' is not marked as EOG\n",
      "llm_load_vocab: control token:    749 '[control_747]' is not marked as EOG\n",
      "llm_load_vocab: control token:    721 '[control_719]' is not marked as EOG\n",
      "llm_load_vocab: control token:    103 '[control_101]' is not marked as EOG\n",
      "llm_load_vocab: control token:    294 '[control_292]' is not marked as EOG\n",
      "llm_load_vocab: control token:     41 '[control_39]' is not marked as EOG\n",
      "llm_load_vocab: control token:    133 '[control_131]' is not marked as EOG\n",
      "llm_load_vocab: control token:    188 '[control_186]' is not marked as EOG\n",
      "llm_load_vocab: control token:    276 '[control_274]' is not marked as EOG\n",
      "llm_load_vocab: control token:    644 '[control_642]' is not marked as EOG\n",
      "llm_load_vocab: control token:    648 '[control_646]' is not marked as EOG\n",
      "llm_load_vocab: control token:    459 '[control_457]' is not marked as EOG\n",
      "llm_load_vocab: control token:    112 '[control_110]' is not marked as EOG\n",
      "llm_load_vocab: control token:    300 '[control_298]' is not marked as EOG\n",
      "llm_load_vocab: control token:    206 '[control_204]' is not marked as EOG\n",
      "llm_load_vocab: control token:    121 '[control_119]' is not marked as EOG\n",
      "llm_load_vocab: control token:    750 '[control_748]' is not marked as EOG\n",
      "llm_load_vocab: control token:    131 '[control_129]' is not marked as EOG\n",
      "llm_load_vocab: control token:    474 '[control_472]' is not marked as EOG\n",
      "llm_load_vocab: control token:    685 '[control_683]' is not marked as EOG\n",
      "llm_load_vocab: control token:    251 '[control_249]' is not marked as EOG\n",
      "llm_load_vocab: control token:    402 '[control_400]' is not marked as EOG\n",
      "llm_load_vocab: control token:    281 '[control_279]' is not marked as EOG\n",
      "llm_load_vocab: control token:    192 '[control_190]' is not marked as EOG\n",
      "llm_load_vocab: control token:    387 '[control_385]' is not marked as EOG\n",
      "llm_load_vocab: control token:    587 '[control_585]' is not marked as EOG\n",
      "llm_load_vocab: control token:     66 '[control_64]' is not marked as EOG\n",
      "llm_load_vocab: control token:    394 '[control_392]' is not marked as EOG\n",
      "llm_load_vocab: control token:     49 '[control_47]' is not marked as EOG\n",
      "llm_load_vocab: control token:     42 '[control_40]' is not marked as EOG\n",
      "llm_load_vocab: control token:     32 '[control_30]' is not marked as EOG\n",
      "llm_load_vocab: control token:    399 '[control_397]' is not marked as EOG\n",
      "llm_load_vocab: control token:    448 '[control_446]' is not marked as EOG\n",
      "llm_load_vocab: control token:    479 '[control_477]' is not marked as EOG\n",
      "llm_load_vocab: control token:    493 '[control_491]' is not marked as EOG\n",
      "llm_load_vocab: control token:    736 '[control_734]' is not marked as EOG\n",
      "llm_load_vocab: control token:    348 '[control_346]' is not marked as EOG\n",
      "llm_load_vocab: control token:    193 '[control_191]' is not marked as EOG\n",
      "llm_load_vocab: control token:    231 '[control_229]' is not marked as EOG\n",
      "llm_load_vocab: control token:    609 '[control_607]' is not marked as EOG\n",
      "llm_load_vocab: control token:    213 '[control_211]' is not marked as EOG\n",
      "llm_load_vocab: control token:    128 '[control_126]' is not marked as EOG\n",
      "llm_load_vocab: control token:    118 '[control_116]' is not marked as EOG\n",
      "llm_load_vocab: control token:    369 '[control_367]' is not marked as EOG\n",
      "llm_load_vocab: control token:    630 '[control_628]' is not marked as EOG\n",
      "llm_load_vocab: control token:    755 '[control_753]' is not marked as EOG\n",
      "llm_load_vocab: control token:    747 '[control_745]' is not marked as EOG\n",
      "llm_load_vocab: control token:    289 '[control_287]' is not marked as EOG\n",
      "llm_load_vocab: control token:     26 '[control_24]' is not marked as EOG\n",
      "llm_load_vocab: control token:     63 '[control_61]' is not marked as EOG\n",
      "llm_load_vocab: control token:    284 '[control_282]' is not marked as EOG\n",
      "llm_load_vocab: control token:    164 '[control_162]' is not marked as EOG\n",
      "llm_load_vocab: control token:    404 '[control_402]' is not marked as EOG\n",
      "llm_load_vocab: control token:    506 '[control_504]' is not marked as EOG\n",
      "llm_load_vocab: control token:    123 '[control_121]' is not marked as EOG\n",
      "llm_load_vocab: control token:    237 '[control_235]' is not marked as EOG\n",
      "llm_load_vocab: control token:     62 '[control_60]' is not marked as EOG\n",
      "llm_load_vocab: control token:    510 '[control_508]' is not marked as EOG\n",
      "llm_load_vocab: control token:    233 '[control_231]' is not marked as EOG\n",
      "llm_load_vocab: control token:     68 '[control_66]' is not marked as EOG\n",
      "llm_load_vocab: control token:    487 '[control_485]' is not marked as EOG\n",
      "llm_load_vocab: control token:    471 '[control_469]' is not marked as EOG\n",
      "llm_load_vocab: control token:    415 '[control_413]' is not marked as EOG\n",
      "llm_load_vocab: control token:     78 '[control_76]' is not marked as EOG\n",
      "llm_load_vocab: control token:    610 '[control_608]' is not marked as EOG\n",
      "llm_load_vocab: control token:    137 '[control_135]' is not marked as EOG\n",
      "llm_load_vocab: control token:    539 '[control_537]' is not marked as EOG\n",
      "llm_load_vocab: control token:    658 '[control_656]' is not marked as EOG\n",
      "llm_load_vocab: control token:    158 '[control_156]' is not marked as EOG\n",
      "llm_load_vocab: control token:    585 '[control_583]' is not marked as EOG\n",
      "llm_load_vocab: control token:    215 '[control_213]' is not marked as EOG\n",
      "llm_load_vocab: control token:    554 '[control_552]' is not marked as EOG\n",
      "llm_load_vocab: control token:    762 '[control_760]' is not marked as EOG\n",
      "llm_load_vocab: control token:    717 '[control_715]' is not marked as EOG\n",
      "llm_load_vocab: control token:    228 '[control_226]' is not marked as EOG\n",
      "llm_load_vocab: control token:    442 '[control_440]' is not marked as EOG\n",
      "llm_load_vocab: control token:    494 '[control_492]' is not marked as EOG\n",
      "llm_load_vocab: control token:     97 '[control_95]' is not marked as EOG\n",
      "llm_load_vocab: control token:    683 '[control_681]' is not marked as EOG\n",
      "llm_load_vocab: control token:    629 '[control_627]' is not marked as EOG\n",
      "llm_load_vocab: control token:    725 '[control_723]' is not marked as EOG\n",
      "llm_load_vocab: control token:    432 '[control_430]' is not marked as EOG\n",
      "llm_load_vocab: control token:    477 '[control_475]' is not marked as EOG\n",
      "llm_load_vocab: control token:    355 '[control_353]' is not marked as EOG\n",
      "llm_load_vocab: control token:     36 '[control_34]' is not marked as EOG\n",
      "llm_load_vocab: control token:    534 '[control_532]' is not marked as EOG\n",
      "llm_load_vocab: control token:    120 '[control_118]' is not marked as EOG\n",
      "llm_load_vocab: control token:     28 '[control_26]' is not marked as EOG\n",
      "llm_load_vocab: control token:    306 '[control_304]' is not marked as EOG\n",
      "llm_load_vocab: control token:    407 '[control_405]' is not marked as EOG\n",
      "llm_load_vocab: control token:    696 '[control_694]' is not marked as EOG\n",
      "llm_load_vocab: control token:    274 '[control_272]' is not marked as EOG\n",
      "llm_load_vocab: control token:    142 '[control_140]' is not marked as EOG\n",
      "llm_load_vocab: control token:    136 '[control_134]' is not marked as EOG\n",
      "llm_load_vocab: control token:    309 '[control_307]' is not marked as EOG\n",
      "llm_load_vocab: control token:    423 '[control_421]' is not marked as EOG\n",
      "llm_load_vocab: control token:    724 '[control_722]' is not marked as EOG\n",
      "llm_load_vocab: control token:    262 '[control_260]' is not marked as EOG\n",
      "llm_load_vocab: control token:    419 '[control_417]' is not marked as EOG\n",
      "llm_load_vocab: control token:    329 '[control_327]' is not marked as EOG\n",
      "llm_load_vocab: control token:    427 '[control_425]' is not marked as EOG\n",
      "llm_load_vocab: control token:    370 '[control_368]' is not marked as EOG\n",
      "llm_load_vocab: control token:    266 '[control_264]' is not marked as EOG\n",
      "llm_load_vocab: control token:    710 '[control_708]' is not marked as EOG\n",
      "llm_load_vocab: control token:    602 '[control_600]' is not marked as EOG\n",
      "llm_load_vocab: control token:    277 '[control_275]' is not marked as EOG\n",
      "llm_load_vocab: control token:    298 '[control_296]' is not marked as EOG\n",
      "llm_load_vocab: control token:    378 '[control_376]' is not marked as EOG\n",
      "llm_load_vocab: control token:    198 '[control_196]' is not marked as EOG\n",
      "llm_load_vocab: control token:     76 '[control_74]' is not marked as EOG\n",
      "llm_load_vocab: control token:    607 '[control_605]' is not marked as EOG\n",
      "llm_load_vocab: control token:    682 '[control_680]' is not marked as EOG\n",
      "llm_load_vocab: control token:    333 '[control_331]' is not marked as EOG\n",
      "llm_load_vocab: control token:    660 '[control_658]' is not marked as EOG\n",
      "llm_load_vocab: control token:    163 '[control_161]' is not marked as EOG\n",
      "llm_load_vocab: control token:     95 '[control_93]' is not marked as EOG\n",
      "llm_load_vocab: control token:    377 '[control_375]' is not marked as EOG\n",
      "llm_load_vocab: control token:    223 '[control_221]' is not marked as EOG\n",
      "llm_load_vocab: control token:    326 '[control_324]' is not marked as EOG\n",
      "llm_load_vocab: control token:    111 '[control_109]' is not marked as EOG\n",
      "llm_load_vocab: control token:    187 '[control_185]' is not marked as EOG\n",
      "llm_load_vocab: control token:    678 '[control_676]' is not marked as EOG\n",
      "llm_load_vocab: control token:    514 '[control_512]' is not marked as EOG\n",
      "llm_load_vocab: control token:    431 '[control_429]' is not marked as EOG\n",
      "llm_load_vocab: control token:      4 '[/INST]' is not marked as EOG\n",
      "llm_load_vocab: control token:    342 '[control_340]' is not marked as EOG\n",
      "llm_load_vocab: control token:    594 '[control_592]' is not marked as EOG\n",
      "llm_load_vocab: control token:    768 '[control_766]' is not marked as EOG\n",
      "llm_load_vocab: control token:    143 '[control_141]' is not marked as EOG\n",
      "llm_load_vocab: control token:    445 '[control_443]' is not marked as EOG\n",
      "llm_load_vocab: control token:    165 '[control_163]' is not marked as EOG\n",
      "llm_load_vocab: control token:    439 '[control_437]' is not marked as EOG\n",
      "llm_load_vocab: control token:    181 '[control_179]' is not marked as EOG\n",
      "llm_load_vocab: control token:    352 '[control_350]' is not marked as EOG\n",
      "llm_load_vocab: control token:    643 '[control_641]' is not marked as EOG\n",
      "llm_load_vocab: control token:    182 '[control_180]' is not marked as EOG\n",
      "llm_load_vocab: control token:     19 '[control_17]' is not marked as EOG\n",
      "llm_load_vocab: control token:    269 '[control_267]' is not marked as EOG\n",
      "llm_load_vocab: control token:    677 '[control_675]' is not marked as EOG\n",
      "llm_load_vocab: control token:    615 '[control_613]' is not marked as EOG\n",
      "llm_load_vocab: control token:    170 '[control_168]' is not marked as EOG\n",
      "llm_load_vocab: control token:     56 '[control_54]' is not marked as EOG\n",
      "llm_load_vocab: control token:    582 '[control_580]' is not marked as EOG\n",
      "llm_load_vocab: control token:    700 '[control_698]' is not marked as EOG\n",
      "llm_load_vocab: control token:    561 '[control_559]' is not marked as EOG\n",
      "llm_load_vocab: control token:    381 '[control_379]' is not marked as EOG\n",
      "llm_load_vocab: control token:    647 '[control_645]' is not marked as EOG\n",
      "llm_load_vocab: control token:    437 '[control_435]' is not marked as EOG\n",
      "llm_load_vocab: control token:    507 '[control_505]' is not marked as EOG\n",
      "llm_load_vocab: control token:    490 '[control_488]' is not marked as EOG\n",
      "llm_load_vocab: control token:    586 '[control_584]' is not marked as EOG\n",
      "llm_load_vocab: control token:     23 '[control_21]' is not marked as EOG\n",
      "llm_load_vocab: control token:    452 '[control_450]' is not marked as EOG\n",
      "llm_load_vocab: control token:    605 '[control_603]' is not marked as EOG\n",
      "llm_load_vocab: control token:    426 '[control_424]' is not marked as EOG\n",
      "llm_load_vocab: control token:    769 '[control_767]' is not marked as EOG\n",
      "llm_load_vocab: control token:     81 '[control_79]' is not marked as EOG\n",
      "llm_load_vocab: control token:    386 '[control_384]' is not marked as EOG\n",
      "llm_load_vocab: control token:    627 '[control_625]' is not marked as EOG\n",
      "llm_load_vocab: control token:     18 '[control_16]' is not marked as EOG\n",
      "llm_load_vocab: control token:    741 '[control_739]' is not marked as EOG\n",
      "llm_load_vocab: control token:     96 '[control_94]' is not marked as EOG\n",
      "llm_load_vocab: control token:    502 '[control_500]' is not marked as EOG\n",
      "llm_load_vocab: control token:    482 '[control_480]' is not marked as EOG\n",
      "llm_load_vocab: control token:    480 '[control_478]' is not marked as EOG\n",
      "llm_load_vocab: control token:    557 '[control_555]' is not marked as EOG\n",
      "llm_load_vocab: control token:    263 '[control_261]' is not marked as EOG\n",
      "llm_load_vocab: control token:    668 '[control_666]' is not marked as EOG\n",
      "llm_load_vocab: control token:    466 '[control_464]' is not marked as EOG\n",
      "llm_load_vocab: control token:    334 '[control_332]' is not marked as EOG\n",
      "llm_load_vocab: control token:    413 '[control_411]' is not marked as EOG\n",
      "llm_load_vocab: control token:    572 '[control_570]' is not marked as EOG\n",
      "llm_load_vocab: control token:    295 '[control_293]' is not marked as EOG\n",
      "llm_load_vocab: control token:    150 '[control_148]' is not marked as EOG\n",
      "llm_load_vocab: control token:    275 '[control_273]' is not marked as EOG\n",
      "llm_load_vocab: control token:    748 '[control_746]' is not marked as EOG\n",
      "llm_load_vocab: control token:    135 '[control_133]' is not marked as EOG\n",
      "llm_load_vocab: control token:    357 '[control_355]' is not marked as EOG\n",
      "llm_load_vocab: control token:    577 '[control_575]' is not marked as EOG\n",
      "llm_load_vocab: control token:    578 '[control_576]' is not marked as EOG\n",
      "llm_load_vocab: control token:    556 '[control_554]' is not marked as EOG\n",
      "llm_load_vocab: control token:    375 '[control_373]' is not marked as EOG\n",
      "llm_load_vocab: control token:    589 '[control_587]' is not marked as EOG\n",
      "llm_load_vocab: control token:    202 '[control_200]' is not marked as EOG\n",
      "llm_load_vocab: control token:     85 '[control_83]' is not marked as EOG\n",
      "llm_load_vocab: control token:    278 '[control_276]' is not marked as EOG\n",
      "llm_load_vocab: control token:    169 '[control_167]' is not marked as EOG\n",
      "llm_load_vocab: control token:    208 '[control_206]' is not marked as EOG\n",
      "llm_load_vocab: control token:    488 '[control_486]' is not marked as EOG\n",
      "llm_load_vocab: control token:    337 '[control_335]' is not marked as EOG\n",
      "llm_load_vocab: control token:    733 '[control_731]' is not marked as EOG\n",
      "llm_load_vocab: control token:    109 '[control_107]' is not marked as EOG\n",
      "llm_load_vocab: control token:    547 '[control_545]' is not marked as EOG\n",
      "llm_load_vocab: control token:    350 '[control_348]' is not marked as EOG\n",
      "llm_load_vocab: control token:    132 '[control_130]' is not marked as EOG\n",
      "llm_load_vocab: control token:    114 '[control_112]' is not marked as EOG\n",
      "llm_load_vocab: control token:    248 '[control_246]' is not marked as EOG\n",
      "llm_load_vocab: control token:    328 '[control_326]' is not marked as EOG\n",
      "llm_load_vocab: control token:    104 '[control_102]' is not marked as EOG\n",
      "llm_load_vocab: control token:    449 '[control_447]' is not marked as EOG\n",
      "llm_load_vocab: control token:    711 '[control_709]' is not marked as EOG\n",
      "llm_load_vocab: control token:    715 '[control_713]' is not marked as EOG\n",
      "llm_load_vocab: control token:    358 '[control_356]' is not marked as EOG\n",
      "llm_load_vocab: control token:    746 '[control_744]' is not marked as EOG\n",
      "llm_load_vocab: control token:    385 '[control_383]' is not marked as EOG\n",
      "llm_load_vocab: control token:    720 '[control_718]' is not marked as EOG\n",
      "llm_load_vocab: control token:      2 '</s>' is not marked as EOG\n",
      "llm_load_vocab: control token:    460 '[control_458]' is not marked as EOG\n",
      "llm_load_vocab: control token:    632 '[control_630]' is not marked as EOG\n",
      "llm_load_vocab: control token:    296 '[control_294]' is not marked as EOG\n",
      "llm_load_vocab: control token:    240 '[control_238]' is not marked as EOG\n",
      "llm_load_vocab: control token:    361 '[control_359]' is not marked as EOG\n",
      "llm_load_vocab: control token:    504 '[control_502]' is not marked as EOG\n",
      "llm_load_vocab: control token:    149 '[control_147]' is not marked as EOG\n",
      "llm_load_vocab: control token:      1 '<s>' is not marked as EOG\n",
      "llm_load_vocab: control token:    219 '[control_217]' is not marked as EOG\n",
      "llm_load_vocab: control token:    106 '[control_104]' is not marked as EOG\n",
      "llm_load_vocab: control token:    669 '[control_667]' is not marked as EOG\n",
      "llm_load_vocab: control token:    411 '[control_409]' is not marked as EOG\n",
      "llm_load_vocab: control token:    546 '[control_544]' is not marked as EOG\n",
      "llm_load_vocab: control token:    379 '[control_377]' is not marked as EOG\n",
      "llm_load_vocab: control token:    209 '[control_207]' is not marked as EOG\n",
      "llm_load_vocab: control token:    110 '[control_108]' is not marked as EOG\n",
      "llm_load_vocab: control token:    681 '[control_679]' is not marked as EOG\n",
      "llm_load_vocab: control token:    153 '[control_151]' is not marked as EOG\n",
      "llm_load_vocab: control token:    457 '[control_455]' is not marked as EOG\n",
      "llm_load_vocab: control token:     91 '[control_89]' is not marked as EOG\n",
      "llm_load_vocab: control token:    224 '[control_222]' is not marked as EOG\n",
      "llm_load_vocab: control token:    653 '[control_651]' is not marked as EOG\n",
      "llm_load_vocab: control token:    694 '[control_692]' is not marked as EOG\n",
      "llm_load_vocab: control token:    316 '[control_314]' is not marked as EOG\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 771\n",
      "llm_load_vocab: token to piece cache size = 0.1731 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32768\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 7.25 B\n",
      "llm_load_print_meta: model size       = 5.54 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = Mistral-7B-Instruct-v0.3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 781 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 2 '</s>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q6_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  5671.02 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 16000\n",
      "llama_new_context_with_model: n_ctx_per_seq = 16000\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 1000000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (16000) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 16000, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =  2000.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 2000.00 MiB, K (f16): 1000.00 MiB, V (f16): 1000.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  1063.26 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_data/calibration_data.txt', 'quantize.imatrix.chunks_count': '228', 'quantize.imatrix.file': '/models/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.imatrix', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.pre': 'default', 'llama.context_length': '32768', 'general.name': 'Mistral-7B-Instruct-v0.3', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '18', 'llama.vocab_size': '32768', 'llama.rope.dimension_count': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n",
      "2025-01-25 14:43:07,773 - global - INFO - Model loaded successfully.\n",
      "2025-01-25 14:43:07,774 - global - INFO - [BUILT LLAMA LLM]: \n",
      "        [LLAMA LLM]\n",
      "        model_path: ./models/mistral-7B-Instruct-v0.3-Q6_K.gguf\n",
      "        context_window_size: 16000\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from main import build_llama_llm\n",
    "\n",
    "# Initialize the custom Llama LLM\n",
    "# llama_model = load_local_model(DEFAULT_MODEL_PATH, DEFAULT_CONTEXT_WINDOW_SIZE)\n",
    "# llm = CustomLlamaLLM(llama_model, DEFAULT_CONTEXT_WINDOW_SIZE)\n",
    "\n",
    "#  the two functions above in one call\n",
    "llm = build_llama_llm(\n",
    "    model_path=DEFAULT_MODEL_PATH,\n",
    "    context_window_size=DEFAULT_CONTEXT_WINDOW_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing the database in the setup, load the database from path (this assumes a local sqllite database, but could be extended to use other connectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 14:43:07,787 - global - INFO - Database connected successfully with descriptions.\n",
      "2025-01-25 14:43:07,789 - global - INFO - Reflected Table Info:\n",
      "\n",
      "CREATE TABLE clients (\n",
      "\tclnt_id INTEGER NOT NULL, \n",
      "\tclnt_name VARCHAR NOT NULL, \n",
      "\tPRIMARY KEY (clnt_id)\n",
      ")\n",
      "\n",
      "\n",
      "CREATE TABLE transactions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tclnt_id INTEGER NOT NULL, \n",
      "\tbank_id INTEGER NOT NULL, \n",
      "\tacc_id INTEGER NOT NULL, \n",
      "\ttxn_id INTEGER NOT NULL, \n",
      "\ttxn_date DATETIME NOT NULL, \n",
      "\t\"desc\" VARCHAR, \n",
      "\tamt FLOAT NOT NULL, \n",
      "\tcat VARCHAR, \n",
      "\tmerchant VARCHAR, \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "Table transactions:\n",
      "  id INTEGER\n",
      "  clnt_id INTEGER  # Client ID\n",
      "  bank_id INTEGER  # Bank ID\n",
      "  acc_id INTEGER  # Account ID\n",
      "  txn_id INTEGER  # Transaction ID\n",
      "  txn_date DATETIME  # Transaction date\n",
      "  desc VARCHAR  # Description\n",
      "  amt FLOAT  # Amount\n",
      "  cat VARCHAR  # Category of the transaction\n",
      "  merchant VARCHAR  # Merchant of the transaction\n",
      "\n",
      "Table clients:\n",
      "  clnt_id INTEGER  # Client ID\n",
      "  clnt_name VARCHAR  # Client Name\n"
     ]
    }
   ],
   "source": [
    "# NOTE: the meta data of the tables are loaded using my own custom SQLDatabase subclass implementation as compared to original implementation\n",
    "sql_database = load_database_connection(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a prompt template appropraite for your SQL assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myprompts import ALL_PROMPT_STRINGS, ALL_PROMPT_SUFFIXES, prompt_template_generator, DEFAULT_SQLITE_PROMPT_TEMPLATE\n",
    "\n",
    "# the best prompt template that works so far is the latest one among all the ones i tested (when using mistral-7b-v0.3-Q6-K)\n",
    "# best_prompt_template = prompt_template_generator(ALL_PROMPT_STRINGS[-1], ALL_PROMPT_SUFFIXES[-1])\n",
    "\n",
    "# the same as above\n",
    "best_prompt_template = DEFAULT_SQLITE_PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build phase is complete after building the SQL LLM chain with all the above dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 14:43:07,802 - global - INFO - Banking assistant created successfully.\n"
     ]
    }
   ],
   "source": [
    "from main import DEFAULT_SQL_CHAIN_CLS, DEFAULT_SQLDATABASE_CLS\n",
    "\n",
    "# DEFAULT_SQL_CHAIN_CLS=SQLDatabaseChain  \n",
    "# DEFAULT_SQLDATABASE_CLS=CustomizableSQLDatabase  \n",
    "\n",
    "llm_chain = create_sql_llm_chain(\n",
    "    database=sql_database,\n",
    "    llm=llm,\n",
    "    prompt=best_prompt_template, \n",
    "    database_chain_cls=DEFAULT_SQL_CHAIN_CLS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we finally run the LLM + Database = SQL LLM Chain (and time the execution as well), this assumes a pre-defined set of questions.\n",
    "Order matters! This is because conversation history is preserved in the LLM context window in sequential manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the LLM with a pre-defined set of questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 14:43:07,811 - global - INFO - Simulated Question: How many rows are in the 'transactions' table?\n",
      "/home/bot/personal_proj/moneylion-ml-assessment/main.py:297: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm_chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to the Banking Assistant!\n",
      "Type your natural language request below, or type 'exit' to quit.\n",
      "\n",
      "Simulated Question: How many rows are in the 'transactions' table?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many rows are in the 'transactions' table?\n",
      "SQLQuery:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  2150 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  215414.24 ms /  2161 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 167 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   167 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   34728.61 ms /   176 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 2175 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mSELECT COUNT(*) FROM transactions;\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(257063,)]\u001b[0m\n",
      "Answer:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  2175 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  286838.73 ms /  2194 tokens\n",
      "2025-01-25 14:52:04,867 - global - INFO - llm response: There are 257,063 rows in the 'transactions' table.\n",
      "2025-01-25 14:52:04,869 - global - INFO - Simulated Question: Can you filter for transactions with merchant '1INFINITE'?\n",
      "Llama.generate: 2133 prefix-match hit, remaining 19 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThere are 257,063 rows in the 'transactions' table.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Query Result:\n",
      "There are 257,063 rows in the 'transactions' table.\n",
      "\n",
      "Simulated Question: Can you filter for transactions with merchant '1INFINITE'?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Can you filter for transactions with merchant '1INFINITE'?\n",
      "SQLQuery:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    19 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   12989.24 ms /    44 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 181 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   181 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   23743.14 ms /   198 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 2626 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mSELECT * FROM transactions WHERE merchant='1INFINITE' LIMIT 5;\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(4, 28, 1, 1, 108, '2023-07-25 00:00:00', '1INFINITELOOP@ 07/25 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA', 59.1, 'Shops', '1INFINITE'), (5, 28, 1, 1, 136, '2023-08-14 00:00:00', '1INFINITELOOP@ 08/14 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA', 4.924, 'Shops', '1INFINITE'), (6, 28, 1, 1, 86, '2023-08-21 00:00:00', '1INFINITELOOP@ 08/20 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA', 98.5, 'Shops', '1INFINITE'), (7, 28, 1, 1, 43, '2023-08-21 00:00:00', '1INFINITELOOP@ 08/19 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA', 59.1, 'Shops', '1INFINITE'), (8, 28, 1, 1, 119, '2023-08-14 00:00:00', '1INFINITELOOP@ 08/13 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA', 59.1, 'Shops', '1INFINITE')]\u001b[0m\n",
      "Answer:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  2626 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  282791.73 ms /  2639 tokens\n",
      "2025-01-25 14:57:24,448 - global - INFO - llm response: There are 5 transactions with merchant '1INFINITE'.\n",
      "2025-01-25 14:57:24,450 - global - INFO - Simulated Question: How much did Julia Johnson spend last week?\n",
      "Llama.generate: 2133 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThere are 5 transactions with merchant '1INFINITE'.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Query Result:\n",
      "There are 5 transactions with merchant '1INFINITE'.\n",
      "\n",
      "Simulated Question: How much did Julia Johnson spend last week?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How much did Julia Johnson spend last week?\n",
      "SQLQuery:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    14 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    65 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   13841.41 ms /    79 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 220 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   220 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    35 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   27101.50 ms /   255 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 2200 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mSELECT SUM(amt) FROM transactions WHERE clnt_id = (SELECT clnt_id FROM clients WHERE clnt_name = 'Julia Johnson');\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(5747.736,)]\u001b[0m\n",
      "Answer:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  2200 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  219142.60 ms /  2216 tokens\n",
      "2025-01-25 15:01:44,615 - global - INFO - llm response: Julia Johnson spent 5747.74 last week.\n",
      "2025-01-25 15:01:44,618 - global - INFO - Simulated Question: How much did clnt_id=6 spend last week?\n",
      "Llama.generate: 2136 prefix-match hit, remaining 15 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mJulia Johnson spent 5747.74 last week.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Query Result:\n",
      "Julia Johnson spent 5747.74 last week.\n",
      "\n",
      "Simulated Question: How much did clnt_id=6 spend last week?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How much did clnt_id=6 spend last week?\n",
      "SQLQuery:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    15 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    9568.31 ms /    47 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 188 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   188 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   26201.98 ms /   220 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 2194 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mSELECT SUM(amt) FROM transactions WHERE clnt_id = 6 AND txn_date >= DATE('now', 'last week');\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(None,)]\u001b[0m\n",
      "Answer:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  2194 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  224529.53 ms /  2208 tokens\n",
      "2025-01-25 15:06:05,003 - global - INFO - llm response: Clnt_id 6 did not have any transactions last week.\n",
      "2025-01-25 15:06:05,005 - global - INFO - Simulated Question: What is the amount Julia Johnson have spent on Uber in the last 5 months?\n",
      "Llama.generate: 2133 prefix-match hit, remaining 23 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mClnt_id 6 did not have any transactions last week.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Query Result:\n",
      "Clnt_id 6 did not have any transactions last week.\n",
      "\n",
      "Simulated Question: What is the amount Julia Johnson have spent on Uber in the last 5 months?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "What is the amount Julia Johnson have spent on Uber in the last 5 months?\n",
      "SQLQuery:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    23 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    60 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   15962.74 ms /    83 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 216 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   216 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   25547.85 ms /   250 tokens\n",
      "Llama.generate: 1 prefix-match hit, remaining 2208 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mSELECT SUM(amt) FROM transactions WHERE clnt_id IN (SELECT clnt_id FROM clients WHERE clnt_name='Julia Johnson');\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(5747.736,)]\u001b[0m\n",
      "Answer:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  212478.61 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  2208 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  217768.74 ms /  2232 tokens\n",
      "2025-01-25 15:10:24,370 - global - INFO - llm response: Julia Johnson has spent 5747.74 on Uber in the last 5 months.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mJulia Johnson has spent 5747.74 on Uber in the last 5 months.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Query Result:\n",
      "Julia Johnson has spent 5747.74 on Uber in the last 5 months.\n"
     ]
    }
   ],
   "source": [
    "# Simulate user queries to the assistant\n",
    "from configs import BENCHMARK_QUES_SET\n",
    "from main import chat_loop\n",
    "\n",
    "# BENCHMARK_QUES_SET=[\n",
    "#     \"How many rows are in the 'transactions' table?\",\n",
    "#     \"Can you filter for transactions with merchant '1INFINITE'?\",\n",
    "#     \"How much did Julia Johnson spend last week?\",\n",
    "#     \"How much did clnt_id=6 spend last week?\",\n",
    "#     \"What is the amount Julia Johnson have spent on Uber in the last 5 months?\"\n",
    "# ]\n",
    "\n",
    "# NOTE: you can replace this with your own pre-defined set of questions \n",
    "questions: List[str] = BENCHMARK_QUES_SET\n",
    "\n",
    "# NOTE: the llm_chain has been configured with verbose=True hence the full trace of the internal tokens generated\n",
    "# NOTE: this is not a simple chat loop,  it has try except mechanisms in place in case the SQL LLM chain incurs a SQL exception error due to invalid SQL query syntax\n",
    "# NOTE: the core of the NL2SQL2NL LLM assistant system, do refer to the code in `main.py` for the code\n",
    "chat_loop(\n",
    "    llm_chain = llm_chain, \n",
    "    prompt_template = best_prompt_template, \n",
    "    simulated = True, \n",
    "    questions = questions,\n",
    "    output_file = None,\n",
    "    use_memory = False, \n",
    "    context_window_size = DEFAULT_CONTEXT_WINDOW_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To real a real-time session as though a User talking to the LLM. Input \"exit\" to exit the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: uncomment to enter the chat loop\n",
    "\n",
    "# chat_loop(\n",
    "#     llm_chain = llm_chain, \n",
    "#     prompt_template = best_prompt_template, \n",
    "#     simulated = False, \n",
    "#     questions = [],\n",
    "#     output_file = None,\n",
    "#     use_memory = False, \n",
    "#     context_window_size = DEFAULT_CONTEXT_WINDOW_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the main loop with minimal code\n",
    "\n",
    "running the chat loop as though you are speaking to the SQL DB Chain LLM in real-time, \n",
    "<br>\n",
    "**type \"exit\" to exit the loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from main import main_run_loop\n",
    "# main_run_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USAGE with CLI on pure python scripts\n",
    "\n",
    "**NOTE: --simulate and --benchmark cannot be used together. The script will throw an error if both are provided**\n",
    "\n",
    "**NOTE: it is recommended to be ran in a terminal shell for complete logs(e.g. bash)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bot/personal_proj/moneylion-ml-assessment/main.py:60: LangChainDeprecationWarning: Importing SQLDatabase from langchain is deprecated. Please replace deprecated imports:\n",
      "\n",
      ">> from langchain import SQLDatabase\n",
      "\n",
      "with new imports of:\n",
      "\n",
      ">> from langchain_community.utilities import SQLDatabase\n",
      "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
      "  from langchain.sql_database import SQLDatabase\n",
      "/home/bot/personal_proj/moneylion-ml-assessment/classes.py:9: LangChainDeprecationWarning: Importing SQLDatabase from langchain is deprecated. Please replace deprecated imports:\n",
      "\n",
      ">> from langchain import SQLDatabase\n",
      "\n",
      "with new imports of:\n",
      "\n",
      ">> from langchain_community.utilities import SQLDatabase\n",
      "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
      "  from langchain.sql_database import SQLDatabase\n",
      "DEFAULT_MODEL_PATH: ./models/mistral-7B-Instruct-v0.3-Q6_K.gguf\n",
      "DATABASE_PATH: data.db\n",
      "DATABASE_URL: sqlite:///data.db\n",
      "TRANSACTION_CSV: data.csv\n",
      "CLIENT_INFO_CSV: clients.csv\n",
      "DEFAULT_CHAT_OUTPUT_FILEPATH: chat_report.txt\n",
      "Existing database 'data.db' has been deleted.\n",
      "Data from data.csv has been successfully loaded into 'transactions' table.\n",
      "2025-01-25 15:10:32,798 - global - INFO - Loaded data from data.csv into 'transactions' table.\n",
      "Data from clients.csv has been successfully loaded into 'clients' table.\n",
      "2025-01-25 15:10:32,805 - global - INFO - Loaded data from clients.csv into 'clients' table.\n",
      "2025-01-25 15:10:32,805 - global - INFO - [MODE]: BENCHMARK=False, SIMULATE=False, MEMORY=False\n",
      "llama_model_loader: loaded meta data with 29 key-value pairs and 291 tensors from ./models/mistral-7B-Instruct-v0.3-Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Mistral-7B-Instruct-v0.3\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 32768\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32768]   = [\"<unk>\", \"<s>\", \"</s>\", \"[INST]\", \"[...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32768]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32768]   = [2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  25:                      quantize.imatrix.file str              = /models/Mistral-7B-Instruct-v0.3-GGUF...\n",
      "llama_model_loader: - kv  26:                   quantize.imatrix.dataset str              = /training_data/calibration_data.txt\n",
      "llama_model_loader: - kv  27:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  28:              quantize.imatrix.chunks_count i32              = 228\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: control token:    468 '[control_466]' is not marked as EOG\n",
      "llm_load_vocab: control token:    464 '[control_462]' is not marked as EOG\n",
      "llm_load_vocab: control token:    727 '[control_725]' is not marked as EOG\n",
      "llm_load_vocab: control token:    343 '[control_341]' is not marked as EOG\n",
      "llm_load_vocab: control token:    603 '[control_601]' is not marked as EOG\n",
      "llm_load_vocab: control token:    332 '[control_330]' is not marked as EOG\n",
      "llm_load_vocab: control token:     34 '[control_32]' is not marked as EOG\n",
      "llm_load_vocab: control token:    412 '[control_410]' is not marked as EOG\n",
      "llm_load_vocab: control token:    675 '[control_673]' is not marked as EOG\n",
      "llm_load_vocab: control token:    177 '[control_175]' is not marked as EOG\n",
      "llm_load_vocab: control token:    434 '[control_432]' is not marked as EOG\n",
      "llm_load_vocab: control token:    166 '[control_164]' is not marked as EOG\n",
      "llm_load_vocab: control token:    199 '[control_197]' is not marked as EOG\n",
      "llm_load_vocab: control token:    252 '[control_250]' is not marked as EOG\n",
      "llm_load_vocab: control token:    742 '[control_740]' is not marked as EOG\n",
      "llm_load_vocab: control token:    611 '[control_609]' is not marked as EOG\n",
      "llm_load_vocab: control token:    573 '[control_571]' is not marked as EOG\n",
      "llm_load_vocab: control token:    455 '[control_453]' is not marked as EOG\n",
      "llm_load_vocab: control token:    701 '[control_699]' is not marked as EOG\n",
      "llm_load_vocab: control token:    583 '[control_581]' is not marked as EOG\n",
      "llm_load_vocab: control token:    433 '[control_431]' is not marked as EOG\n",
      "llm_load_vocab: control token:    301 '[control_299]' is not marked as EOG\n",
      "llm_load_vocab: control token:    617 '[control_615]' is not marked as EOG\n",
      "llm_load_vocab: control token:    536 '[control_534]' is not marked as EOG\n",
      "llm_load_vocab: control token:    285 '[control_283]' is not marked as EOG\n",
      "llm_load_vocab: control token:    376 '[control_374]' is not marked as EOG\n",
      "llm_load_vocab: control token:     79 '[control_77]' is not marked as EOG\n",
      "llm_load_vocab: control token:    671 '[control_669]' is not marked as EOG\n",
      "llm_load_vocab: control token:    391 '[control_389]' is not marked as EOG\n",
      "llm_load_vocab: control token:    174 '[control_172]' is not marked as EOG\n",
      "llm_load_vocab: control token:    708 '[control_706]' is not marked as EOG\n",
      "llm_load_vocab: control token:    729 '[control_727]' is not marked as EOG\n",
      "llm_load_vocab: control token:    311 '[control_309]' is not marked as EOG\n",
      "llm_load_vocab: control token:    384 '[control_382]' is not marked as EOG\n",
      "llm_load_vocab: control token:    766 '[control_764]' is not marked as EOG\n",
      "llm_load_vocab: control token:     94 '[control_92]' is not marked as EOG\n",
      "llm_load_vocab: control token:    304 '[control_302]' is not marked as EOG\n",
      "llm_load_vocab: control token:    197 '[control_195]' is not marked as EOG\n",
      "llm_load_vocab: control token:     17 '[control_15]' is not marked as EOG\n",
      "llm_load_vocab: control token:    604 '[control_602]' is not marked as EOG\n",
      "llm_load_vocab: control token:    576 '[control_574]' is not marked as EOG\n",
      "llm_load_vocab: control token:    359 '[control_357]' is not marked as EOG\n",
      "llm_load_vocab: control token:    302 '[control_300]' is not marked as EOG\n",
      "llm_load_vocab: control token:    453 '[control_451]' is not marked as EOG\n",
      "llm_load_vocab: control token:    374 '[control_372]' is not marked as EOG\n",
      "llm_load_vocab: control token:    207 '[control_205]' is not marked as EOG\n",
      "llm_load_vocab: control token:    739 '[control_737]' is not marked as EOG\n",
      "llm_load_vocab: control token:    689 '[control_687]' is not marked as EOG\n",
      "llm_load_vocab: control token:    335 '[control_333]' is not marked as EOG\n",
      "llm_load_vocab: control token:    485 '[control_483]' is not marked as EOG\n",
      "llm_load_vocab: control token:    283 '[control_281]' is not marked as EOG\n",
      "llm_load_vocab: control token:    249 '[control_247]' is not marked as EOG\n",
      "llm_load_vocab: control token:    752 '[control_750]' is not marked as EOG\n",
      "llm_load_vocab: control token:    330 '[control_328]' is not marked as EOG\n",
      "llm_load_vocab: control token:    635 '[control_633]' is not marked as EOG\n",
      "llm_load_vocab: control token:    161 '[control_159]' is not marked as EOG\n",
      "llm_load_vocab: control token:    731 '[control_729]' is not marked as EOG\n",
      "llm_load_vocab: control token:    631 '[control_629]' is not marked as EOG\n",
      "llm_load_vocab: control token:    323 '[control_321]' is not marked as EOG\n",
      "llm_load_vocab: control token:     48 '[control_46]' is not marked as EOG\n",
      "llm_load_vocab: control token:    544 '[control_542]' is not marked as EOG\n",
      "llm_load_vocab: control token:    687 '[control_685]' is not marked as EOG\n",
      "llm_load_vocab: control token:    463 '[control_461]' is not marked as EOG\n",
      "llm_load_vocab: control token:     47 '[control_45]' is not marked as EOG\n",
      "llm_load_vocab: control token:     86 '[control_84]' is not marked as EOG\n",
      "llm_load_vocab: control token:    331 '[control_329]' is not marked as EOG\n",
      "llm_load_vocab: control token:     13 '[control_11]' is not marked as EOG\n",
      "llm_load_vocab: control token:    760 '[control_758]' is not marked as EOG\n",
      "llm_load_vocab: control token:    612 '[control_610]' is not marked as EOG\n",
      "llm_load_vocab: control token:    473 '[control_471]' is not marked as EOG\n",
      "llm_load_vocab: control token:    601 '[control_599]' is not marked as EOG\n",
      "llm_load_vocab: control token:    146 '[control_144]' is not marked as EOG\n",
      "llm_load_vocab: control token:    734 '[control_732]' is not marked as EOG\n",
      "llm_load_vocab: control token:    141 '[control_139]' is not marked as EOG\n",
      "llm_load_vocab: control token:    138 '[control_136]' is not marked as EOG\n",
      "llm_load_vocab: control token:     61 '[control_59]' is not marked as EOG\n",
      "llm_load_vocab: control token:     46 '[control_44]' is not marked as EOG\n",
      "llm_load_vocab: control token:    173 '[control_171]' is not marked as EOG\n",
      "llm_load_vocab: control token:    367 '[control_365]' is not marked as EOG\n",
      "llm_load_vocab: control token:    417 '[control_415]' is not marked as EOG\n",
      "llm_load_vocab: control token:    740 '[control_738]' is not marked as EOG\n",
      "llm_load_vocab: control token:    216 '[control_214]' is not marked as EOG\n",
      "llm_load_vocab: control token:    498 '[control_496]' is not marked as EOG\n",
      "llm_load_vocab: control token:    512 '[control_510]' is not marked as EOG\n",
      "llm_load_vocab: control token:    122 '[control_120]' is not marked as EOG\n",
      "llm_load_vocab: control token:    246 '[control_244]' is not marked as EOG\n",
      "llm_load_vocab: control token:    745 '[control_743]' is not marked as EOG\n",
      "llm_load_vocab: control token:    451 '[control_449]' is not marked as EOG\n",
      "llm_load_vocab: control token:    280 '[control_278]' is not marked as EOG\n",
      "llm_load_vocab: control token:    654 '[control_652]' is not marked as EOG\n",
      "llm_load_vocab: control token:    679 '[control_677]' is not marked as EOG\n",
      "llm_load_vocab: control token:     77 '[control_75]' is not marked as EOG\n",
      "llm_load_vocab: control token:    638 '[control_636]' is not marked as EOG\n",
      "llm_load_vocab: control token:    472 '[control_470]' is not marked as EOG\n",
      "llm_load_vocab: control token:     59 '[control_57]' is not marked as EOG\n",
      "llm_load_vocab: control token:    145 '[control_143]' is not marked as EOG\n",
      "llm_load_vocab: control token:    318 '[control_316]' is not marked as EOG\n",
      "llm_load_vocab: control token:    640 '[control_638]' is not marked as EOG\n",
      "llm_load_vocab: control token:    690 '[control_688]' is not marked as EOG\n",
      "llm_load_vocab: control token:    256 '[control_254]' is not marked as EOG\n",
      "llm_load_vocab: control token:    476 '[control_474]' is not marked as EOG\n",
      "llm_load_vocab: control token:     21 '[control_19]' is not marked as EOG\n",
      "llm_load_vocab: control token:    288 '[control_286]' is not marked as EOG\n",
      "llm_load_vocab: control token:    255 '[control_253]' is not marked as EOG\n",
      "llm_load_vocab: control token:    113 '[control_111]' is not marked as EOG\n",
      "llm_load_vocab: control token:    190 '[control_188]' is not marked as EOG\n",
      "llm_load_vocab: control token:    108 '[control_106]' is not marked as EOG\n",
      "llm_load_vocab: control token:    211 '[control_209]' is not marked as EOG\n",
      "llm_load_vocab: control token:    551 '[control_549]' is not marked as EOG\n",
      "llm_load_vocab: control token:     14 '[control_12]' is not marked as EOG\n",
      "llm_load_vocab: control token:    737 '[control_735]' is not marked as EOG\n",
      "llm_load_vocab: control token:    555 '[control_553]' is not marked as EOG\n",
      "llm_load_vocab: control token:    227 '[control_225]' is not marked as EOG\n",
      "llm_load_vocab: control token:    210 '[control_208]' is not marked as EOG\n",
      "llm_load_vocab: control token:    230 '[control_228]' is not marked as EOG\n",
      "llm_load_vocab: control token:      7 '[/AVAILABLE_TOOLS]' is not marked as EOG\n",
      "llm_load_vocab: control token:     55 '[control_53]' is not marked as EOG\n",
      "llm_load_vocab: control token:    525 '[control_523]' is not marked as EOG\n",
      "llm_load_vocab: control token:    533 '[control_531]' is not marked as EOG\n",
      "llm_load_vocab: control token:    195 '[control_193]' is not marked as EOG\n",
      "llm_load_vocab: control token:    584 '[control_582]' is not marked as EOG\n",
      "llm_load_vocab: control token:    203 '[control_201]' is not marked as EOG\n",
      "llm_load_vocab: control token:    322 '[control_320]' is not marked as EOG\n",
      "llm_load_vocab: control token:    757 '[control_755]' is not marked as EOG\n",
      "llm_load_vocab: control token:    642 '[control_640]' is not marked as EOG\n",
      "llm_load_vocab: control token:    168 '[control_166]' is not marked as EOG\n",
      "llm_load_vocab: control token:    389 '[control_387]' is not marked as EOG\n",
      "llm_load_vocab: control token:    368 '[control_366]' is not marked as EOG\n",
      "llm_load_vocab: control token:    767 '[control_765]' is not marked as EOG\n",
      "llm_load_vocab: control token:    222 '[control_220]' is not marked as EOG\n",
      "llm_load_vocab: control token:    420 '[control_418]' is not marked as EOG\n",
      "llm_load_vocab: control token:    530 '[control_528]' is not marked as EOG\n",
      "llm_load_vocab: control token:    535 '[control_533]' is not marked as EOG\n",
      "llm_load_vocab: control token:    765 '[control_763]' is not marked as EOG\n",
      "llm_load_vocab: control token:    661 '[control_659]' is not marked as EOG\n",
      "llm_load_vocab: control token:     88 '[control_86]' is not marked as EOG\n",
      "llm_load_vocab: control token:    581 '[control_579]' is not marked as EOG\n",
      "llm_load_vocab: control token:    327 '[control_325]' is not marked as EOG\n",
      "llm_load_vocab: control token:    201 '[control_199]' is not marked as EOG\n",
      "llm_load_vocab: control token:    115 '[control_113]' is not marked as EOG\n",
      "llm_load_vocab: control token:    709 '[control_707]' is not marked as EOG\n",
      "llm_load_vocab: control token:    291 '[control_289]' is not marked as EOG\n",
      "llm_load_vocab: control token:    265 '[control_263]' is not marked as EOG\n",
      "llm_load_vocab: control token:    148 '[control_146]' is not marked as EOG\n",
      "llm_load_vocab: control token:    185 '[control_183]' is not marked as EOG\n",
      "llm_load_vocab: control token:    574 '[control_572]' is not marked as EOG\n",
      "llm_load_vocab: control token:    360 '[control_358]' is not marked as EOG\n",
      "llm_load_vocab: control token:    127 '[control_125]' is not marked as EOG\n",
      "llm_load_vocab: control token:    325 '[control_323]' is not marked as EOG\n",
      "llm_load_vocab: control token:    183 '[control_181]' is not marked as EOG\n",
      "llm_load_vocab: control token:    116 '[control_114]' is not marked as EOG\n",
      "llm_load_vocab: control token:    540 '[control_538]' is not marked as EOG\n",
      "llm_load_vocab: control token:    293 '[control_291]' is not marked as EOG\n",
      "llm_load_vocab: control token:    559 '[control_557]' is not marked as EOG\n",
      "llm_load_vocab: control token:    527 '[control_525]' is not marked as EOG\n",
      "llm_load_vocab: control token:    156 '[control_154]' is not marked as EOG\n",
      "llm_load_vocab: control token:    338 '[control_336]' is not marked as EOG\n",
      "llm_load_vocab: control token:    519 '[control_517]' is not marked as EOG\n",
      "llm_load_vocab: control token:    516 '[control_514]' is not marked as EOG\n",
      "llm_load_vocab: control token:     10 '[control_8]' is not marked as EOG\n",
      "llm_load_vocab: control token:      8 '[TOOL_RESULTS]' is not marked as EOG\n",
      "llm_load_vocab: control token:    505 '[control_503]' is not marked as EOG\n",
      "llm_load_vocab: control token:    503 '[control_501]' is not marked as EOG\n",
      "llm_load_vocab: control token:    500 '[control_498]' is not marked as EOG\n",
      "llm_load_vocab: control token:    496 '[control_494]' is not marked as EOG\n",
      "llm_load_vocab: control token:    492 '[control_490]' is not marked as EOG\n",
      "llm_load_vocab: control token:    489 '[control_487]' is not marked as EOG\n",
      "llm_load_vocab: control token:    538 '[control_536]' is not marked as EOG\n",
      "llm_load_vocab: control token:    596 '[control_594]' is not marked as EOG\n",
      "llm_load_vocab: control token:    481 '[control_479]' is not marked as EOG\n",
      "llm_load_vocab: control token:    475 '[control_473]' is not marked as EOG\n",
      "llm_load_vocab: control token:    336 '[control_334]' is not marked as EOG\n",
      "llm_load_vocab: control token:    670 '[control_668]' is not marked as EOG\n",
      "llm_load_vocab: control token:     50 '[control_48]' is not marked as EOG\n",
      "llm_load_vocab: control token:    456 '[control_454]' is not marked as EOG\n",
      "llm_load_vocab: control token:    105 '[control_103]' is not marked as EOG\n",
      "llm_load_vocab: control token:    421 '[control_419]' is not marked as EOG\n",
      "llm_load_vocab: control token:    430 '[control_428]' is not marked as EOG\n",
      "llm_load_vocab: control token:    429 '[control_427]' is not marked as EOG\n",
      "llm_load_vocab: control token:    575 '[control_573]' is not marked as EOG\n",
      "llm_load_vocab: control token:    425 '[control_423]' is not marked as EOG\n",
      "llm_load_vocab: control token:    424 '[control_422]' is not marked as EOG\n",
      "llm_load_vocab: control token:    680 '[control_678]' is not marked as EOG\n",
      "llm_load_vocab: control token:     57 '[control_55]' is not marked as EOG\n",
      "llm_load_vocab: control token:    356 '[control_354]' is not marked as EOG\n",
      "llm_load_vocab: control token:    458 '[control_456]' is not marked as EOG\n",
      "llm_load_vocab: control token:    313 '[control_311]' is not marked as EOG\n",
      "llm_load_vocab: control token:    418 '[control_416]' is not marked as EOG\n",
      "llm_load_vocab: control token:     70 '[control_68]' is not marked as EOG\n",
      "llm_load_vocab: control token:    759 '[control_757]' is not marked as EOG\n",
      "llm_load_vocab: control token:    416 '[control_414]' is not marked as EOG\n",
      "llm_load_vocab: control token:    238 '[control_236]' is not marked as EOG\n",
      "llm_load_vocab: control token:    568 '[control_566]' is not marked as EOG\n",
      "llm_load_vocab: control token:    409 '[control_407]' is not marked as EOG\n",
      "llm_load_vocab: control token:    550 '[control_548]' is not marked as EOG\n",
      "llm_load_vocab: control token:    571 '[control_569]' is not marked as EOG\n",
      "llm_load_vocab: control token:    618 '[control_616]' is not marked as EOG\n",
      "llm_load_vocab: control token:    623 '[control_621]' is not marked as EOG\n",
      "llm_load_vocab: control token:    247 '[control_245]' is not marked as EOG\n",
      "llm_load_vocab: control token:    400 '[control_398]' is not marked as EOG\n",
      "llm_load_vocab: control token:    396 '[control_394]' is not marked as EOG\n",
      "llm_load_vocab: control token:    392 '[control_390]' is not marked as EOG\n",
      "llm_load_vocab: control token:    552 '[control_550]' is not marked as EOG\n",
      "llm_load_vocab: control token:    651 '[control_649]' is not marked as EOG\n",
      "llm_load_vocab: control token:    390 '[control_388]' is not marked as EOG\n",
      "llm_load_vocab: control token:    186 '[control_184]' is not marked as EOG\n",
      "llm_load_vocab: control token:    565 '[control_563]' is not marked as EOG\n",
      "llm_load_vocab: control token:     92 '[control_90]' is not marked as EOG\n",
      "llm_load_vocab: control token:    508 '[control_506]' is not marked as EOG\n",
      "llm_load_vocab: control token:    373 '[control_371]' is not marked as EOG\n",
      "llm_load_vocab: control token:    299 '[control_297]' is not marked as EOG\n",
      "llm_load_vocab: control token:    562 '[control_560]' is not marked as EOG\n",
      "llm_load_vocab: control token:    537 '[control_535]' is not marked as EOG\n",
      "llm_load_vocab: control token:    372 '[control_370]' is not marked as EOG\n",
      "llm_load_vocab: control token:    366 '[control_364]' is not marked as EOG\n",
      "llm_load_vocab: control token:    196 '[control_194]' is not marked as EOG\n",
      "llm_load_vocab: control token:    478 '[control_476]' is not marked as EOG\n",
      "llm_load_vocab: control token:    621 '[control_619]' is not marked as EOG\n",
      "llm_load_vocab: control token:     53 '[control_51]' is not marked as EOG\n",
      "llm_load_vocab: control token:     40 '[control_38]' is not marked as EOG\n",
      "llm_load_vocab: control token:    347 '[control_345]' is not marked as EOG\n",
      "llm_load_vocab: control token:    345 '[control_343]' is not marked as EOG\n",
      "llm_load_vocab: control token:    339 '[control_337]' is not marked as EOG\n",
      "llm_load_vocab: control token:    234 '[control_232]' is not marked as EOG\n",
      "llm_load_vocab: control token:    770 '[control_768]' is not marked as EOG\n",
      "llm_load_vocab: control token:    444 '[control_442]' is not marked as EOG\n",
      "llm_load_vocab: control token:    317 '[control_315]' is not marked as EOG\n",
      "llm_load_vocab: control token:    693 '[control_691]' is not marked as EOG\n",
      "llm_load_vocab: control token:    321 '[control_319]' is not marked as EOG\n",
      "llm_load_vocab: control token:    320 '[control_318]' is not marked as EOG\n",
      "llm_load_vocab: control token:    179 '[control_177]' is not marked as EOG\n",
      "llm_load_vocab: control token:    214 '[control_212]' is not marked as EOG\n",
      "llm_load_vocab: control token:    666 '[control_664]' is not marked as EOG\n",
      "llm_load_vocab: control token:    712 '[control_710]' is not marked as EOG\n",
      "llm_load_vocab: control token:    303 '[control_301]' is not marked as EOG\n",
      "llm_load_vocab: control token:    440 '[control_438]' is not marked as EOG\n",
      "llm_load_vocab: control token:    314 '[control_312]' is not marked as EOG\n",
      "llm_load_vocab: control token:    397 '[control_395]' is not marked as EOG\n",
      "llm_load_vocab: control token:    312 '[control_310]' is not marked as EOG\n",
      "llm_load_vocab: control token:    129 '[control_127]' is not marked as EOG\n",
      "llm_load_vocab: control token:    545 '[control_543]' is not marked as EOG\n",
      "llm_load_vocab: control token:     58 '[control_56]' is not marked as EOG\n",
      "llm_load_vocab: control token:    509 '[control_507]' is not marked as EOG\n",
      "llm_load_vocab: control token:    541 '[control_539]' is not marked as EOG\n",
      "llm_load_vocab: control token:    443 '[control_441]' is not marked as EOG\n",
      "llm_load_vocab: control token:     45 '[control_43]' is not marked as EOG\n",
      "llm_load_vocab: control token:    469 '[control_467]' is not marked as EOG\n",
      "llm_load_vocab: control token:    532 '[control_530]' is not marked as EOG\n",
      "llm_load_vocab: control token:     64 '[control_62]' is not marked as EOG\n",
      "llm_load_vocab: control token:    365 '[control_363]' is not marked as EOG\n",
      "llm_load_vocab: control token:    563 '[control_561]' is not marked as EOG\n",
      "llm_load_vocab: control token:    346 '[control_344]' is not marked as EOG\n",
      "llm_load_vocab: control token:    282 '[control_280]' is not marked as EOG\n",
      "llm_load_vocab: control token:    450 '[control_448]' is not marked as EOG\n",
      "llm_load_vocab: control token:    526 '[control_524]' is not marked as EOG\n",
      "llm_load_vocab: control token:    672 '[control_670]' is not marked as EOG\n",
      "llm_load_vocab: control token:    232 '[control_230]' is not marked as EOG\n",
      "llm_load_vocab: control token:    273 '[control_271]' is not marked as EOG\n",
      "llm_load_vocab: control token:    272 '[control_270]' is not marked as EOG\n",
      "llm_load_vocab: control token:    636 '[control_634]' is not marked as EOG\n",
      "llm_load_vocab: control token:    260 '[control_258]' is not marked as EOG\n",
      "llm_load_vocab: control token:    518 '[control_516]' is not marked as EOG\n",
      "llm_load_vocab: control token:    353 '[control_351]' is not marked as EOG\n",
      "llm_load_vocab: control token:    257 '[control_255]' is not marked as EOG\n",
      "llm_load_vocab: control token:    126 '[control_124]' is not marked as EOG\n",
      "llm_load_vocab: control token:    124 '[control_122]' is not marked as EOG\n",
      "llm_load_vocab: control token:    751 '[control_749]' is not marked as EOG\n",
      "llm_load_vocab: control token:    383 '[control_381]' is not marked as EOG\n",
      "llm_load_vocab: control token:    175 '[control_173]' is not marked as EOG\n",
      "llm_load_vocab: control token:     75 '[control_73]' is not marked as EOG\n",
      "llm_load_vocab: control token:     72 '[control_70]' is not marked as EOG\n",
      "llm_load_vocab: control token:    614 '[control_612]' is not marked as EOG\n",
      "llm_load_vocab: control token:    167 '[control_165]' is not marked as EOG\n",
      "llm_load_vocab: control token:    465 '[control_463]' is not marked as EOG\n",
      "llm_load_vocab: control token:    341 '[control_339]' is not marked as EOG\n",
      "llm_load_vocab: control token:    703 '[control_701]' is not marked as EOG\n",
      "llm_load_vocab: control token:    501 '[control_499]' is not marked as EOG\n",
      "llm_load_vocab: control token:     90 '[control_88]' is not marked as EOG\n",
      "llm_load_vocab: control token:     89 '[control_87]' is not marked as EOG\n",
      "llm_load_vocab: control token:    593 '[control_591]' is not marked as EOG\n",
      "llm_load_vocab: control token:    107 '[control_105]' is not marked as EOG\n",
      "llm_load_vocab: control token:    241 '[control_239]' is not marked as EOG\n",
      "llm_load_vocab: control token:    713 '[control_711]' is not marked as EOG\n",
      "llm_load_vocab: control token:    212 '[control_210]' is not marked as EOG\n",
      "llm_load_vocab: control token:     80 '[control_78]' is not marked as EOG\n",
      "llm_load_vocab: control token:    707 '[control_705]' is not marked as EOG\n",
      "llm_load_vocab: control token:    371 '[control_369]' is not marked as EOG\n",
      "llm_load_vocab: control token:    628 '[control_626]' is not marked as EOG\n",
      "llm_load_vocab: control token:     15 '[control_13]' is not marked as EOG\n",
      "llm_load_vocab: control token:    354 '[control_352]' is not marked as EOG\n",
      "llm_load_vocab: control token:     25 '[control_23]' is not marked as EOG\n",
      "llm_load_vocab: control token:    261 '[control_259]' is not marked as EOG\n",
      "llm_load_vocab: control token:    435 '[control_433]' is not marked as EOG\n",
      "llm_load_vocab: control token:    307 '[control_305]' is not marked as EOG\n",
      "llm_load_vocab: control token:    305 '[control_303]' is not marked as EOG\n",
      "llm_load_vocab: control token:    656 '[control_654]' is not marked as EOG\n",
      "llm_load_vocab: control token:    702 '[control_700]' is not marked as EOG\n",
      "llm_load_vocab: control token:    428 '[control_426]' is not marked as EOG\n",
      "llm_load_vocab: control token:    499 '[control_497]' is not marked as EOG\n",
      "llm_load_vocab: control token:    154 '[control_152]' is not marked as EOG\n",
      "llm_load_vocab: control token:    308 '[control_306]' is not marked as EOG\n",
      "llm_load_vocab: control token:    286 '[control_284]' is not marked as EOG\n",
      "llm_load_vocab: control token:    634 '[control_632]' is not marked as EOG\n",
      "llm_load_vocab: control token:     51 '[control_49]' is not marked as EOG\n",
      "llm_load_vocab: control token:    599 '[control_597]' is not marked as EOG\n",
      "llm_load_vocab: control token:    606 '[control_604]' is not marked as EOG\n",
      "llm_load_vocab: control token:     30 '[control_28]' is not marked as EOG\n",
      "llm_load_vocab: control token:    250 '[control_248]' is not marked as EOG\n",
      "llm_load_vocab: control token:    714 '[control_712]' is not marked as EOG\n",
      "llm_load_vocab: control token:    270 '[control_268]' is not marked as EOG\n",
      "llm_load_vocab: control token:     83 '[control_81]' is not marked as EOG\n",
      "llm_load_vocab: control token:    730 '[control_728]' is not marked as EOG\n",
      "llm_load_vocab: control token:    743 '[control_741]' is not marked as EOG\n",
      "llm_load_vocab: control token:    484 '[control_482]' is not marked as EOG\n",
      "llm_load_vocab: control token:    758 '[control_756]' is not marked as EOG\n",
      "llm_load_vocab: control token:    271 '[control_269]' is not marked as EOG\n",
      "llm_load_vocab: control token:    279 '[control_277]' is not marked as EOG\n",
      "llm_load_vocab: control token:     73 '[control_71]' is not marked as EOG\n",
      "llm_load_vocab: control token:    363 '[control_361]' is not marked as EOG\n",
      "llm_load_vocab: control token:     60 '[control_58]' is not marked as EOG\n",
      "llm_load_vocab: control token:    405 '[control_403]' is not marked as EOG\n",
      "llm_load_vocab: control token:    220 '[control_218]' is not marked as EOG\n",
      "llm_load_vocab: control token:    436 '[control_434]' is not marked as EOG\n",
      "llm_load_vocab: control token:     27 '[control_25]' is not marked as EOG\n",
      "llm_load_vocab: control token:    652 '[control_650]' is not marked as EOG\n",
      "llm_load_vocab: control token:    646 '[control_644]' is not marked as EOG\n",
      "llm_load_vocab: control token:    395 '[control_393]' is not marked as EOG\n",
      "llm_load_vocab: control token:    549 '[control_547]' is not marked as EOG\n",
      "llm_load_vocab: control token:     12 '[control_10]' is not marked as EOG\n",
      "llm_load_vocab: control token:    229 '[control_227]' is not marked as EOG\n",
      "llm_load_vocab: control token:    162 '[control_160]' is not marked as EOG\n",
      "llm_load_vocab: control token:    497 '[control_495]' is not marked as EOG\n",
      "llm_load_vocab: control token:     31 '[control_29]' is not marked as EOG\n",
      "llm_load_vocab: control token:     98 '[control_96]' is not marked as EOG\n",
      "llm_load_vocab: control token:    686 '[control_684]' is not marked as EOG\n",
      "llm_load_vocab: control token:      3 '[INST]' is not marked as EOG\n",
      "llm_load_vocab: control token:    155 '[control_153]' is not marked as EOG\n",
      "llm_load_vocab: control token:    470 '[control_468]' is not marked as EOG\n",
      "llm_load_vocab: control token:     69 '[control_67]' is not marked as EOG\n",
      "llm_load_vocab: control token:     93 '[control_91]' is not marked as EOG\n",
      "llm_load_vocab: control token:     71 '[control_69]' is not marked as EOG\n",
      "llm_load_vocab: control token:     11 '[control_9]' is not marked as EOG\n",
      "llm_load_vocab: control token:     43 '[control_41]' is not marked as EOG\n",
      "llm_load_vocab: control token:     22 '[control_20]' is not marked as EOG\n",
      "llm_load_vocab: control token:     35 '[control_33]' is not marked as EOG\n",
      "llm_load_vocab: control token:    706 '[control_704]' is not marked as EOG\n",
      "llm_load_vocab: control token:    511 '[control_509]' is not marked as EOG\n",
      "llm_load_vocab: control token:    491 '[control_489]' is not marked as EOG\n",
      "llm_load_vocab: control token:    324 '[control_322]' is not marked as EOG\n",
      "llm_load_vocab: control token:    655 '[control_653]' is not marked as EOG\n",
      "llm_load_vocab: control token:    117 '[control_115]' is not marked as EOG\n",
      "llm_load_vocab: control token:    665 '[control_663]' is not marked as EOG\n",
      "llm_load_vocab: control token:      9 '[/TOOL_RESULTS]' is not marked as EOG\n",
      "llm_load_vocab: control token:     29 '[control_27]' is not marked as EOG\n",
      "llm_load_vocab: control token:     44 '[control_42]' is not marked as EOG\n",
      "llm_load_vocab: control token:    310 '[control_308]' is not marked as EOG\n",
      "llm_load_vocab: control token:    157 '[control_155]' is not marked as EOG\n",
      "llm_load_vocab: control token:    515 '[control_513]' is not marked as EOG\n",
      "llm_load_vocab: control token:    388 '[control_386]' is not marked as EOG\n",
      "llm_load_vocab: control token:    438 '[control_436]' is not marked as EOG\n",
      "llm_load_vocab: control token:    486 '[control_484]' is not marked as EOG\n",
      "llm_load_vocab: control token:    139 '[control_137]' is not marked as EOG\n",
      "llm_load_vocab: control token:    543 '[control_541]' is not marked as EOG\n",
      "llm_load_vocab: control token:    622 '[control_620]' is not marked as EOG\n",
      "llm_load_vocab: control token:    598 '[control_596]' is not marked as EOG\n",
      "llm_load_vocab: control token:     16 '[control_14]' is not marked as EOG\n",
      "llm_load_vocab: control token:     39 '[control_37]' is not marked as EOG\n",
      "llm_load_vocab: control token:    102 '[control_100]' is not marked as EOG\n",
      "llm_load_vocab: control token:    673 '[control_671]' is not marked as EOG\n",
      "llm_load_vocab: control token:    287 '[control_285]' is not marked as EOG\n",
      "llm_load_vocab: control token:    244 '[control_242]' is not marked as EOG\n",
      "llm_load_vocab: control token:    446 '[control_444]' is not marked as EOG\n",
      "llm_load_vocab: control token:    483 '[control_481]' is not marked as EOG\n",
      "llm_load_vocab: control token:    467 '[control_465]' is not marked as EOG\n",
      "llm_load_vocab: control token:    264 '[control_262]' is not marked as EOG\n",
      "llm_load_vocab: control token:    176 '[control_174]' is not marked as EOG\n",
      "llm_load_vocab: control token:    625 '[control_623]' is not marked as EOG\n",
      "llm_load_vocab: control token:    160 '[control_158]' is not marked as EOG\n",
      "llm_load_vocab: control token:     20 '[control_18]' is not marked as EOG\n",
      "llm_load_vocab: control token:    641 '[control_639]' is not marked as EOG\n",
      "llm_load_vocab: control token:     99 '[control_97]' is not marked as EOG\n",
      "llm_load_vocab: control token:     54 '[control_52]' is not marked as EOG\n",
      "llm_load_vocab: control token:     37 '[control_35]' is not marked as EOG\n",
      "llm_load_vocab: control token:    401 '[control_399]' is not marked as EOG\n",
      "llm_load_vocab: control token:    130 '[control_128]' is not marked as EOG\n",
      "llm_load_vocab: control token:    218 '[control_216]' is not marked as EOG\n",
      "llm_load_vocab: control token:    243 '[control_241]' is not marked as EOG\n",
      "llm_load_vocab: control token:    753 '[control_751]' is not marked as EOG\n",
      "llm_load_vocab: control token:     74 '[control_72]' is not marked as EOG\n",
      "llm_load_vocab: control token:    171 '[control_169]' is not marked as EOG\n",
      "llm_load_vocab: control token:    151 '[control_149]' is not marked as EOG\n",
      "llm_load_vocab: control token:    364 '[control_362]' is not marked as EOG\n",
      "llm_load_vocab: control token:    495 '[control_493]' is not marked as EOG\n",
      "llm_load_vocab: control token:    119 '[control_117]' is not marked as EOG\n",
      "llm_load_vocab: control token:    217 '[control_215]' is not marked as EOG\n",
      "llm_load_vocab: control token:     84 '[control_82]' is not marked as EOG\n",
      "llm_load_vocab: control token:      5 '[TOOL_CALLS]' is not marked as EOG\n",
      "llm_load_vocab: control token:    531 '[control_529]' is not marked as EOG\n",
      "llm_load_vocab: control token:     33 '[control_31]' is not marked as EOG\n",
      "llm_load_vocab: control token:     82 '[control_80]' is not marked as EOG\n",
      "llm_load_vocab: control token:    100 '[control_98]' is not marked as EOG\n",
      "llm_load_vocab: control token:    125 '[control_123]' is not marked as EOG\n",
      "llm_load_vocab: control token:    520 '[control_518]' is not marked as EOG\n",
      "llm_load_vocab: control token:    144 '[control_142]' is not marked as EOG\n",
      "llm_load_vocab: control token:    152 '[control_150]' is not marked as EOG\n",
      "llm_load_vocab: control token:    592 '[control_590]' is not marked as EOG\n",
      "llm_load_vocab: control token:    461 '[control_459]' is not marked as EOG\n",
      "llm_load_vocab: control token:    624 '[control_622]' is not marked as EOG\n",
      "llm_load_vocab: control token:     65 '[control_63]' is not marked as EOG\n",
      "llm_load_vocab: control token:    172 '[control_170]' is not marked as EOG\n",
      "llm_load_vocab: control token:    178 '[control_176]' is not marked as EOG\n",
      "llm_load_vocab: control token:    258 '[control_256]' is not marked as EOG\n",
      "llm_load_vocab: control token:    524 '[control_522]' is not marked as EOG\n",
      "llm_load_vocab: control token:    657 '[control_655]' is not marked as EOG\n",
      "llm_load_vocab: control token:    184 '[control_182]' is not marked as EOG\n",
      "llm_load_vocab: control token:    441 '[control_439]' is not marked as EOG\n",
      "llm_load_vocab: control token:    315 '[control_313]' is not marked as EOG\n",
      "llm_load_vocab: control token:    662 '[control_660]' is not marked as EOG\n",
      "llm_load_vocab: control token:      6 '[AVAILABLE_TOOLS]' is not marked as EOG\n",
      "llm_load_vocab: control token:    517 '[control_515]' is not marked as EOG\n",
      "llm_load_vocab: control token:    194 '[control_192]' is not marked as EOG\n",
      "llm_load_vocab: control token:    447 '[control_445]' is not marked as EOG\n",
      "llm_load_vocab: control token:     52 '[control_50]' is not marked as EOG\n",
      "llm_load_vocab: control token:    718 '[control_716]' is not marked as EOG\n",
      "llm_load_vocab: control token:    692 '[control_690]' is not marked as EOG\n",
      "llm_load_vocab: control token:    290 '[control_288]' is not marked as EOG\n",
      "llm_load_vocab: control token:    763 '[control_761]' is not marked as EOG\n",
      "llm_load_vocab: control token:    362 '[control_360]' is not marked as EOG\n",
      "llm_load_vocab: control token:    200 '[control_198]' is not marked as EOG\n",
      "llm_load_vocab: control token:    204 '[control_202]' is not marked as EOG\n",
      "llm_load_vocab: control token:    722 '[control_720]' is not marked as EOG\n",
      "llm_load_vocab: control token:    351 '[control_349]' is not marked as EOG\n",
      "llm_load_vocab: control token:    349 '[control_347]' is not marked as EOG\n",
      "llm_load_vocab: control token:     38 '[control_36]' is not marked as EOG\n",
      "llm_load_vocab: control token:    134 '[control_132]' is not marked as EOG\n",
      "llm_load_vocab: control token:     67 '[control_65]' is not marked as EOG\n",
      "llm_load_vocab: control token:    239 '[control_237]' is not marked as EOG\n",
      "llm_load_vocab: control token:    570 '[control_568]' is not marked as EOG\n",
      "llm_load_vocab: control token:    253 '[control_251]' is not marked as EOG\n",
      "llm_load_vocab: control token:    221 '[control_219]' is not marked as EOG\n",
      "llm_load_vocab: control token:    664 '[control_662]' is not marked as EOG\n",
      "llm_load_vocab: control token:    225 '[control_223]' is not marked as EOG\n",
      "llm_load_vocab: control token:    226 '[control_224]' is not marked as EOG\n",
      "llm_load_vocab: control token:    553 '[control_551]' is not marked as EOG\n",
      "llm_load_vocab: control token:    242 '[control_240]' is not marked as EOG\n",
      "llm_load_vocab: control token:    633 '[control_631]' is not marked as EOG\n",
      "llm_load_vocab: control token:    580 '[control_578]' is not marked as EOG\n",
      "llm_load_vocab: control token:    245 '[control_243]' is not marked as EOG\n",
      "llm_load_vocab: control token:    620 '[control_618]' is not marked as EOG\n",
      "llm_load_vocab: control token:    191 '[control_189]' is not marked as EOG\n",
      "llm_load_vocab: control token:     87 '[control_85]' is not marked as EOG\n",
      "llm_load_vocab: control token:    189 '[control_187]' is not marked as EOG\n",
      "llm_load_vocab: control token:    542 '[control_540]' is not marked as EOG\n",
      "llm_load_vocab: control token:    548 '[control_546]' is not marked as EOG\n",
      "llm_load_vocab: control token:    558 '[control_556]' is not marked as EOG\n",
      "llm_load_vocab: control token:    560 '[control_558]' is not marked as EOG\n",
      "llm_load_vocab: control token:    564 '[control_562]' is not marked as EOG\n",
      "llm_load_vocab: control token:    410 '[control_408]' is not marked as EOG\n",
      "llm_load_vocab: control token:    566 '[control_564]' is not marked as EOG\n",
      "llm_load_vocab: control token:    649 '[control_647]' is not marked as EOG\n",
      "llm_load_vocab: control token:    414 '[control_412]' is not marked as EOG\n",
      "llm_load_vocab: control token:    567 '[control_565]' is not marked as EOG\n",
      "llm_load_vocab: control token:    569 '[control_567]' is not marked as EOG\n",
      "llm_load_vocab: control token:    761 '[control_759]' is not marked as EOG\n",
      "llm_load_vocab: control token:    408 '[control_406]' is not marked as EOG\n",
      "llm_load_vocab: control token:    579 '[control_577]' is not marked as EOG\n",
      "llm_load_vocab: control token:    147 '[control_145]' is not marked as EOG\n",
      "llm_load_vocab: control token:    236 '[control_234]' is not marked as EOG\n",
      "llm_load_vocab: control token:    588 '[control_586]' is not marked as EOG\n",
      "llm_load_vocab: control token:    292 '[control_290]' is not marked as EOG\n",
      "llm_load_vocab: control token:    591 '[control_589]' is not marked as EOG\n",
      "llm_load_vocab: control token:    645 '[control_643]' is not marked as EOG\n",
      "llm_load_vocab: control token:    140 '[control_138]' is not marked as EOG\n",
      "llm_load_vocab: control token:    422 '[control_420]' is not marked as EOG\n",
      "llm_load_vocab: control token:    595 '[control_593]' is not marked as EOG\n",
      "llm_load_vocab: control token:    597 '[control_595]' is not marked as EOG\n",
      "llm_load_vocab: control token:    754 '[control_752]' is not marked as EOG\n",
      "llm_load_vocab: control token:    159 '[control_157]' is not marked as EOG\n",
      "llm_load_vocab: control token:    344 '[control_342]' is not marked as EOG\n",
      "llm_load_vocab: control token:    393 '[control_391]' is not marked as EOG\n",
      "llm_load_vocab: control token:    691 '[control_689]' is not marked as EOG\n",
      "llm_load_vocab: control token:    608 '[control_606]' is not marked as EOG\n",
      "llm_load_vocab: control token:    663 '[control_661]' is not marked as EOG\n",
      "llm_load_vocab: control token:    613 '[control_611]' is not marked as EOG\n",
      "llm_load_vocab: control token:    340 '[control_338]' is not marked as EOG\n",
      "llm_load_vocab: control token:    616 '[control_614]' is not marked as EOG\n",
      "llm_load_vocab: control token:    719 '[control_717]' is not marked as EOG\n",
      "llm_load_vocab: control token:    521 '[control_519]' is not marked as EOG\n",
      "llm_load_vocab: control token:    619 '[control_617]' is not marked as EOG\n",
      "llm_load_vocab: control token:    523 '[control_521]' is not marked as EOG\n",
      "llm_load_vocab: control token:    626 '[control_624]' is not marked as EOG\n",
      "llm_load_vocab: control token:    695 '[control_693]' is not marked as EOG\n",
      "llm_load_vocab: control token:    637 '[control_635]' is not marked as EOG\n",
      "llm_load_vocab: control token:    235 '[control_233]' is not marked as EOG\n",
      "llm_load_vocab: control token:    659 '[control_657]' is not marked as EOG\n",
      "llm_load_vocab: control token:    268 '[control_266]' is not marked as EOG\n",
      "llm_load_vocab: control token:    406 '[control_404]' is not marked as EOG\n",
      "llm_load_vocab: control token:    735 '[control_733]' is not marked as EOG\n",
      "llm_load_vocab: control token:    398 '[control_396]' is not marked as EOG\n",
      "llm_load_vocab: control token:    674 '[control_672]' is not marked as EOG\n",
      "llm_load_vocab: control token:    684 '[control_682]' is not marked as EOG\n",
      "llm_load_vocab: control token:    462 '[control_460]' is not marked as EOG\n",
      "llm_load_vocab: control token:    382 '[control_380]' is not marked as EOG\n",
      "llm_load_vocab: control token:    697 '[control_695]' is not marked as EOG\n",
      "llm_load_vocab: control token:    698 '[control_696]' is not marked as EOG\n",
      "llm_load_vocab: control token:    699 '[control_697]' is not marked as EOG\n",
      "llm_load_vocab: control token:    688 '[control_686]' is not marked as EOG\n",
      "llm_load_vocab: control token:    704 '[control_702]' is not marked as EOG\n",
      "llm_load_vocab: control token:    705 '[control_703]' is not marked as EOG\n",
      "llm_load_vocab: control token:    205 '[control_203]' is not marked as EOG\n",
      "llm_load_vocab: control token:    726 '[control_724]' is not marked as EOG\n",
      "llm_load_vocab: control token:    180 '[control_178]' is not marked as EOG\n",
      "llm_load_vocab: control token:    716 '[control_714]' is not marked as EOG\n",
      "llm_load_vocab: control token:    590 '[control_588]' is not marked as EOG\n",
      "llm_load_vocab: control token:    454 '[control_452]' is not marked as EOG\n",
      "llm_load_vocab: control token:    728 '[control_726]' is not marked as EOG\n",
      "llm_load_vocab: control token:    738 '[control_736]' is not marked as EOG\n",
      "llm_load_vocab: control token:    744 '[control_742]' is not marked as EOG\n",
      "llm_load_vocab: control token:    403 '[control_401]' is not marked as EOG\n",
      "llm_load_vocab: control token:    764 '[control_762]' is not marked as EOG\n",
      "llm_load_vocab: control token:    676 '[control_674]' is not marked as EOG\n",
      "llm_load_vocab: control token:    756 '[control_754]' is not marked as EOG\n",
      "llm_load_vocab: control token:    380 '[control_378]' is not marked as EOG\n",
      "llm_load_vocab: control token:    319 '[control_317]' is not marked as EOG\n",
      "llm_load_vocab: control token:    600 '[control_598]' is not marked as EOG\n",
      "llm_load_vocab: control token:    297 '[control_295]' is not marked as EOG\n",
      "llm_load_vocab: control token:    259 '[control_257]' is not marked as EOG\n",
      "llm_load_vocab: control token:    639 '[control_637]' is not marked as EOG\n",
      "llm_load_vocab: control token:    529 '[control_527]' is not marked as EOG\n",
      "llm_load_vocab: control token:    101 '[control_99]' is not marked as EOG\n",
      "llm_load_vocab: control token:    522 '[control_520]' is not marked as EOG\n",
      "llm_load_vocab: control token:    723 '[control_721]' is not marked as EOG\n",
      "llm_load_vocab: control token:    254 '[control_252]' is not marked as EOG\n",
      "llm_load_vocab: control token:    513 '[control_511]' is not marked as EOG\n",
      "llm_load_vocab: control token:    667 '[control_665]' is not marked as EOG\n",
      "llm_load_vocab: control token:    267 '[control_265]' is not marked as EOG\n",
      "llm_load_vocab: control token:    732 '[control_730]' is not marked as EOG\n",
      "llm_load_vocab: control token:     24 '[control_22]' is not marked as EOG\n",
      "llm_load_vocab: control token:    650 '[control_648]' is not marked as EOG\n",
      "llm_load_vocab: control token:    528 '[control_526]' is not marked as EOG\n",
      "llm_load_vocab: control token:    749 '[control_747]' is not marked as EOG\n",
      "llm_load_vocab: control token:    721 '[control_719]' is not marked as EOG\n",
      "llm_load_vocab: control token:    103 '[control_101]' is not marked as EOG\n",
      "llm_load_vocab: control token:    294 '[control_292]' is not marked as EOG\n",
      "llm_load_vocab: control token:     41 '[control_39]' is not marked as EOG\n",
      "llm_load_vocab: control token:    133 '[control_131]' is not marked as EOG\n",
      "llm_load_vocab: control token:    188 '[control_186]' is not marked as EOG\n",
      "llm_load_vocab: control token:    276 '[control_274]' is not marked as EOG\n",
      "llm_load_vocab: control token:    644 '[control_642]' is not marked as EOG\n",
      "llm_load_vocab: control token:    648 '[control_646]' is not marked as EOG\n",
      "llm_load_vocab: control token:    459 '[control_457]' is not marked as EOG\n",
      "llm_load_vocab: control token:    112 '[control_110]' is not marked as EOG\n",
      "llm_load_vocab: control token:    300 '[control_298]' is not marked as EOG\n",
      "llm_load_vocab: control token:    206 '[control_204]' is not marked as EOG\n",
      "llm_load_vocab: control token:    121 '[control_119]' is not marked as EOG\n",
      "llm_load_vocab: control token:    750 '[control_748]' is not marked as EOG\n",
      "llm_load_vocab: control token:    131 '[control_129]' is not marked as EOG\n",
      "llm_load_vocab: control token:    474 '[control_472]' is not marked as EOG\n",
      "llm_load_vocab: control token:    685 '[control_683]' is not marked as EOG\n",
      "llm_load_vocab: control token:    251 '[control_249]' is not marked as EOG\n",
      "llm_load_vocab: control token:    402 '[control_400]' is not marked as EOG\n",
      "llm_load_vocab: control token:    281 '[control_279]' is not marked as EOG\n",
      "llm_load_vocab: control token:    192 '[control_190]' is not marked as EOG\n",
      "llm_load_vocab: control token:    387 '[control_385]' is not marked as EOG\n",
      "llm_load_vocab: control token:    587 '[control_585]' is not marked as EOG\n",
      "llm_load_vocab: control token:     66 '[control_64]' is not marked as EOG\n",
      "llm_load_vocab: control token:    394 '[control_392]' is not marked as EOG\n",
      "llm_load_vocab: control token:     49 '[control_47]' is not marked as EOG\n",
      "llm_load_vocab: control token:     42 '[control_40]' is not marked as EOG\n",
      "llm_load_vocab: control token:     32 '[control_30]' is not marked as EOG\n",
      "llm_load_vocab: control token:    399 '[control_397]' is not marked as EOG\n",
      "llm_load_vocab: control token:    448 '[control_446]' is not marked as EOG\n",
      "llm_load_vocab: control token:    479 '[control_477]' is not marked as EOG\n",
      "llm_load_vocab: control token:    493 '[control_491]' is not marked as EOG\n",
      "llm_load_vocab: control token:    736 '[control_734]' is not marked as EOG\n",
      "llm_load_vocab: control token:    348 '[control_346]' is not marked as EOG\n",
      "llm_load_vocab: control token:    193 '[control_191]' is not marked as EOG\n",
      "llm_load_vocab: control token:    231 '[control_229]' is not marked as EOG\n",
      "llm_load_vocab: control token:    609 '[control_607]' is not marked as EOG\n",
      "llm_load_vocab: control token:    213 '[control_211]' is not marked as EOG\n",
      "llm_load_vocab: control token:    128 '[control_126]' is not marked as EOG\n",
      "llm_load_vocab: control token:    118 '[control_116]' is not marked as EOG\n",
      "llm_load_vocab: control token:    369 '[control_367]' is not marked as EOG\n",
      "llm_load_vocab: control token:    630 '[control_628]' is not marked as EOG\n",
      "llm_load_vocab: control token:    755 '[control_753]' is not marked as EOG\n",
      "llm_load_vocab: control token:    747 '[control_745]' is not marked as EOG\n",
      "llm_load_vocab: control token:    289 '[control_287]' is not marked as EOG\n",
      "llm_load_vocab: control token:     26 '[control_24]' is not marked as EOG\n",
      "llm_load_vocab: control token:     63 '[control_61]' is not marked as EOG\n",
      "llm_load_vocab: control token:    284 '[control_282]' is not marked as EOG\n",
      "llm_load_vocab: control token:    164 '[control_162]' is not marked as EOG\n",
      "llm_load_vocab: control token:    404 '[control_402]' is not marked as EOG\n",
      "llm_load_vocab: control token:    506 '[control_504]' is not marked as EOG\n",
      "llm_load_vocab: control token:    123 '[control_121]' is not marked as EOG\n",
      "llm_load_vocab: control token:    237 '[control_235]' is not marked as EOG\n",
      "llm_load_vocab: control token:     62 '[control_60]' is not marked as EOG\n",
      "llm_load_vocab: control token:    510 '[control_508]' is not marked as EOG\n",
      "llm_load_vocab: control token:    233 '[control_231]' is not marked as EOG\n",
      "llm_load_vocab: control token:     68 '[control_66]' is not marked as EOG\n",
      "llm_load_vocab: control token:    487 '[control_485]' is not marked as EOG\n",
      "llm_load_vocab: control token:    471 '[control_469]' is not marked as EOG\n",
      "llm_load_vocab: control token:    415 '[control_413]' is not marked as EOG\n",
      "llm_load_vocab: control token:     78 '[control_76]' is not marked as EOG\n",
      "llm_load_vocab: control token:    610 '[control_608]' is not marked as EOG\n",
      "llm_load_vocab: control token:    137 '[control_135]' is not marked as EOG\n",
      "llm_load_vocab: control token:    539 '[control_537]' is not marked as EOG\n",
      "llm_load_vocab: control token:    658 '[control_656]' is not marked as EOG\n",
      "llm_load_vocab: control token:    158 '[control_156]' is not marked as EOG\n",
      "llm_load_vocab: control token:    585 '[control_583]' is not marked as EOG\n",
      "llm_load_vocab: control token:    215 '[control_213]' is not marked as EOG\n",
      "llm_load_vocab: control token:    554 '[control_552]' is not marked as EOG\n",
      "llm_load_vocab: control token:    762 '[control_760]' is not marked as EOG\n",
      "llm_load_vocab: control token:    717 '[control_715]' is not marked as EOG\n",
      "llm_load_vocab: control token:    228 '[control_226]' is not marked as EOG\n",
      "llm_load_vocab: control token:    442 '[control_440]' is not marked as EOG\n",
      "llm_load_vocab: control token:    494 '[control_492]' is not marked as EOG\n",
      "llm_load_vocab: control token:     97 '[control_95]' is not marked as EOG\n",
      "llm_load_vocab: control token:    683 '[control_681]' is not marked as EOG\n",
      "llm_load_vocab: control token:    629 '[control_627]' is not marked as EOG\n",
      "llm_load_vocab: control token:    725 '[control_723]' is not marked as EOG\n",
      "llm_load_vocab: control token:    432 '[control_430]' is not marked as EOG\n",
      "llm_load_vocab: control token:    477 '[control_475]' is not marked as EOG\n",
      "llm_load_vocab: control token:    355 '[control_353]' is not marked as EOG\n",
      "llm_load_vocab: control token:     36 '[control_34]' is not marked as EOG\n",
      "llm_load_vocab: control token:    534 '[control_532]' is not marked as EOG\n",
      "llm_load_vocab: control token:    120 '[control_118]' is not marked as EOG\n",
      "llm_load_vocab: control token:     28 '[control_26]' is not marked as EOG\n",
      "llm_load_vocab: control token:    306 '[control_304]' is not marked as EOG\n",
      "llm_load_vocab: control token:    407 '[control_405]' is not marked as EOG\n",
      "llm_load_vocab: control token:    696 '[control_694]' is not marked as EOG\n",
      "llm_load_vocab: control token:    274 '[control_272]' is not marked as EOG\n",
      "llm_load_vocab: control token:    142 '[control_140]' is not marked as EOG\n",
      "llm_load_vocab: control token:    136 '[control_134]' is not marked as EOG\n",
      "llm_load_vocab: control token:    309 '[control_307]' is not marked as EOG\n",
      "llm_load_vocab: control token:    423 '[control_421]' is not marked as EOG\n",
      "llm_load_vocab: control token:    724 '[control_722]' is not marked as EOG\n",
      "llm_load_vocab: control token:    262 '[control_260]' is not marked as EOG\n",
      "llm_load_vocab: control token:    419 '[control_417]' is not marked as EOG\n",
      "llm_load_vocab: control token:    329 '[control_327]' is not marked as EOG\n",
      "llm_load_vocab: control token:    427 '[control_425]' is not marked as EOG\n",
      "llm_load_vocab: control token:    370 '[control_368]' is not marked as EOG\n",
      "llm_load_vocab: control token:    266 '[control_264]' is not marked as EOG\n",
      "llm_load_vocab: control token:    710 '[control_708]' is not marked as EOG\n",
      "llm_load_vocab: control token:    602 '[control_600]' is not marked as EOG\n",
      "llm_load_vocab: control token:    277 '[control_275]' is not marked as EOG\n",
      "llm_load_vocab: control token:    298 '[control_296]' is not marked as EOG\n",
      "llm_load_vocab: control token:    378 '[control_376]' is not marked as EOG\n",
      "llm_load_vocab: control token:    198 '[control_196]' is not marked as EOG\n",
      "llm_load_vocab: control token:     76 '[control_74]' is not marked as EOG\n",
      "llm_load_vocab: control token:    607 '[control_605]' is not marked as EOG\n",
      "llm_load_vocab: control token:    682 '[control_680]' is not marked as EOG\n",
      "llm_load_vocab: control token:    333 '[control_331]' is not marked as EOG\n",
      "llm_load_vocab: control token:    660 '[control_658]' is not marked as EOG\n",
      "llm_load_vocab: control token:    163 '[control_161]' is not marked as EOG\n",
      "llm_load_vocab: control token:     95 '[control_93]' is not marked as EOG\n",
      "llm_load_vocab: control token:    377 '[control_375]' is not marked as EOG\n",
      "llm_load_vocab: control token:    223 '[control_221]' is not marked as EOG\n",
      "llm_load_vocab: control token:    326 '[control_324]' is not marked as EOG\n",
      "llm_load_vocab: control token:    111 '[control_109]' is not marked as EOG\n",
      "llm_load_vocab: control token:    187 '[control_185]' is not marked as EOG\n",
      "llm_load_vocab: control token:    678 '[control_676]' is not marked as EOG\n",
      "llm_load_vocab: control token:    514 '[control_512]' is not marked as EOG\n",
      "llm_load_vocab: control token:    431 '[control_429]' is not marked as EOG\n",
      "llm_load_vocab: control token:      4 '[/INST]' is not marked as EOG\n",
      "llm_load_vocab: control token:    342 '[control_340]' is not marked as EOG\n",
      "llm_load_vocab: control token:    594 '[control_592]' is not marked as EOG\n",
      "llm_load_vocab: control token:    768 '[control_766]' is not marked as EOG\n",
      "llm_load_vocab: control token:    143 '[control_141]' is not marked as EOG\n",
      "llm_load_vocab: control token:    445 '[control_443]' is not marked as EOG\n",
      "llm_load_vocab: control token:    165 '[control_163]' is not marked as EOG\n",
      "llm_load_vocab: control token:    439 '[control_437]' is not marked as EOG\n",
      "llm_load_vocab: control token:    181 '[control_179]' is not marked as EOG\n",
      "llm_load_vocab: control token:    352 '[control_350]' is not marked as EOG\n",
      "llm_load_vocab: control token:    643 '[control_641]' is not marked as EOG\n",
      "llm_load_vocab: control token:    182 '[control_180]' is not marked as EOG\n",
      "llm_load_vocab: control token:     19 '[control_17]' is not marked as EOG\n",
      "llm_load_vocab: control token:    269 '[control_267]' is not marked as EOG\n",
      "llm_load_vocab: control token:    677 '[control_675]' is not marked as EOG\n",
      "llm_load_vocab: control token:    615 '[control_613]' is not marked as EOG\n",
      "llm_load_vocab: control token:    170 '[control_168]' is not marked as EOG\n",
      "llm_load_vocab: control token:     56 '[control_54]' is not marked as EOG\n",
      "llm_load_vocab: control token:    582 '[control_580]' is not marked as EOG\n",
      "llm_load_vocab: control token:    700 '[control_698]' is not marked as EOG\n",
      "llm_load_vocab: control token:    561 '[control_559]' is not marked as EOG\n",
      "llm_load_vocab: control token:    381 '[control_379]' is not marked as EOG\n",
      "llm_load_vocab: control token:    647 '[control_645]' is not marked as EOG\n",
      "llm_load_vocab: control token:    437 '[control_435]' is not marked as EOG\n",
      "llm_load_vocab: control token:    507 '[control_505]' is not marked as EOG\n",
      "llm_load_vocab: control token:    490 '[control_488]' is not marked as EOG\n",
      "llm_load_vocab: control token:    586 '[control_584]' is not marked as EOG\n",
      "llm_load_vocab: control token:     23 '[control_21]' is not marked as EOG\n",
      "llm_load_vocab: control token:    452 '[control_450]' is not marked as EOG\n",
      "llm_load_vocab: control token:    605 '[control_603]' is not marked as EOG\n",
      "llm_load_vocab: control token:    426 '[control_424]' is not marked as EOG\n",
      "llm_load_vocab: control token:    769 '[control_767]' is not marked as EOG\n",
      "llm_load_vocab: control token:     81 '[control_79]' is not marked as EOG\n",
      "llm_load_vocab: control token:    386 '[control_384]' is not marked as EOG\n",
      "llm_load_vocab: control token:    627 '[control_625]' is not marked as EOG\n",
      "llm_load_vocab: control token:     18 '[control_16]' is not marked as EOG\n",
      "llm_load_vocab: control token:    741 '[control_739]' is not marked as EOG\n",
      "llm_load_vocab: control token:     96 '[control_94]' is not marked as EOG\n",
      "llm_load_vocab: control token:    502 '[control_500]' is not marked as EOG\n",
      "llm_load_vocab: control token:    482 '[control_480]' is not marked as EOG\n",
      "llm_load_vocab: control token:    480 '[control_478]' is not marked as EOG\n",
      "llm_load_vocab: control token:    557 '[control_555]' is not marked as EOG\n",
      "llm_load_vocab: control token:    263 '[control_261]' is not marked as EOG\n",
      "llm_load_vocab: control token:    668 '[control_666]' is not marked as EOG\n",
      "llm_load_vocab: control token:    466 '[control_464]' is not marked as EOG\n",
      "llm_load_vocab: control token:    334 '[control_332]' is not marked as EOG\n",
      "llm_load_vocab: control token:    413 '[control_411]' is not marked as EOG\n",
      "llm_load_vocab: control token:    572 '[control_570]' is not marked as EOG\n",
      "llm_load_vocab: control token:    295 '[control_293]' is not marked as EOG\n",
      "llm_load_vocab: control token:    150 '[control_148]' is not marked as EOG\n",
      "llm_load_vocab: control token:    275 '[control_273]' is not marked as EOG\n",
      "llm_load_vocab: control token:    748 '[control_746]' is not marked as EOG\n",
      "llm_load_vocab: control token:    135 '[control_133]' is not marked as EOG\n",
      "llm_load_vocab: control token:    357 '[control_355]' is not marked as EOG\n",
      "llm_load_vocab: control token:    577 '[control_575]' is not marked as EOG\n",
      "llm_load_vocab: control token:    578 '[control_576]' is not marked as EOG\n",
      "llm_load_vocab: control token:    556 '[control_554]' is not marked as EOG\n",
      "llm_load_vocab: control token:    375 '[control_373]' is not marked as EOG\n",
      "llm_load_vocab: control token:    589 '[control_587]' is not marked as EOG\n",
      "llm_load_vocab: control token:    202 '[control_200]' is not marked as EOG\n",
      "llm_load_vocab: control token:     85 '[control_83]' is not marked as EOG\n",
      "llm_load_vocab: control token:    278 '[control_276]' is not marked as EOG\n",
      "llm_load_vocab: control token:    169 '[control_167]' is not marked as EOG\n",
      "llm_load_vocab: control token:    208 '[control_206]' is not marked as EOG\n",
      "llm_load_vocab: control token:    488 '[control_486]' is not marked as EOG\n",
      "llm_load_vocab: control token:    337 '[control_335]' is not marked as EOG\n",
      "llm_load_vocab: control token:    733 '[control_731]' is not marked as EOG\n",
      "llm_load_vocab: control token:    109 '[control_107]' is not marked as EOG\n",
      "llm_load_vocab: control token:    547 '[control_545]' is not marked as EOG\n",
      "llm_load_vocab: control token:    350 '[control_348]' is not marked as EOG\n",
      "llm_load_vocab: control token:    132 '[control_130]' is not marked as EOG\n",
      "llm_load_vocab: control token:    114 '[control_112]' is not marked as EOG\n",
      "llm_load_vocab: control token:    248 '[control_246]' is not marked as EOG\n",
      "llm_load_vocab: control token:    328 '[control_326]' is not marked as EOG\n",
      "llm_load_vocab: control token:    104 '[control_102]' is not marked as EOG\n",
      "llm_load_vocab: control token:    449 '[control_447]' is not marked as EOG\n",
      "llm_load_vocab: control token:    711 '[control_709]' is not marked as EOG\n",
      "llm_load_vocab: control token:    715 '[control_713]' is not marked as EOG\n",
      "llm_load_vocab: control token:    358 '[control_356]' is not marked as EOG\n",
      "llm_load_vocab: control token:    746 '[control_744]' is not marked as EOG\n",
      "llm_load_vocab: control token:    385 '[control_383]' is not marked as EOG\n",
      "llm_load_vocab: control token:    720 '[control_718]' is not marked as EOG\n",
      "llm_load_vocab: control token:      2 '</s>' is not marked as EOG\n",
      "llm_load_vocab: control token:    460 '[control_458]' is not marked as EOG\n",
      "llm_load_vocab: control token:    632 '[control_630]' is not marked as EOG\n",
      "llm_load_vocab: control token:    296 '[control_294]' is not marked as EOG\n",
      "llm_load_vocab: control token:    240 '[control_238]' is not marked as EOG\n",
      "llm_load_vocab: control token:    361 '[control_359]' is not marked as EOG\n",
      "llm_load_vocab: control token:    504 '[control_502]' is not marked as EOG\n",
      "llm_load_vocab: control token:    149 '[control_147]' is not marked as EOG\n",
      "llm_load_vocab: control token:      1 '<s>' is not marked as EOG\n",
      "llm_load_vocab: control token:    219 '[control_217]' is not marked as EOG\n",
      "llm_load_vocab: control token:    106 '[control_104]' is not marked as EOG\n",
      "llm_load_vocab: control token:    669 '[control_667]' is not marked as EOG\n",
      "llm_load_vocab: control token:    411 '[control_409]' is not marked as EOG\n",
      "llm_load_vocab: control token:    546 '[control_544]' is not marked as EOG\n",
      "llm_load_vocab: control token:    379 '[control_377]' is not marked as EOG\n",
      "llm_load_vocab: control token:    209 '[control_207]' is not marked as EOG\n",
      "llm_load_vocab: control token:    110 '[control_108]' is not marked as EOG\n",
      "llm_load_vocab: control token:    681 '[control_679]' is not marked as EOG\n",
      "llm_load_vocab: control token:    153 '[control_151]' is not marked as EOG\n",
      "llm_load_vocab: control token:    457 '[control_455]' is not marked as EOG\n",
      "llm_load_vocab: control token:     91 '[control_89]' is not marked as EOG\n",
      "llm_load_vocab: control token:    224 '[control_222]' is not marked as EOG\n",
      "llm_load_vocab: control token:    653 '[control_651]' is not marked as EOG\n",
      "llm_load_vocab: control token:    694 '[control_692]' is not marked as EOG\n",
      "llm_load_vocab: control token:    316 '[control_314]' is not marked as EOG\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 771\n",
      "llm_load_vocab: token to piece cache size = 0.1731 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32768\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 7.25 B\n",
      "llm_load_print_meta: model size       = 5.54 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = Mistral-7B-Instruct-v0.3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 781 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 2 '</s>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q6_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  5671.02 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 16000\n",
      "llama_new_context_with_model: n_ctx_per_seq = 16000\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 1000000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (16000) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 16000, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =  2000.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 2000.00 MiB, K (f16): 1000.00 MiB, V (f16): 1000.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  1063.26 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_data/calibration_data.txt', 'quantize.imatrix.chunks_count': '228', 'quantize.imatrix.file': '/models/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3.imatrix', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.pre': 'default', 'llama.context_length': '32768', 'general.name': 'Mistral-7B-Instruct-v0.3', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '18', 'llama.vocab_size': '32768', 'llama.rope.dimension_count': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n",
      "2025-01-25 15:10:37,726 - global - INFO - Model loaded successfully.\n",
      "2025-01-25 15:10:37,727 - global - INFO - [BUILT LLAMA LLM]: \n",
      "        [LLAMA LLM]\n",
      "        model_path: ./models/mistral-7B-Instruct-v0.3-Q6_K.gguf\n",
      "        context_window_size: 16000\n",
      "        \n",
      "2025-01-25 15:10:37,733 - global - INFO - Database connected successfully with descriptions.\n",
      "2025-01-25 15:10:37,734 - global - INFO - Reflected Table Info:\n",
      "\n",
      "CREATE TABLE clients (\n",
      "\tclnt_id INTEGER NOT NULL, \n",
      "\tclnt_name VARCHAR NOT NULL, \n",
      "\tPRIMARY KEY (clnt_id)\n",
      ")\n",
      "\n",
      "\n",
      "CREATE TABLE transactions (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tclnt_id INTEGER NOT NULL, \n",
      "\tbank_id INTEGER NOT NULL, \n",
      "\tacc_id INTEGER NOT NULL, \n",
      "\ttxn_id INTEGER NOT NULL, \n",
      "\ttxn_date DATETIME NOT NULL, \n",
      "\t\"desc\" VARCHAR, \n",
      "\tamt FLOAT NOT NULL, \n",
      "\tcat VARCHAR, \n",
      "\tmerchant VARCHAR, \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "Table transactions:\n",
      "  id INTEGER\n",
      "  clnt_id INTEGER  # Client ID\n",
      "  bank_id INTEGER  # Bank ID\n",
      "  acc_id INTEGER  # Account ID\n",
      "  txn_id INTEGER  # Transaction ID\n",
      "  txn_date DATETIME  # Transaction date\n",
      "  desc VARCHAR  # Description\n",
      "  amt FLOAT  # Amount\n",
      "  cat VARCHAR  # Category of the transaction\n",
      "  merchant VARCHAR  # Merchant of the transaction\n",
      "\n",
      "Table clients:\n",
      "  clnt_id INTEGER  # Client ID\n",
      "  clnt_name VARCHAR  # Client Name\n",
      "2025-01-25 15:10:37,735 - global - INFO - Banking assistant created successfully.\n",
      "2025-01-25 15:10:37,735 - global - INFO - [New LLMCHAIN]:\n",
      "2025-01-25 15:10:37,735 - global - INFO - MODEL: [RUNTIME WINDOW_SIZE: 16000, MAX_TOKENS:200, TEMPERATURE: 0.4]:\n",
      "2025-01-25 15:10:37,735 - global - INFO - CHAIN: [PROMPT: input_variables=['input', 'table_info', 'top_k'] input_types={} partial_variables={} template='You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date(\\'now\\') function to get the current date, if the question involves \"today\".\\nImportant: Do not include \"Question: \" in your answer. You are not allowed to generate Questions.\\nImportant: You should never include ``` in the generated SQL Query as this is not a valid syntax. e.g. ``` SELECT * FROM transations ``` is not allowed.\\n\\nThe below are correct examples of how you should reason about your answer:\\nCorrect Example 1:\\nUser: How many records are there in \\'transactions\\' table?\\nSQL Query: SELECT COUNT(*) FROM transactions;\\nSQL Query Result: 5\\nAssistant LLM: There are two records in the transactions table\\n\\nCorrect Example 2:\\nUser: Can you filter for transactions with merchant \\'1INFINITE\\'?\\nSQL Query: SELECT * FROM transactions WHERE merchant=\\'1INFINITE\\' LIMIT 5;\\nSQL Query Result: [\\n    4\\t28\\t1\\t1\\t108\\t2023-07-25 00:00:00\\t1INFINITELOOP@ 07/25 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA\\t59.1\\tShops\\t1INFINITE,\\n    5\\t28\\t1\\t1\\t136\\t2023-08-14 00:00:00\\t1INFINITELOOP@ 08/14 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA\\t4.924\\tShops\\t1INFINITE\\n]\\nAssistant LLM: There are 10 rows where merchant is \\'1INFINITE\\'\\n\\nCorrect Example 3:\\nUser: Can you show me transactions for \\'Julia Johnson\\'?\\nSQL Query: SELECT * FROM transactions t JOIN clients c ON t.clnt_id=c.clnt_id WHERE c.clnt_name=\\'Julia Johnson\\' LIMIT 5;\\nSQL Query Result: [\\n    1\\t6\\t1\\t1\\t54\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    2\\t6\\t1\\t1\\t27\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    3\\t6\\t1\\t1\\t11\\t2023-08-01 00:00:00\\tCLOC Advance\\t2.268\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    100158\\t6\\t1\\t1\\t42\\t2023-07-31 00:00:00\\tPos Adjustment - Cr Brigit New York NY US\\t10.0\\tLoans\\tNULL\\t6\\tJulia Johnson,\\n    100159\\t6\\t1\\t1\\t48\\t2023-06-16 00:00:00\\tPos Adjustment - Cr Empower Finance, I Visa Direct CA US\\t20.0\\tLoans\\tEmpower\\t6\\tJulia Johnson\\n]\\nAssistant LLM: Julia Johnson has 5 transactions in total.\\n\\nCorrect Example 4:\\nUser: Can you show total amount of money for transactions for \\'Julia Johnson\\'?\\nSQL Query: SELECT SUM(t.amt) FROM transactions t JOIN clients c ON t.clnt_id=c.clnt_id WHERE c.clnt_name=\\'Julia Johnson\\' LIMIT 5;\\nSQL Query Result: [\\n    1\\t6\\t1\\t1\\t54\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    2\\t6\\t1\\t1\\t27\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    3\\t6\\t1\\t1\\t11\\t2023-08-01 00:00:00\\tCLOC Advance\\t2.268\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    100158\\t6\\t1\\t1\\t42\\t2023-07-31 00:00:00\\tPos Adjustment - Cr Brigit New York NY US\\t10.0\\tLoans\\tNULL\\t6\\tJulia Johnson,\\n    100159\\t6\\t1\\t1\\t48\\t2023-06-16 00:00:00\\tPos Adjustment - Cr Empower Finance, I Visa Direct CA US\\t20.0\\tLoans\\tEmpower\\t6\\tJulia Johnson\\n]\\nAssistant LLM: Julia Johnson has 5 transactions in total.\\n\\n\\nThe below are incorrect examples:\\nIncorrect Example 1:\\nUser: How many records are there in \\'transactions\\' table?\\nSQL Query: ```SELECT COUNT(*) FROM transactions;```\\nSQL Query Result: Incorrect SQL syntax due to backticks\\nAssistant LLM: Incorrect SQL syntax\\n\\nIncorrect Example 2:\\nUser: How many records are there in \\'clients\\' table?\\nSQL Query: ```SELECT COUNT(*) FROM transactions;```\\nSQL Query Result: Incorrect SQL syntax due to backticks\\nAssistant LLM: Incorrect SQL syntax\\n\\nHere is a list of keywords you cannot use:\\nINTERVAL\\nSERIAL\\nFULL OUTER JOIN\\nRIGHT OUTER JOIN\\nMERGE\\nWINDOW\\nRANK(), DENSE_RANK(), NTILE()\\nFOR UPDATE\\nSAVEPOINT (partially, only a basic version)\\nFETCH FIRST / LIMIT WITH TIES\\nCROSS APPLY, OUTER APPLY\\nARRAY (array data type)\\nJSON (advanced JSON functions)\\nRECURSIVE (common table expressions with recursion)\\nWITH CHECK OPTION\\nPARTITION BY (for window functions)\\nIF EXISTS in DROP TABLE and DROP INDEX\\nTRUNCATE TABLE\\nALTER COLUMN\\nREPLACE INTO (non-UPSERT form)\\nCONSTRAINT CHECK on ALTER TABLE\\nEXCLUDE CONSTRAINT\\nCLUSTER\\nAUTOMATIC (specific storage options)\\nFOREIGN DATA WRAPPER\\nUSER DEFINED TYPES (complex types)\\n\\nOnly use the following tables:\\n{table_info}\\n\\nUse the following format to generate your answer:\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nImportant: You must only answer the question provided by the user. Do not include another question in your answer.\\nQuestion: {input}\\n']:\n",
      "\n",
      "Welcome to the Banking Assistant!\n",
      "Type your natural language request below, or type 'exit' to quit.\n",
      "\n",
      "Your Query: ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bot/personal_proj/moneylion-ml-assessment/main.py\", line 565, in <module>\n",
      "    main_run_loop(use_memory=args.memory)\n",
      "  File \"/home/bot/personal_proj/moneylion-ml-assessment/main.py\", line 515, in main_run_loop\n",
      "    chat_loop(\n",
      "  File \"/home/bot/personal_proj/moneylion-ml-assessment/main.py\", line 314, in chat_loop\n",
      "    user_input = input(\"\\nYour Query: \").strip()  # Normalize user input\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# default usage:\n",
    "# ! python main.py\n",
    "\n",
    "#  or if you face relative import issues:\n",
    "# ! python -m main\n",
    "# ! python -m main --simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate a chat run against a pre-defiuned set of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python main.py --simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO RUN Benchmarking tests against a pre-defined set of questions and sets of pre-defined configurations on the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python main.py --benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If memory is enabled, which means the LLM chain is not stateless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python main.py --memory\n",
    "# ! python main.py --simulate --memory\n",
    "# ! python main.py --benchmark --memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUSTIFICATIONS / THOUGHT PROCESS  / CONSIDERATIONS\n",
    "- TODO: write justificatijon about why i tried to inherit the sql database chain from lagnchain for a retry mechanism on sql query failures even though there is a trivial query chcker mechanism in place already\n",
    "- TODO: one final run throgujupyter notebook# \n",
    "\n",
    "### BACKGROUND CONSIDERATIONS\n",
    "-  As I come from a backend-heavy background with skills in ML /AI/LLM as well, the code in this repo is aimed to serve as a strong foundation to fine tune different configurations of the LLM chain that leads to different generation behaviours for the final answer. \n",
    "-  The notebook here merely serves as a demonstration of usage here and my justifications of my thought process, and however not experiments on fine-tuning the Model on the available data. The experiments on prompt engineering is done in the code itself with a benchmarking feature that could be used during runtime.\n",
    "-  This is in order to understand what kind of parameters work best if for example we are bound by certain parameter constraints which is very relevant in production, the most straightfoward one being hardware constraints in my case. We can also have other constraints such as not being able to use state of the art closed-sourced models like GPT-4 which is one of the most powerful for NL2SQL generation.\n",
    "\n",
    "### INITIAL JUSTIFICATION OF MY DIRECTION\n",
    "- A simple but effective brute force method to the given problem statement of building an LLM assistant tasked with helping users with enqueries regarding their personal transactions will be to first query all of the relevant users' personal data after performing an SQL query on the database (moneylion's transaction data) and then feed it to the LLM to perform summarisation and analysis for the users' data. However:\n",
    "  - this violates data sensivity if we were to dump the data in the context window of a non-locally-hosted LLM\n",
    "  - the amount of data needed to dump into the LLM can get very large easily especially if the data is complex and requires a lot of JOIN operations\n",
    "  - dumping the data before determining what kind of data is needed by the LLM by forming a query first can be fast, but very expensive in terms of LLM compute tokens\n",
    "- by using coding extensively in the implementation of the LLM pipeline, I can also define graceful fallback mechanisms and hook onto other potential backend services that might prove to be useful in a microservices architecture pattern as well!\n",
    "  - using message queues could be great for a very heavy backend load system and this could be paired with the LLM as a future consideration!\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "### Step by Step Approach In Tackling the problem\n",
    "1. I know this is a NL2SQL problem, so i first look at the open source models that are still popular for such tsks\n",
    "2. I tried to full models at first, but I couldnt due to memory constraints, now I remember there are quantized / smaller versions of these models that I can load with `llama-cpp` a very popular library to load LLM models from local files and is flexible in terms of hardware constraints\n",
    "   1. this had led me to rethink me whole approach and refactor it to make it even lower level to make llama-cpp models be compatible to be loaded with langchain, I needed to implement my custom subclass of langchain's base LLM class\n",
    "3. Now I added more code to ensure I can run the LLM minimally with the LLM SQL Database Chain setup, `database + LLM = SQL Database Chain` in order to talk to our `data.csv` files that are loaded into a sqlite local DB\n",
    "4. I knew that smaller models as well as coupled with lots of configurations are not guaranteed to work perfectly out of the box, hece affecting stability, hence, I introduced code to benchmark different configurations to evaluate the best parameters to use for my LLM\n",
    "   1.  these configurations include experimenting with different open source LLM models, runtime context window sizes, temperature, prompt templates, etc.\n",
    "   2.  the logs of these runs can be found in `archive` wihich store much older runs when my code is still in its infancy\n",
    "   3.  `benchmark` stores much newer runs featuring more recent attempts at improving the  system as a whole\n",
    "   4. there is the `memory` option when calling `chat_loop` however, as it is not stable yet, this is not part of the parameter tuning experiment, but could be done so after the feature is stabilised\n",
    "5.  I still cannot get a perfect result with any of the configurations, threre are minor errors in the SQL queries generated but the understanding of the natural language to be translated to SQL is decent\n",
    "6.  Now I remembered that the meta data of the columns are not really passed into the LLM, the default SQLDatabase.tableinfo shouldnt have too much metadata passed into the chain, hence I start to make changes to the code to accomodate for that, this is done so by\n",
    "    1. including meta data info inside the SQLAlcehmy ORM table schema classes\n",
    "    2. parse the info in side the columns into a string using `generate_table_info_from_orm_models`\n",
    "    3. Note that the original implementation of the SQLDatabaseCHain prompt template only passes the column names (unless there is an intelligent column metadata generation system off SQL DDL code that I am not aware of)\n",
    "    4. However, I wasnt aware that it is not as simple as modifying the prompt template, the table_info is actually passed from `sqlalchemy` and the logic is inside `SQLDatabase` in langchain code, so I have to override it with a subclass which is very tedious and hacky I admit! So this took longer than Expected\n",
    " 7. After being able to inject the table meta data as prompt into the LLM chain, I found out that the reason why the LLM keeps trying to continue after is partially due to how `SQLDatabaseChain` injects sample data, which might confuse the LLM, so I overriden `SQLDatabase` to remove that as well and experiment with the benchmark question set\n",
    " 8. However, there are still a few SQL failures resulting from the SQL LLM Chain not being able to understand that certain scenarios require `JOIN` queries, this is definitely the hardest obstacle to tackle because `JOIN` queries are more complex than standard queries which means harder for the LLM to understand the context in which to generate the complex `JOIN` query\n",
    "    1. I suspect with the proposed modification on generation of `table_info` in my custom `SQLDatabase` subclass, I could dump some relationship info regarding FOREIGN key pair relationships to include that in the context and encourage the LLM to perform `JOIN` with the additional context\n",
    "    2. also this can be mixed with a feedback retry loop so tha the LLM knows it has failed and will try again with the failure trace dumped into its context window now\n",
    "    3. We could also modify the code to opt to use `SQLDatabaseSequentialChain` which will predict the tables to use first before generating the SQL query\n",
    "    4. similar to a `SQLDatabaseSequentialChain` implementation maybe we could add a simple preprocessing layer to match the user query against available table names in order to narrow down which tables to use and dump that as a hint into the conversation history alongside the query\n",
    " 9. In an attempt to improve my LLM chain's output, I later tried:\n",
    "    1.  Refining my prompt template to have few shot prompting techniques to include some postive and negative examples in my prompt template.\n",
    "    2.  Noticed that there is a use_query_checker setting when initialising the `SQLDatabaseChain` instance, which introduces another layer of checking of the validity of the SQL syntax\n",
    "    3.  this yielded better results, however I still have troubles making the sql command be a valid SQL that would be executed after passing through the `use_query_checker` layer because it is not in RAW SQL code\n",
    "    4.  Now I figured to also modify the query_checker prompt to make sure it only outputs raw SQL code and the results are much better and much less prone to SQL errors!\n",
    "    5.  However, with the retry mechanism, it seems that the query checking layer has lost some of the information about the table, and it lost track of what columns the original query contained or the original query itself did not narrow down the right columns to use\n",
    "        1.  Although the query syntax is correct, the output is still some deviation from the correct truth\n",
    "    6.  to this, I propose another layer in the chain to narrow down the columns to use first\n",
    "7.  From my findings and a evidence-backed deductions, the optimal chain might look something like this:\n",
    "    1.  NL to NL (narrow down columns needed): narrow down the columns needed in the SQL query first in the initial user input\n",
    "    2.  NL to SQL (generate initial SQL): generate the SQL to run the database queries\n",
    "    3.  SQL to SQL (check the query for syntax errors depending on which database dialect e.g. sqlite): verify the SQL generated and output the corrected SQL code\n",
    "    4.  (there could be more chain components depending on how complex the workflow is, one might start to consider langgraph)\n",
    "    5.  SQL to NL (run the db query and output the answer): form the final answer in Natural language back to user based on queried results from the database.\n",
    "\n",
    "### CONCLUSION\n",
    "- one may find the approach i explored is more on the coding-side of things rather than heavy prompt engineering. This is because yet again, this is an open ended challenege and the current prompt engineering techniques for NL2SQL generation might work with a snmall number of tables, one would find prompt engineering techniques becomning harder to maintain as databases as systems get larger and more complex.\n",
    "\n",
    "- an example is that oif there are too many databases and tit is an overall complex system to query from, few shot prompting in NL2SQL might not prove to be worth it, as there could be many different NL2SQL patterns wihich make one argue that it would be far better to focus on the LLM chain pipelnine and the overall hosted model's capability. Prompt engineering can only get you so far in a non-reaosning LLM paradigm for the current trend set by unless we employ open-source reasoning models and that perhaps would be a completely different paradigm shift in terms of the whole `[NL2SQL2NL]` pipel\n",
    "\n",
    "- assuming that I will be working heavily in / with backend in the future integrating LLM capabiltiies into existing backend systems , this is why my approch is heavily tuned towards using coding / deploying chaining pipelines to solve the problem statement\n",
    "\n",
    "- the code can be also easily extended to encompass more tools in the LLM chain [NL > SQL > NL] to become  [NL > SQL >  .... > NL]\n",
    "\n",
    "- from my findings when experimenting with distilled version of mistral-7-b which is not as powerful as the full model, i found it prompt engineering techniques to be unreliable as a less powerful model can reason far worse than a full model. This results in a very drastic answer outcome for every change to the prompt template. In the benchmark reports, one will find that the LLM returns the correct \n",
    "\n",
    "\n",
    "- after experimenting with more advanced models of mistral-7b the syntax of SQL code looks fine, howevever, it easily fails at tasks requiring data across multiple tables, this leads me to believe aneven more advanced pipeline is needed ,we could consider looking into SQLDatabaseSequentialChain from langchain\n",
    "\n",
    "- I have some regrets on why not starting with the most fundamental `Chain` class from langchain's offering which might make it more customisable and less redious to overwrite some logic indeed! However, this was mostly due to personal preference to incorporate a substantial amount of framework/library to a certain degree in case maintenance of self-defined code gets tedious at most times. I have definitely encountered such issues when fixing vulnerability / bug patches and these issues comes up every other month!\n",
    "\n",
    "- I hope what I showcased here comes across as a fun mix of backend engineering plus prompt engineering techniques which facilitates a healthy mix of both because deploying to production would certainly require one to be well-versed on both ends.\n",
    "\n",
    "- even though the current techniques prove to be good enough for the igven data set, it should not perform well across a large database system with a lot of tables, I hypothesize that when that happens a more complex SQL chain will be required which comes up with a trade-off in terms of more compute tokens needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "after numerous long running iterative benchmark tests, I found that the combinations that work the best includes:\n",
    "- specifically, it has passed all 5/5 benchmark questions that I have given it with flying col\n",
    "- using a bigger mistral-7b most up-to-date model `mistral-7b-v0.3-Q6-K` with `16000` runtime context window, strangely enough, `32000` didnt perform that well\n",
    "- using `_sqliteprompt7` combined with `PROMPT_SUFFIX4`\n",
    "- you can find out more prompts that I have used inside `myprompts.py`\n",
    "- the entire unfilled prompt is something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_chain_prompt_template = \"\"\" \n",
    "You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
    "Important: Do not include \"Question: \" in your answer. You are not allowed to generate Questions.\n",
    "Important: You should never include ``` in the generated SQL Query as this is not a valid syntax. e.g. ``` SELECT * FROM transations ``` is not allowed.\n",
    "\n",
    "The below are correct examples of how you should reason about your answer:\n",
    "Correct Example 1:\n",
    "User: How many records are there in 'transactions' table?\n",
    "SQL Query: SELECT COUNT(*) FROM transactions;\n",
    "SQL Query Result: 5\n",
    "Assistant LLM: There are two records in the transactions table\n",
    "\n",
    "Correct Example 2:\n",
    "User: Can you filter for transactions with merchant '1INFINITE'?\n",
    "SQL Query: SELECT * FROM transactions WHERE merchant='1INFINITE' LIMIT 5;\n",
    "SQL Query Result: [\n",
    "    4\t28\t1\t1\t108\t2023-07-25 00:00:00\t1INFINITELOOP@ 07/25 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA\t59.1\tShops\t1INFINITE,\n",
    "    5\t28\t1\t1\t136\t2023-08-14 00:00:00\t1INFINITELOOP@ 08/14 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA\t4.924\tShops\t1INFINITE\n",
    "]\n",
    "Assistant LLM: There are 10 rows where merchant is '1INFINITE'\n",
    "\n",
    "Correct Example 3:\n",
    "User: Can you show me transactions for 'Julia Johnson'?\n",
    "SQL Query: SELECT * FROM transactions t JOIN clients c ON t.clnt_id=c.clnt_id WHERE c.clnt_name='Julia Johnson' LIMIT 5;\n",
    "SQL Query Result: [\n",
    "    1\t6\t1\t1\t54\t2023-07-31 00:00:00\tCLOC Advance\t6.286\tShops\tNULL\t6\tJulia Johnson,\n",
    "    2\t6\t1\t1\t27\t2023-07-31 00:00:00\tCLOC Advance\t6.286\tShops\tNULL\t6\tJulia Johnson,\n",
    "    3\t6\t1\t1\t11\t2023-08-01 00:00:00\tCLOC Advance\t2.268\tShops\tNULL\t6\tJulia Johnson,\n",
    "    100158\t6\t1\t1\t42\t2023-07-31 00:00:00\tPos Adjustment - Cr Brigit New York NY US\t10.0\tLoans\tNULL\t6\tJulia Johnson,\n",
    "    100159\t6\t1\t1\t48\t2023-06-16 00:00:00\tPos Adjustment - Cr Empower Finance, I Visa Direct CA US\t20.0\tLoans\tEmpower\t6\tJulia Johnson\n",
    "]\n",
    "Assistant LLM: Julia Johnson has 5 transactions in total.\n",
    "\n",
    "Correct Example 4:\n",
    "User: Can you show total amount of money for transactions for 'Julia Johnson'?\n",
    "SQL Query: SELECT SUM(t.amt) FROM transactions t JOIN clients c ON t.clnt_id=c.clnt_id WHERE c.clnt_name='Julia Johnson' LIMIT 5;\n",
    "SQL Query Result: [\n",
    "    1\t6\t1\t1\t54\t2023-07-31 00:00:00\tCLOC Advance\t6.286\tShops\tNULL\t6\tJulia Johnson,\n",
    "    2\t6\t1\t1\t27\t2023-07-31 00:00:00\tCLOC Advance\t6.286\tShops\tNULL\t6\tJulia Johnson,\n",
    "    3\t6\t1\t1\t11\t2023-08-01 00:00:00\tCLOC Advance\t2.268\tShops\tNULL\t6\tJulia Johnson,\n",
    "    100158\t6\t1\t1\t42\t2023-07-31 00:00:00\tPos Adjustment - Cr Brigit New York NY US\t10.0\tLoans\tNULL\t6\tJulia Johnson,\n",
    "    100159\t6\t1\t1\t48\t2023-06-16 00:00:00\tPos Adjustment - Cr Empower Finance, I Visa Direct CA US\t20.0\tLoans\tEmpower\t6\tJulia Johnson\n",
    "]\n",
    "Assistant LLM: Julia Johnson has 5 transactions in total.\n",
    "\n",
    "\n",
    "The below are incorrect examples:\n",
    "Incorrect Example 1:\n",
    "User: How many records are there in 'transactions' table?\n",
    "SQL Query: ```SELECT COUNT(*) FROM transactions;```\n",
    "SQL Query Result: Incorrect SQL syntax due to backticks\n",
    "Assistant LLM: Incorrect SQL syntax\n",
    "\n",
    "Incorrect Example 2:\n",
    "User: How many records are there in 'clients' table?\n",
    "SQL Query: ```SELECT COUNT(*) FROM transactions;```\n",
    "SQL Query Result: Incorrect SQL syntax due to backticks\n",
    "Assistant LLM: Incorrect SQL syntax\n",
    "\n",
    "Here is a list of keywords you cannot use:\n",
    "INTERVAL\n",
    "SERIAL\n",
    "FULL OUTER JOIN\n",
    "RIGHT OUTER JOIN\n",
    "MERGE\n",
    "WINDOW\n",
    "RANK(), DENSE_RANK(), NTILE()\n",
    "FOR UPDATE\n",
    "SAVEPOINT (partially, only a basic version)\n",
    "FETCH FIRST / LIMIT WITH TIES\n",
    "CROSS APPLY, OUTER APPLY\n",
    "ARRAY (array data type)\n",
    "JSON (advanced JSON functions)\n",
    "RECURSIVE (common table expressions with recursion)\n",
    "WITH CHECK OPTION\n",
    "PARTITION BY (for window functions)\n",
    "IF EXISTS in DROP TABLE and DROP INDEX\n",
    "TRUNCATE TABLE\n",
    "ALTER COLUMN\n",
    "REPLACE INTO (non-UPSERT form)\n",
    "CONSTRAINT CHECK on ALTER TABLE\n",
    "EXCLUDE CONSTRAINT\n",
    "CLUSTER\n",
    "AUTOMATIC (specific storage options)\n",
    "FOREIGN DATA WRAPPER\n",
    "USER DEFINED TYPES (complex types)\n",
    "\n",
    "\n",
    "Use the following format to generate your answer:\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "\n",
    "Important: You must only answer the question provided by the user. Do not include another question in your answer.\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "\n",
    "query_checker_prompt_template = \"\"\"\n",
    "{query}\n",
    "Double check the {dialect} query above for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\n",
    "\n",
    "Important: Output the final SQL query only. Do not include any comments. Do not include any use of ``` and ` in your output code.\n",
    "\n",
    "SQL Query: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST RUN LOGS:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "benchmark report can be found at (./2025-01-25_10-26-53/benchmark_model_mistral-7B-Instruct-v03-Q6_K_context_16000_prompt_4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Question 1: How many rows are in the 'transactions' table?\n",
    "Answer 1: There are 257063 rows in the 'transactions' table.\n",
    "Question 2: Can you filter for transactions with merchant '1INFINITE'?\n",
    "Answer 2: There are 5 transactions where the merchant is '1INFINITE'. Here are the details:\n",
    "\n",
    "1. Transaction ID: 108, Amount: 59.1, Category: Shops, Date: 2023-07-25\n",
    "2. Transaction ID: 136, Amount: 4.924, Category: Shops, Date: 2023-08-14\n",
    "3. Transaction ID: 86, Amount: 98.5, Category: Shops, Date: 2023-08-21\n",
    "4. Transaction ID: 43, Amount: 59.1, Category: Shops, Date: 2023-08-21\n",
    "5. Transaction ID: 119, Amount: 59.1, Category: Shops, Date:\n",
    "Question 3: How much did Julia Johnson spend last week?\n",
    "Answer 3: Julia Johnson spent 5747.74 USD last week.\n",
    "Question 4: How much did clnt_id=6 spend last week?\n",
    "Answer 4: Clnt_id 6 did not make any transactions last week.\n",
    "Question 5: What is the amount Julia Johnson have spent on Uber in the last 5 months?\n",
    "Answer 5: Julia Johnson have not spent any money on Uber in the last 5 months.\n",
    "Time Taken: 00:26:10\n",
    "Error Count: 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the partial log that is logged in the `global.log` file during the run for this particular iteration for benchmarking test, due to the global.log file is constantly being modified I cannot paste the whole file here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2025-01-25 11:05:46,107 - global - INFO - Database connected successfully with descriptions.\\n2025-01-25 11:05:46,108 - global - INFO - Reflected Table Info:\\n\\nCREATE TABLE clients (\\n\\tclnt_id INTEGER NOT NULL, \\n\\tclnt_name VARCHAR NOT NULL, \\n\\tPRIMARY KEY (clnt_id)\\n)\\n\\n\\nCREATE TABLE transactions (\\n\\tid INTEGER NOT NULL, \\n\\tclnt_id INTEGER NOT NULL, \\n\\tbank_id INTEGER NOT NULL, \\n\\tacc_id INTEGER NOT NULL, \\n\\ttxn_id INTEGER NOT NULL, \\n\\ttxn_date DATETIME NOT NULL, \\n\\t\"desc\" VARCHAR, \\n\\tamt FLOAT NOT NULL, \\n\\tcat VARCHAR, \\n\\tmerchant VARCHAR, \\n\\tPRIMARY KEY (id)\\n)\\n\\nTable transactions:\\n  id INTEGER\\n  clnt_id INTEGER  # Client ID\\n  bank_id INTEGER  # Bank ID\\n  acc_id INTEGER  # Account ID\\n  txn_id INTEGER  # Transaction ID\\n  txn_date DATETIME  # Transaction date\\n  desc VARCHAR  # Description\\n  amt FLOAT  # Amount\\n  cat VARCHAR  # Category of the transaction\\n  merchant VARCHAR  # Merchant of the transaction\\n\\nTable clients:\\n  clnt_id INTEGER  # Client ID\\n  clnt_name VARCHAR  # Client Name\\n2025-01-25 11:05:46,109 - global - INFO - Banking assistant created successfully.\\n2025-01-25 11:05:46,109 - global - INFO - [New LLMCHAIN]:\\n2025-01-25 11:05:46,109 - global - INFO - MODEL: [RUNTIME WINDOW_SIZE: 16000, MAX_TOKENS:200, TEMPERATURE: 0.4]:\\n2025-01-25 11:05:46,110 - global - INFO - CHAIN: [PROMPT: input_variables=[\\'input\\', \\'table_info\\', \\'top_k\\'] input_types={} partial_variables={} template=\\'You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date(\\'now\\') function to get the current date, if the question involves \"today\".\\nImportant: Do not include \"Question: \" in your answer. You are not allowed to generate Questions.\\nImportant: You should never include ``` in the generated SQL Query as this is not a valid syntax. e.g. ``` SELECT * FROM transations ``` is not allowed.\\n\\nThe below are correct examples of how you should reason about your answer:\\nCorrect Example 1:\\nUser: How many records are there in \\'transactions\\' table?\\nSQL Query: SELECT COUNT(*) FROM transactions;\\nSQL Query Result: 5\\nAssistant LLM: There are two records in the transactions table\\n\\nCorrect Example 2:\\nUser: Can you filter for transactions with merchant \\'1INFINITE\\'?\\nSQL Query: SELECT * FROM transactions WHERE merchant=\\'1INFINITE\\' LIMIT 5;\\nSQL Query Result: [\\n    4\\t28\\t1\\t1\\t108\\t2023-07-25 00:00:00\\t1INFINITELOOP@ 07/25 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA\\t59.1\\tShops\\t1INFINITE,\\n    5\\t28\\t1\\t1\\t136\\t2023-08-14 00:00:00\\t1INFINITELOOP@ 08/14 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA\\t4.924\\tShops\\t1INFINITE\\n]\\nAssistant LLM: There are 10 rows where merchant is \\'1INFINITE\\'\\n\\nCorrect Example 3:\\nUser: Can you show me transactions for \\'Julia Johnson\\'?\\nSQL Query: SELECT * FROM transactions t JOIN clients c ON t.clnt_id=c.clnt_id WHERE c.clnt_name=\\'Julia Johnson\\' LIMIT 5;\\nSQL Query Result: [\\n    1\\t6\\t1\\t1\\t54\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    2\\t6\\t1\\t1\\t27\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    3\\t6\\t1\\t1\\t11\\t2023-08-01 00:00:00\\tCLOC Advance\\t2.268\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    100158\\t6\\t1\\t1\\t42\\t2023-07-31 00:00:00\\tPos Adjustment - Cr Brigit New York NY US\\t10.0\\tLoans\\tNULL\\t6\\tJulia Johnson,\\n    100159\\t6\\t1\\t1\\t48\\t2023-06-16 00:00:00\\tPos Adjustment - Cr Empower Finance, I Visa Direct CA US\\t20.0\\tLoans\\tEmpower\\t6\\tJulia Johnson\\n]\\nAssistant LLM: Julia Johnson has 5 transactions in total.\\n\\nCorrect Example 4:\\nUser: Can you show total amount of money for transactions for \\'Julia Johnson\\'?\\nSQL Query: SELECT SUM(t.amt) FROM transactions t JOIN clients c ON t.clnt_id=c.clnt_id WHERE c.clnt_name=\\'Julia Johnson\\' LIMIT 5;\\nSQL Query Result: [\\n    1\\t6\\t1\\t1\\t54\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    2\\t6\\t1\\t1\\t27\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    3\\t6\\t1\\t1\\t11\\t2023-08-01 00:00:00\\tCLOC Advance\\t2.268\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    100158\\t6\\t1\\t1\\t42\\t2023-07-31 00:00:00\\tPos Adjustment - Cr Brigit New York NY US\\t10.0\\tLoans\\tNULL\\t6\\tJulia Johnson,\\n    100159\\t6\\t1\\t1\\t48\\t2023-06-16 00:00:00\\tPos Adjustment - Cr Empower Finance, I Visa Direct CA US\\t20.0\\tLoans\\tEmpower\\t6\\tJulia Johnson\\n]\\nAssistant LLM: Julia Johnson has 5 transactions in total.\\n\\n\\nThe below are incorrect examples:\\nIncorrect Example 1:\\nUser: How many records are there in \\'transactions\\' table?\\nSQL Query: ```SELECT COUNT(*) FROM transactions;```\\nSQL Query Result: Incorrect SQL syntax due to backticks\\nAssistant LLM: Incorrect SQL syntax\\n\\nIncorrect Example 2:\\nUser: How many records are there in \\'clients\\' table?\\nSQL Query: ```SELECT COUNT(*) FROM transactions;```\\nSQL Query Result: Incorrect SQL syntax due to backticks\\nAssistant LLM: Incorrect SQL syntax\\n\\nHere is a list of keywords you cannot use:\\nINTERVAL\\nSERIAL\\nFULL OUTER JOIN\\nRIGHT OUTER JOIN\\nMERGE\\nWINDOW\\nRANK(), DENSE_RANK(), NTILE()\\nFOR UPDATE\\nSAVEPOINT (partially, only a basic version)\\nFETCH FIRST / LIMIT WITH TIES\\nCROSS APPLY, OUTER APPLY\\nARRAY (array data type)\\nJSON (advanced JSON functions)\\nRECURSIVE (common table expressions with recursion)\\nWITH CHECK OPTION\\nPARTITION BY (for window functions)\\nIF EXISTS in DROP TABLE and DROP INDEX\\nTRUNCATE TABLE\\nALTER COLUMN\\nREPLACE INTO (non-UPSERT form)\\nCONSTRAINT CHECK on ALTER TABLE\\nEXCLUDE CONSTRAINT\\nCLUSTER\\nAUTOMATIC (specific storage options)\\nFOREIGN DATA WRAPPER\\nUSER DEFINED TYPES (complex types)\\n\\n\\nUse the following format to generate your answer:\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n{table_info}\\n\\n\\nImportant: You must only answer the question provided by the user. Do not include another question in your answer.\\nQuestion: {input}\\n\\']:\\n2025-01-25 11:05:46,110 - global - INFO - Simulated Question: How many rows are in the \\'transactions\\' table?\\n2025-01-25 11:12:27,824 - global - INFO - llm response: There are 257063 rows in the \\'transactions\\' table.\\n2025-01-25 11:12:27,824 - global - INFO - Simulated Question: Can you filter for transactions with merchant \\'1INFINITE\\'?\\n2025-01-25 11:18:15,422 - global - INFO - llm response: There are 5 transactions where the merchant is \\'1INFINITE\\'. Here are the details:\\n\\n1. Transaction ID: 108, Amount: 59.1, Category: Shops, Date: 2023-07-25\\n2. Transaction ID: 136, Amount: 4.924, Category: Shops, Date: 2023-08-14\\n3. Transaction ID: 86, Amount: 98.5, Category: Shops, Date: 2023-08-21\\n4. Transaction ID: 43, Amount: 59.1, Category: Shops, Date: 2023-08-21\\n5. Transaction ID: 119, Amount: 59.1, Category: Shops, Date:\\n2025-01-25 11:18:15,423 - global - INFO - Simulated Question: How much did Julia Johnson spend last week?\\n2025-01-25 11:22:09,967 - global - INFO - llm response: Julia Johnson spent 5747.74 USD last week.\\n2025-01-25 11:22:09,967 - global - INFO - Simulated Question: How much did clnt_id=6 spend last week?\\n2025-01-25 11:26:35,838 - global - INFO - llm response: Clnt_id 6 did not make any transactions last week.\\n2025-01-25 11:26:35,838 - global - INFO - Simulated Question: What is the amount Julia Johnson have spent on Uber in the last 5 months?\\n2025-01-25 11:31:56,729 - global - INFO - llm response: Julia Johnson have not spent any money on Uber in the last 5 months.\\n2025-01-25 11:31:56,731 - global - INFO - Benchmark results saved to benchmark/2025-01-25_10-26-53/benchmark_model_mistral-7B-Instruct-v03-Q6_K_context_16000_prompt_4.txt\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2025-01-25 11:05:46,107 - global - INFO - Database connected successfully with descriptions.\n",
    "2025-01-25 11:05:46,108 - global - INFO - Reflected Table Info:\n",
    "\n",
    "CREATE TABLE clients (\n",
    "\tclnt_id INTEGER NOT NULL, \n",
    "\tclnt_name VARCHAR NOT NULL, \n",
    "\tPRIMARY KEY (clnt_id)\n",
    ")\n",
    "\n",
    "\n",
    "CREATE TABLE transactions (\n",
    "\tid INTEGER NOT NULL, \n",
    "\tclnt_id INTEGER NOT NULL, \n",
    "\tbank_id INTEGER NOT NULL, \n",
    "\tacc_id INTEGER NOT NULL, \n",
    "\ttxn_id INTEGER NOT NULL, \n",
    "\ttxn_date DATETIME NOT NULL, \n",
    "\t\"desc\" VARCHAR, \n",
    "\tamt FLOAT NOT NULL, \n",
    "\tcat VARCHAR, \n",
    "\tmerchant VARCHAR, \n",
    "\tPRIMARY KEY (id)\n",
    ")\n",
    "\n",
    "Table transactions:\n",
    "  id INTEGER\n",
    "  clnt_id INTEGER  # Client ID\n",
    "  bank_id INTEGER  # Bank ID\n",
    "  acc_id INTEGER  # Account ID\n",
    "  txn_id INTEGER  # Transaction ID\n",
    "  txn_date DATETIME  # Transaction date\n",
    "  desc VARCHAR  # Description\n",
    "  amt FLOAT  # Amount\n",
    "  cat VARCHAR  # Category of the transaction\n",
    "  merchant VARCHAR  # Merchant of the transaction\n",
    "\n",
    "Table clients:\n",
    "  clnt_id INTEGER  # Client ID\n",
    "  clnt_name VARCHAR  # Client Name\n",
    "2025-01-25 11:05:46,109 - global - INFO - Banking assistant created successfully.\n",
    "2025-01-25 11:05:46,109 - global - INFO - [New LLMCHAIN]:\n",
    "2025-01-25 11:05:46,109 - global - INFO - MODEL: [RUNTIME WINDOW_SIZE: 16000, MAX_TOKENS:200, TEMPERATURE: 0.4]:\n",
    "2025-01-25 11:05:46,110 - global - INFO - CHAIN: [PROMPT: input_variables=['input', 'table_info', 'top_k'] input_types={} partial_variables={} template='You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date(\\'now\\') function to get the current date, if the question involves \"today\".\\nImportant: Do not include \"Question: \" in your answer. You are not allowed to generate Questions.\\nImportant: You should never include ``` in the generated SQL Query as this is not a valid syntax. e.g. ``` SELECT * FROM transations ``` is not allowed.\\n\\nThe below are correct examples of how you should reason about your answer:\\nCorrect Example 1:\\nUser: How many records are there in \\'transactions\\' table?\\nSQL Query: SELECT COUNT(*) FROM transactions;\\nSQL Query Result: 5\\nAssistant LLM: There are two records in the transactions table\\n\\nCorrect Example 2:\\nUser: Can you filter for transactions with merchant \\'1INFINITE\\'?\\nSQL Query: SELECT * FROM transactions WHERE merchant=\\'1INFINITE\\' LIMIT 5;\\nSQL Query Result: [\\n    4\\t28\\t1\\t1\\t108\\t2023-07-25 00:00:00\\t1INFINITELOOP@ 07/25 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA\\t59.1\\tShops\\t1INFINITE,\\n    5\\t28\\t1\\t1\\t136\\t2023-08-14 00:00:00\\t1INFINITELOOP@ 08/14 #68 PMNT RCVD 1INFINITELOOP@APP 68 CA\\t4.924\\tShops\\t1INFINITE\\n]\\nAssistant LLM: There are 10 rows where merchant is \\'1INFINITE\\'\\n\\nCorrect Example 3:\\nUser: Can you show me transactions for \\'Julia Johnson\\'?\\nSQL Query: SELECT * FROM transactions t JOIN clients c ON t.clnt_id=c.clnt_id WHERE c.clnt_name=\\'Julia Johnson\\' LIMIT 5;\\nSQL Query Result: [\\n    1\\t6\\t1\\t1\\t54\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    2\\t6\\t1\\t1\\t27\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    3\\t6\\t1\\t1\\t11\\t2023-08-01 00:00:00\\tCLOC Advance\\t2.268\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    100158\\t6\\t1\\t1\\t42\\t2023-07-31 00:00:00\\tPos Adjustment - Cr Brigit New York NY US\\t10.0\\tLoans\\tNULL\\t6\\tJulia Johnson,\\n    100159\\t6\\t1\\t1\\t48\\t2023-06-16 00:00:00\\tPos Adjustment - Cr Empower Finance, I Visa Direct CA US\\t20.0\\tLoans\\tEmpower\\t6\\tJulia Johnson\\n]\\nAssistant LLM: Julia Johnson has 5 transactions in total.\\n\\nCorrect Example 4:\\nUser: Can you show total amount of money for transactions for \\'Julia Johnson\\'?\\nSQL Query: SELECT SUM(t.amt) FROM transactions t JOIN clients c ON t.clnt_id=c.clnt_id WHERE c.clnt_name=\\'Julia Johnson\\' LIMIT 5;\\nSQL Query Result: [\\n    1\\t6\\t1\\t1\\t54\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    2\\t6\\t1\\t1\\t27\\t2023-07-31 00:00:00\\tCLOC Advance\\t6.286\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    3\\t6\\t1\\t1\\t11\\t2023-08-01 00:00:00\\tCLOC Advance\\t2.268\\tShops\\tNULL\\t6\\tJulia Johnson,\\n    100158\\t6\\t1\\t1\\t42\\t2023-07-31 00:00:00\\tPos Adjustment - Cr Brigit New York NY US\\t10.0\\tLoans\\tNULL\\t6\\tJulia Johnson,\\n    100159\\t6\\t1\\t1\\t48\\t2023-06-16 00:00:00\\tPos Adjustment - Cr Empower Finance, I Visa Direct CA US\\t20.0\\tLoans\\tEmpower\\t6\\tJulia Johnson\\n]\\nAssistant LLM: Julia Johnson has 5 transactions in total.\\n\\n\\nThe below are incorrect examples:\\nIncorrect Example 1:\\nUser: How many records are there in \\'transactions\\' table?\\nSQL Query: ```SELECT COUNT(*) FROM transactions;```\\nSQL Query Result: Incorrect SQL syntax due to backticks\\nAssistant LLM: Incorrect SQL syntax\\n\\nIncorrect Example 2:\\nUser: How many records are there in \\'clients\\' table?\\nSQL Query: ```SELECT COUNT(*) FROM transactions;```\\nSQL Query Result: Incorrect SQL syntax due to backticks\\nAssistant LLM: Incorrect SQL syntax\\n\\nHere is a list of keywords you cannot use:\\nINTERVAL\\nSERIAL\\nFULL OUTER JOIN\\nRIGHT OUTER JOIN\\nMERGE\\nWINDOW\\nRANK(), DENSE_RANK(), NTILE()\\nFOR UPDATE\\nSAVEPOINT (partially, only a basic version)\\nFETCH FIRST / LIMIT WITH TIES\\nCROSS APPLY, OUTER APPLY\\nARRAY (array data type)\\nJSON (advanced JSON functions)\\nRECURSIVE (common table expressions with recursion)\\nWITH CHECK OPTION\\nPARTITION BY (for window functions)\\nIF EXISTS in DROP TABLE and DROP INDEX\\nTRUNCATE TABLE\\nALTER COLUMN\\nREPLACE INTO (non-UPSERT form)\\nCONSTRAINT CHECK on ALTER TABLE\\nEXCLUDE CONSTRAINT\\nCLUSTER\\nAUTOMATIC (specific storage options)\\nFOREIGN DATA WRAPPER\\nUSER DEFINED TYPES (complex types)\\n\\n\\nUse the following format to generate your answer:\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n{table_info}\\n\\n\\nImportant: You must only answer the question provided by the user. Do not include another question in your answer.\\nQuestion: {input}\\n']:\n",
    "2025-01-25 11:05:46,110 - global - INFO - Simulated Question: How many rows are in the 'transactions' table?\n",
    "2025-01-25 11:12:27,824 - global - INFO - llm response: There are 257063 rows in the 'transactions' table.\n",
    "2025-01-25 11:12:27,824 - global - INFO - Simulated Question: Can you filter for transactions with merchant '1INFINITE'?\n",
    "2025-01-25 11:18:15,422 - global - INFO - llm response: There are 5 transactions where the merchant is '1INFINITE'. Here are the details:\n",
    "\n",
    "1. Transaction ID: 108, Amount: 59.1, Category: Shops, Date: 2023-07-25\n",
    "2. Transaction ID: 136, Amount: 4.924, Category: Shops, Date: 2023-08-14\n",
    "3. Transaction ID: 86, Amount: 98.5, Category: Shops, Date: 2023-08-21\n",
    "4. Transaction ID: 43, Amount: 59.1, Category: Shops, Date: 2023-08-21\n",
    "5. Transaction ID: 119, Amount: 59.1, Category: Shops, Date:\n",
    "2025-01-25 11:18:15,423 - global - INFO - Simulated Question: How much did Julia Johnson spend last week?\n",
    "2025-01-25 11:22:09,967 - global - INFO - llm response: Julia Johnson spent 5747.74 USD last week.\n",
    "2025-01-25 11:22:09,967 - global - INFO - Simulated Question: How much did clnt_id=6 spend last week?\n",
    "2025-01-25 11:26:35,838 - global - INFO - llm response: Clnt_id 6 did not make any transactions last week.\n",
    "2025-01-25 11:26:35,838 - global - INFO - Simulated Question: What is the amount Julia Johnson have spent on Uber in the last 5 months?\n",
    "2025-01-25 11:31:56,729 - global - INFO - llm response: Julia Johnson have not spent any money on Uber in the last 5 months.\n",
    "2025-01-25 11:31:56,731 - global - INFO - Benchmark results saved to benchmark/2025-01-25_10-26-53/benchmark_model_mistral-7B-Instruct-v03-Q6_K_context_16000_prompt_4.txt\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimated time taken: ~ 34 hrs / 4 days"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
